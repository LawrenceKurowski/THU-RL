{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw__LXqk3KTL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTVSzaqr_cUw",
        "colab_type": "code",
        "outputId": "c01d0f60-9212-4d0d-c387-54176ffe40b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"\n",
        "Setup gfootball \n",
        "\"\"\"\n",
        "!apt-get update\n",
        "!apt-get install libsdl2-gfx-dev libsdl2-ttf-dev\n",
        "\n",
        "# Make sure that the Branch in git clone and in wget call matches !!\n",
        "!git clone -b v2.0.6 https://github.com/google-research/football.git\n",
        "!mkdir -p football/third_party/gfootball_engine/lib\n",
        "\n",
        "!wget https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.0.6.so -O football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so\n",
        "!cd football && GFOOTBALL_USE_PREBUILT_SO=1 pip3 install ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,626 B/3,626 B 100\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:3 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rGet:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [6 InRelease 2,586 B/88.7 k\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [6 InRelease 5,482 B/88.7 k\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,814 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [844 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,376 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [908 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,205 kB]\n",
            "Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [875 kB]\n",
            "Fetched 7,294 kB in 3s (2,387 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  gir1.2-ibus-1.0 libcapnp-0.6.1 libdbus-1-dev libibus-1.0-5 libibus-1.0-dev\n",
            "  libmirclient-dev libmirclient9 libmircommon-dev libmircommon7\n",
            "  libmircookie-dev libmircookie2 libmircore-dev libmircore1 libmirprotobuf3\n",
            "  libprotobuf-dev libprotobuf-lite10 libpulse-dev libpulse-mainloop-glib0\n",
            "  libsdl2-dev libsdl2-gfx-1.0-0 libsdl2-ttf-2.0-0 libsndio-dev libudev-dev\n",
            "  libxcursor-dev libxinerama-dev libxkbcommon-dev libxrandr-dev libxv-dev\n",
            "  x11proto-randr-dev x11proto-xinerama-dev\n",
            "Suggested packages:\n",
            "  libsdl2-gfx-doc\n",
            "The following NEW packages will be installed:\n",
            "  gir1.2-ibus-1.0 libcapnp-0.6.1 libdbus-1-dev libibus-1.0-5 libibus-1.0-dev\n",
            "  libmirclient-dev libmirclient9 libmircommon-dev libmircommon7\n",
            "  libmircookie-dev libmircookie2 libmircore-dev libmircore1 libmirprotobuf3\n",
            "  libprotobuf-dev libprotobuf-lite10 libpulse-dev libpulse-mainloop-glib0\n",
            "  libsdl2-dev libsdl2-gfx-1.0-0 libsdl2-gfx-dev libsdl2-ttf-2.0-0\n",
            "  libsdl2-ttf-dev libsndio-dev libudev-dev libxcursor-dev libxinerama-dev\n",
            "  libxkbcommon-dev libxrandr-dev libxv-dev x11proto-randr-dev\n",
            "  x11proto-xinerama-dev\n",
            "0 upgraded, 32 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 3,919 kB of archives.\n",
            "After this operation, 24.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libibus-1.0-5 amd64 1.5.17-3ubuntu5.3 [133 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gir1.2-ibus-1.0 amd64 1.5.17-3ubuntu5.3 [66.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcapnp-0.6.1 amd64 0.6.1-1ubuntu1 [658 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdbus-1-dev amd64 1.12.2-1ubuntu1.1 [165 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libibus-1.0-dev amd64 1.5.17-3ubuntu5.3 [145 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore1 amd64 0.31.1-0ubuntu1 [26.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon7 amd64 0.31.1-0ubuntu1 [73.9 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-lite10 amd64 3.0.0-9.1ubuntu1 [97.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirprotobuf3 amd64 0.31.1-0ubuntu1 [127 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient9 amd64 0.31.1-0ubuntu1 [199 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore-dev amd64 0.31.1-0ubuntu1 [21.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-dev amd64 3.0.0-9.1ubuntu1 [959 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxkbcommon-dev amd64 0.8.2-1~ubuntu18.04.1 [150 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon-dev amd64 0.31.1-0ubuntu1 [13.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie2 amd64 0.31.1-0ubuntu1 [19.7 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie-dev amd64 0.31.1-0ubuntu1 [4,392 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient-dev amd64 0.31.1-0ubuntu1 [47.8 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-mainloop-glib0 amd64 1:11.1-1ubuntu7.5 [22.1 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-dev amd64 1:11.1-1ubuntu7.5 [81.5 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsndio-dev amd64 1.1.0-3 [13.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libudev-dev amd64 237-3ubuntu10.39 [19.1 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor-dev amd64 1:1.1.15-1 [26.5 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xinerama-dev all 2018.4-4 [2,628 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama-dev amd64 2:1.1.3-1 [8,404 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-randr-dev all 2018.4-4 [2,620 B]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr-dev amd64 2:1.5.1-1 [24.0 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxv-dev amd64 2:1.0.11-1 [32.5 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsdl2-dev amd64 2.0.8+dfsg1-1ubuntu1.18.04.4 [683 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-gfx-1.0-0 amd64 1.0.4+dfsg-1 [29.9 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-gfx-dev amd64 1.0.4+dfsg-1 [29.8 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-ttf-2.0-0 amd64 2.0.14+dfsg1-2 [14.8 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-ttf-dev amd64 2.0.14+dfsg1-2 [19.7 kB]\n",
            "Fetched 3,919 kB in 1s (2,787 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libibus-1.0-5:amd64.\n",
            "(Reading database ... 144429 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libibus-1.0-5_1.5.17-3ubuntu5.3_amd64.deb ...\n",
            "Unpacking libibus-1.0-5:amd64 (1.5.17-3ubuntu5.3) ...\n",
            "Selecting previously unselected package gir1.2-ibus-1.0:amd64.\n",
            "Preparing to unpack .../01-gir1.2-ibus-1.0_1.5.17-3ubuntu5.3_amd64.deb ...\n",
            "Unpacking gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu5.3) ...\n",
            "Selecting previously unselected package libcapnp-0.6.1:amd64.\n",
            "Preparing to unpack .../02-libcapnp-0.6.1_0.6.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libdbus-1-dev:amd64.\n",
            "Preparing to unpack .../03-libdbus-1-dev_1.12.2-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libdbus-1-dev:amd64 (1.12.2-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libibus-1.0-dev:amd64.\n",
            "Preparing to unpack .../04-libibus-1.0-dev_1.5.17-3ubuntu5.3_amd64.deb ...\n",
            "Unpacking libibus-1.0-dev:amd64 (1.5.17-3ubuntu5.3) ...\n",
            "Selecting previously unselected package libmircore1:amd64.\n",
            "Preparing to unpack .../05-libmircore1_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircore1:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircommon7:amd64.\n",
            "Preparing to unpack .../06-libmircommon7_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
            "Preparing to unpack .../07-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libmirprotobuf3:amd64.\n",
            "Preparing to unpack .../08-libmirprotobuf3_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmirclient9:amd64.\n",
            "Preparing to unpack .../09-libmirclient9_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircore-dev:amd64.\n",
            "Preparing to unpack .../10-libmircore-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../11-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libxkbcommon-dev:amd64.\n",
            "Preparing to unpack .../12-libxkbcommon-dev_0.8.2-1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\n",
            "Selecting previously unselected package libmircommon-dev:amd64.\n",
            "Preparing to unpack .../13-libmircommon-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircookie2:amd64.\n",
            "Preparing to unpack .../14-libmircookie2_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircookie-dev:amd64.\n",
            "Preparing to unpack .../15-libmircookie-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmirclient-dev:amd64.\n",
            "Preparing to unpack .../16-libmirclient-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libpulse-mainloop-glib0:amd64.\n",
            "Preparing to unpack .../17-libpulse-mainloop-glib0_1%3a11.1-1ubuntu7.5_amd64.deb ...\n",
            "Unpacking libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.5) ...\n",
            "Selecting previously unselected package libpulse-dev:amd64.\n",
            "Preparing to unpack .../18-libpulse-dev_1%3a11.1-1ubuntu7.5_amd64.deb ...\n",
            "Unpacking libpulse-dev:amd64 (1:11.1-1ubuntu7.5) ...\n",
            "Selecting previously unselected package libsndio-dev:amd64.\n",
            "Preparing to unpack .../19-libsndio-dev_1.1.0-3_amd64.deb ...\n",
            "Unpacking libsndio-dev:amd64 (1.1.0-3) ...\n",
            "Selecting previously unselected package libudev-dev:amd64.\n",
            "Preparing to unpack .../20-libudev-dev_237-3ubuntu10.39_amd64.deb ...\n",
            "Unpacking libudev-dev:amd64 (237-3ubuntu10.39) ...\n",
            "Selecting previously unselected package libxcursor-dev:amd64.\n",
            "Preparing to unpack .../21-libxcursor-dev_1%3a1.1.15-1_amd64.deb ...\n",
            "Unpacking libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Selecting previously unselected package x11proto-xinerama-dev.\n",
            "Preparing to unpack .../22-x11proto-xinerama-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-xinerama-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxinerama-dev:amd64.\n",
            "Preparing to unpack .../23-libxinerama-dev_2%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Selecting previously unselected package x11proto-randr-dev.\n",
            "Preparing to unpack .../24-x11proto-randr-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-randr-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxrandr-dev:amd64.\n",
            "Preparing to unpack .../25-libxrandr-dev_2%3a1.5.1-1_amd64.deb ...\n",
            "Unpacking libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
            "Selecting previously unselected package libxv-dev:amd64.\n",
            "Preparing to unpack .../26-libxv-dev_2%3a1.0.11-1_amd64.deb ...\n",
            "Unpacking libxv-dev:amd64 (2:1.0.11-1) ...\n",
            "Selecting previously unselected package libsdl2-dev:amd64.\n",
            "Preparing to unpack .../27-libsdl2-dev_2.0.8+dfsg1-1ubuntu1.18.04.4_amd64.deb ...\n",
            "Unpacking libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\n",
            "Selecting previously unselected package libsdl2-gfx-1.0-0:amd64.\n",
            "Preparing to unpack .../28-libsdl2-gfx-1.0-0_1.0.4+dfsg-1_amd64.deb ...\n",
            "Unpacking libsdl2-gfx-1.0-0:amd64 (1.0.4+dfsg-1) ...\n",
            "Selecting previously unselected package libsdl2-gfx-dev:amd64.\n",
            "Preparing to unpack .../29-libsdl2-gfx-dev_1.0.4+dfsg-1_amd64.deb ...\n",
            "Unpacking libsdl2-gfx-dev:amd64 (1.0.4+dfsg-1) ...\n",
            "Selecting previously unselected package libsdl2-ttf-2.0-0:amd64.\n",
            "Preparing to unpack .../30-libsdl2-ttf-2.0-0_2.0.14+dfsg1-2_amd64.deb ...\n",
            "Unpacking libsdl2-ttf-2.0-0:amd64 (2.0.14+dfsg1-2) ...\n",
            "Selecting previously unselected package libsdl2-ttf-dev:amd64.\n",
            "Preparing to unpack .../31-libsdl2-ttf-dev_2.0.14+dfsg1-2_amd64.deb ...\n",
            "Unpacking libsdl2-ttf-dev:amd64 (2.0.14+dfsg1-2) ...\n",
            "Setting up libdbus-1-dev:amd64 (1.12.2-1ubuntu1.1) ...\n",
            "Setting up libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Setting up libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\n",
            "Setting up libsdl2-gfx-1.0-0:amd64 (1.0.4+dfsg-1) ...\n",
            "Setting up libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.5) ...\n",
            "Setting up libpulse-dev:amd64 (1:11.1-1ubuntu7.5) ...\n",
            "Setting up libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libsndio-dev:amd64 (1.1.0-3) ...\n",
            "Setting up libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up x11proto-xinerama-dev (2018.4-4) ...\n",
            "Setting up x11proto-randr-dev (2018.4-4) ...\n",
            "Setting up libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Setting up libxv-dev:amd64 (2:1.0.11-1) ...\n",
            "Setting up libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n",
            "Setting up libibus-1.0-5:amd64 (1.5.17-3ubuntu5.3) ...\n",
            "Setting up libsdl2-ttf-2.0-0:amd64 (2.0.14+dfsg1-2) ...\n",
            "Setting up libmircore1:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libudev-dev:amd64 (237-3ubuntu10.39) ...\n",
            "Setting up gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu5.3) ...\n",
            "Setting up libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
            "Setting up libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libibus-1.0-dev:amd64 (1.5.17-3ubuntu5.3) ...\n",
            "Setting up libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\n",
            "Setting up libsdl2-ttf-dev:amd64 (2.0.14+dfsg1-2) ...\n",
            "Setting up libsdl2-gfx-dev:amd64 (1.0.4+dfsg-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Cloning into 'football'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 2294 (delta 0), reused 0 (delta 0), pack-reused 2291\u001b[K\n",
            "Receiving objects: 100% (2294/2294), 26.82 MiB | 21.34 MiB/s, done.\n",
            "Resolving deltas: 100% (1232/1232), done.\n",
            "--2020-05-07 00:43:44--  https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.0.6.so\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c14::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45228864 (43M) [application/octet-stream]\n",
            "Saving to: ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’\n",
            "\n",
            "football/third_part 100%[===================>]  43.13M  80.0MB/s    in 0.5s    \n",
            "\n",
            "2020-05-07 00:43:45 (80.0 MB/s) - ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’ saved [45228864/45228864]\n",
            "\n",
            "Processing /content/football\n",
            "Collecting pygame==1.9.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from gfootball==2.0.6) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gfootball==2.0.6) (1.4.1)\n",
            "Requirement already satisfied: gym>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from gfootball==2.0.6) (0.17.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from gfootball==2.0.6) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python->gfootball==2.0.6) (1.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym>=0.11.0->gfootball==2.0.6) (1.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.11.0->gfootball==2.0.6) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.11.0->gfootball==2.0.6) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.11.0->gfootball==2.0.6) (0.16.0)\n",
            "Building wheels for collected packages: gfootball\n",
            "  Building wheel for gfootball (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gfootball: filename=gfootball-2.0.6-cp36-cp36m-linux_x86_64.whl size=38595160 sha256=8cd0c92d6501195bd636737399e6f1936233afaf357aa6cdfb38a2beae429dfd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y8w9amwl/wheels/41/ad/ae/8cf1d92b8694b10187e5daf33e8d5c248ffa5437e234ccbbee\n",
            "Successfully built gfootball\n",
            "Installing collected packages: pygame, gfootball\n",
            "Successfully installed gfootball-2.0.6 pygame-1.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojcw-PlE_c9G",
        "colab_type": "code",
        "outputId": "40208d1a-6399-496f-c816-c6a0499cf760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "Imports\n",
        "\"\"\"\n",
        "\n",
        "import gfootball.env as football_env\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY4f4eWC_mRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Hyperparameters\n",
        "\"\"\"\n",
        "\n",
        "clipping_val = 0.2\n",
        "critic_discount = 0.5\n",
        "entropy_beta = 0.001\n",
        "gamma = 0.99\n",
        "lmbda = 0.95"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GogF0EPO_mmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Define key functions\n",
        "\"\"\"\n",
        "# estimate advantages using GAE generalized advantage estimation\n",
        "def advantages_est(values, masks, rewards):\n",
        "    returns = []\n",
        "    gae = 0\n",
        "    # reverse because it's a iterative formula from t+1 -> t\n",
        "    for i in reversed(range(len(rewards))):\n",
        "      # discounted rewards\n",
        "        # mask means: if game is over, we don't want this value in GAE \n",
        "        delta = rewards[i] + gamma * values[i + 1] * masks[i] - values[i]\n",
        "        # lmbda is the smoothing parameter\n",
        "        gae = delta + gamma * lmbda * masks[i] * gae\n",
        "        # reverse again\n",
        "        returns.insert(0, gae + values[i])\n",
        "\n",
        "    adv = np.array(returns) - values[:-1]\n",
        "    # standardize according to normal dist\n",
        "    adv_st = (adv - np.mean(adv)) / (np.std(adv) + 1e-10)\n",
        "    return returns, adv_st\n",
        "\n",
        "def ppo_loss(oldpolicy_probs, advantages, rewards, values):\n",
        "    def loss(y_true, y_pred):\n",
        "        \n",
        "        newpolicy_probs = y_pred\n",
        "        \n",
        "        # new policy / new policy = exp(log(new policy) - log(old policy)) (add 1e-8 to avoid blow-up)\n",
        "        ratio = K.exp(K.log(newpolicy_probs + 1e-8) - K.log(oldpolicy_probs + 1e-8))\n",
        "        \n",
        "        # actor loss as min(ratio x advantages, (epsilon-clip of ratio) x advantage)\n",
        "        # (just following the formula from paper)\n",
        "        val_1 = ratio * advantages\n",
        "        val_2 = K.clip(ratio, min_value=1 - clipping_val, max_value=1 + clipping_val) * advantages\n",
        "        actor_loss = -K.mean(K.minimum(val_1, val_2))\n",
        "        \n",
        "        critic_loss = K.mean(K.square(rewards - values))\n",
        "        \n",
        "        total_loss = critic_discount * critic_loss + actor_loss - entropy_beta * K.mean(\n",
        "            -(newpolicy_probs * K.log(newpolicy_probs + 1e-8)))\n",
        "        return total_loss\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def get_actor(input_dims, output_dims):\n",
        "  # defines the actor model (net)\n",
        "  # uses ppo_loss defined above\n",
        "    state_input = Input(shape=input_dims)\n",
        "    oldpolicy_probs = Input(shape=(1, output_dims,))\n",
        "    advantages = Input(shape=(1, 1,))\n",
        "    rewards = Input(shape=(1, 1,))\n",
        "    values = Input(shape=(1, 1,))\n",
        "\n",
        "    # F-C net (using Keras)\n",
        "    x = Dense(512, activation='relu', name='fc1')(state_input)\n",
        "    x = Dense(256, activation='relu', name='fc2')(x)\n",
        "    # use softmax to get out probabilities\n",
        "    out_actions = Dense(n_actions, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(inputs=[state_input, oldpolicy_probs, advantages, rewards, values],\n",
        "                  outputs=[out_actions])\n",
        "    model.compile(optimizer=Adam(lr=1e-4), loss=[ppo_loss(\n",
        "        oldpolicy_probs=oldpolicy_probs,\n",
        "        advantages=advantages,\n",
        "        rewards=rewards,\n",
        "        values=values)])\n",
        "    # model.summary()\n",
        "    return model\n",
        "\n",
        "def get_critic(input_dims):\n",
        "  # net for critic, loss here is just mse\n",
        "    state_input = Input(shape=input_dims)\n",
        "\n",
        "    # F-C net (using Keras)\n",
        "    x = Dense(512, activation='relu', name='fc1')(state_input)\n",
        "    x = Dense(256, activation='relu', name='fc2')(x)\n",
        "    # final activation is tanh\n",
        "    out_actions = Dense(1, activation='tanh')(x)\n",
        "\n",
        "    model = Model(inputs=[state_input], outputs=[out_actions])\n",
        "    model.compile(optimizer=Adam(lr=1e-4), loss='mse')\n",
        "    # model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def test_reward():\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    print('testing...')\n",
        "    limit = 0\n",
        "    while not done:\n",
        "        state_input = K.expand_dims(state, 0)\n",
        "        # forward pass to get prob distribution ()\n",
        "        # initialized to random values (rand_n and rand_1)\n",
        "        action_probs = model_actor.predict([state_input, dummy_n, dummy_1, dummy_1, dummy_1], steps=1)\n",
        "\n",
        "        # pick action with highest prob\n",
        "        action = np.argmax(action_probs)\n",
        "\n",
        "        # take action\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        # update step\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "        limit += 1\n",
        "\n",
        "        # allow 100 steps, if still not done, break\n",
        "        if limit > 100:\n",
        "            break\n",
        "    return total_reward\n",
        "\n",
        "\n",
        "def one_hot_encoding(probs):\n",
        "    one_hot = np.zeros_like(probs)\n",
        "    one_hot[:, np.argmax(probs, axis=1)] = 1\n",
        "    return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7tsWmkW7lZC",
        "colab_type": "code",
        "outputId": "84599d2c-6d43-4356-c606-c6b16f98b2c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"\n",
        "The training \n",
        "\"\"\"\n",
        "# define environment\n",
        "env = football_env.create_environment(env_name='academy_empty_goal', representation='simple115')\n",
        "\n",
        "# reset the environment\n",
        "state = env.reset()\n",
        "\n",
        "# define some variables\n",
        "state_dims = env.observation_space.shape\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "# random initialization for testing nets\n",
        "dummy_n = np.zeros((1,1,n_actions))\n",
        "dummy_1 = np.zeros((1,1,1))\n",
        "\n",
        "#rand_n = np.random.rand(1, 1, n_actions)\n",
        "#rand_1 = np.random.rand(1, 1, 1)\n",
        "\n",
        "# define the nets for actor / critic\n",
        "model_actor = get_actor(input_dims=state_dims, output_dims=n_actions)\n",
        "model_critic = get_critic(input_dims=state_dims)\n",
        "\n",
        "# parameters for the looping\n",
        "max_iters = 100\n",
        "ppo_steps = 100\n",
        "target_reached = False\n",
        "best_reward = 0\n",
        "iters = 0\n",
        "\n",
        "# to be populated when looping\n",
        "avg_reward_rec = []\n",
        "actor_loss_rec = []\n",
        "critic_loss_rec = []\n",
        "total_loss_rec = []\n",
        "\n",
        "# iterate episodes\n",
        "while not target_reached and iters < max_iters:\n",
        "\n",
        "    states = []\n",
        "    actions = []\n",
        "    values = []\n",
        "    masks = []\n",
        "    rewards = []\n",
        "    actions_probs = []\n",
        "    actions_onehot = []\n",
        "    state_input = None\n",
        "\n",
        "# within each episode, iterate ppo updates, to collect data about the current policy...\n",
        "    for itr in range(ppo_steps):\n",
        "        state_input = K.expand_dims(state, 0)\n",
        "        \n",
        "        # forward pass for actor, with random initialization, to get the prob dist of actions (random_n and random_1 just used to fill the extra dimensions)\n",
        "        action_dist = model_actor.predict([state_input, dummy_n, dummy_1, dummy_1, dummy_1], steps=1)\n",
        "\n",
        "        # forward pass for critic, to get Q value\n",
        "        q_value = model_critic.predict([state_input], steps=1)\n",
        "\n",
        "        # pick action index (sample for action distribuition)\n",
        "        action = np.random.choice(n_actions, p=action_dist[0, :])\n",
        "        # encode as 1-hot\n",
        "        action_onehot = np.zeros(n_actions)\n",
        "        action_onehot[action] = 1\n",
        "\n",
        "        # do the action and observe \n",
        "        observation, reward, done, info = env.step(action)\n",
        "        if itr%10==0:\n",
        "          print('at episode: '+str(iters) + ', itr: ' + str(itr) + ', action=' + str(action) + ', reward=' + str(reward) + ', q val=' + str(q_value))\n",
        "        mask = not done\n",
        "\n",
        "\n",
        "        states.append(state)\n",
        "        actions.append(action)\n",
        "        actions_onehot.append(action_onehot)\n",
        "        values.append(q_value)\n",
        "        masks.append(mask)\n",
        "        rewards.append(reward)\n",
        "        actions_probs.append(action_dist)\n",
        "\n",
        "        state = observation\n",
        "        if done:\n",
        "            env.reset()\n",
        "# ... and update the policy\n",
        "    # forward pass for critic, using net \n",
        "    q_value = model_critic.predict(state_input, steps=1)\n",
        "    values.append(q_value)\n",
        "\n",
        "    returns, advantages = advantages_est(values, masks, rewards)\n",
        "    # update actor network\n",
        "    # over N epochs (specified as argument of \"fit\")\n",
        "    N = 10\n",
        "    print(\"fitting actor net (PPO loss)...\")\n",
        "    actor_loss = model_actor.fit(\n",
        "        [states, actions_probs, advantages, np.reshape(rewards, newshape=(-1, 1, 1)), values[:-1]],\n",
        "        [(np.reshape(actions_onehot, newshape=(-1, n_actions)))], verbose=True, shuffle=True, epochs=N)\n",
        "\n",
        "    # update critic network\n",
        "    print(\"fitting critic net (MSE loss)...\")\n",
        "    critic_loss = model_critic.fit([states], [np.reshape(returns, newshape=(-1, 1))], shuffle=True, epochs=N,\n",
        "                                   verbose=True)\n",
        "\n",
        "    avg_reward = np.mean([test_reward() for _ in range(5)])\n",
        "    avg_reward_rec.append(avg_reward)\n",
        "\n",
        "    # policy loss:\n",
        "    actor_loss_rec.append(actor_loss)\n",
        "\n",
        "    # value loss:\n",
        "    critic_loss_rec.append(critic_loss)\n",
        "\n",
        "    #total_loss_rec.append()\n",
        "    print('total test reward=' + str(avg_reward))\n",
        "    if avg_reward > best_reward:\n",
        "        print('best reward=' + str(avg_reward))\n",
        "        #model_actor.save('model_actor_{}_{}.hdf5'.format(iters, avg_reward))\n",
        "        #model_critic.save('model_critic_{}_{}.hdf5'.format(iters, avg_reward))\n",
        "        best_reward = avg_reward\n",
        "    if best_reward > 0.9 or iters > max_iters:\n",
        "        target_reached = True\n",
        "\n",
        "    iters += 1\n",
        "    env.reset()\n",
        "env.close()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "at episode: 0, itr: 0, action=16, reward=0.0, q val=[[-0.01680059]]\n",
            "at episode: 0, itr: 10, action=13, reward=0.0, q val=[[-0.02669679]]\n",
            "at episode: 0, itr: 20, action=13, reward=0.0, q val=[[0.03657009]]\n",
            "at episode: 0, itr: 30, action=10, reward=0.0, q val=[[-0.00542722]]\n",
            "at episode: 0, itr: 40, action=9, reward=0.0, q val=[[-0.03015057]]\n",
            "at episode: 0, itr: 50, action=6, reward=0.0, q val=[[-0.02822151]]\n",
            "at episode: 0, itr: 60, action=10, reward=0.0, q val=[[-0.04297094]]\n",
            "at episode: 0, itr: 70, action=7, reward=0.0, q val=[[0.01268417]]\n",
            "at episode: 0, itr: 80, action=14, reward=0.0, q val=[[0.01981226]]\n",
            "at episode: 0, itr: 90, action=4, reward=0.0, q val=[[0.01189235]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0051\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0021\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0024\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0031\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0024\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.0018\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.0021\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.0021\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.0019\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 364us/step - loss: 0.0018\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 926us/step - loss: 0.0658\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 0.0518\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 0.0354\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 186us/step - loss: 0.0330\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 0.0306\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 192us/step - loss: 0.0300\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 0.0286\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 0.0272\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 187us/step - loss: 0.0253\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 0.0256\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 1, itr: 0, action=14, reward=0.0, q val=[[-0.10723101]]\n",
            "at episode: 1, itr: 10, action=2, reward=0.0, q val=[[-0.07663455]]\n",
            "at episode: 1, itr: 20, action=13, reward=0.0, q val=[[0.0105186]]\n",
            "at episode: 1, itr: 30, action=14, reward=0.0, q val=[[-0.2020495]]\n",
            "at episode: 1, itr: 40, action=6, reward=0.0, q val=[[-0.2836682]]\n",
            "at episode: 1, itr: 50, action=8, reward=0.0, q val=[[-0.3093962]]\n",
            "at episode: 1, itr: 60, action=8, reward=0.0, q val=[[0.17051812]]\n",
            "at episode: 1, itr: 70, action=13, reward=0.0, q val=[[0.09925748]]\n",
            "at episode: 1, itr: 80, action=13, reward=0.0, q val=[[-0.00252063]]\n",
            "at episode: 1, itr: 90, action=3, reward=0.0, q val=[[0.10902685]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0676\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.0616\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0591\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0567\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0567\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0566\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0557\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0572\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0575\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.0565\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0159\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0143\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0118\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0111\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0091\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0077\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0074\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0060\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 0.0057\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0048\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 2, itr: 0, action=7, reward=0.0, q val=[[0.11821111]]\n",
            "at episode: 2, itr: 10, action=14, reward=0.0, q val=[[-0.05364352]]\n",
            "at episode: 2, itr: 20, action=11, reward=0.0, q val=[[0.00613241]]\n",
            "at episode: 2, itr: 30, action=0, reward=0.0, q val=[[-0.13634482]]\n",
            "at episode: 2, itr: 40, action=8, reward=0.0, q val=[[-0.18572894]]\n",
            "at episode: 2, itr: 50, action=4, reward=0.0, q val=[[-0.21009424]]\n",
            "at episode: 2, itr: 60, action=4, reward=0.0, q val=[[-0.22311193]]\n",
            "at episode: 2, itr: 70, action=4, reward=0.0, q val=[[-0.2304965]]\n",
            "at episode: 2, itr: 80, action=5, reward=0.0, q val=[[-0.2277481]]\n",
            "at episode: 2, itr: 90, action=10, reward=0.0, q val=[[-0.21846652]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0150\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.0150\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0149\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.0144\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.0151\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0147\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0148\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 268us/step - loss: 0.0143\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.0144\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0136\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 290us/step - loss: 0.0018\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 7.5801e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 196us/step - loss: 4.9456e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 5.3475e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 5.0916e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 4.1600e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 2.7143e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 2.0887e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 1.9416e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 2.3161e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 3, itr: 0, action=13, reward=0.0, q val=[[-0.19596909]]\n",
            "at episode: 3, itr: 10, action=13, reward=0.0, q val=[[-0.06044095]]\n",
            "at episode: 3, itr: 20, action=17, reward=0.0, q val=[[-0.08016962]]\n",
            "at episode: 3, itr: 30, action=17, reward=0.0, q val=[[-0.11041926]]\n",
            "at episode: 3, itr: 40, action=14, reward=0.0, q val=[[-0.13102943]]\n",
            "at episode: 3, itr: 50, action=14, reward=0.0, q val=[[-0.14169778]]\n",
            "at episode: 3, itr: 60, action=2, reward=0.0, q val=[[-0.14495657]]\n",
            "at episode: 3, itr: 70, action=8, reward=0.0, q val=[[-0.14872414]]\n",
            "at episode: 3, itr: 80, action=13, reward=0.0, q val=[[-0.1517303]]\n",
            "at episode: 3, itr: 90, action=16, reward=0.0, q val=[[-0.14829972]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0145\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0149\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.0141\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.0138\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0149\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.0147\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.0140\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0143\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 284us/step - loss: 0.0137\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0142\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 6.2842e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 5.2927e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 3.1958e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 418us/step - loss: 2.3584e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 2.2649e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: 2.6046e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 2.2181e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 1.8590e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 1.6782e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 1.6331e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 4, itr: 0, action=11, reward=0.0, q val=[[-0.11889073]]\n",
            "at episode: 4, itr: 10, action=0, reward=0.0, q val=[[-0.11035821]]\n",
            "at episode: 4, itr: 20, action=8, reward=0.0, q val=[[-0.12040715]]\n",
            "at episode: 4, itr: 30, action=15, reward=0.0, q val=[[-0.1258819]]\n",
            "at episode: 4, itr: 40, action=4, reward=0.0, q val=[[-0.13893327]]\n",
            "at episode: 4, itr: 50, action=13, reward=0.0, q val=[[-0.14319706]]\n",
            "at episode: 4, itr: 60, action=14, reward=0.0, q val=[[-0.0679352]]\n",
            "at episode: 4, itr: 70, action=12, reward=0.0, q val=[[-0.01227271]]\n",
            "at episode: 4, itr: 80, action=12, reward=0.0, q val=[[0.01160228]]\n",
            "at episode: 4, itr: 90, action=13, reward=0.0, q val=[[0.03134122]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: -0.0030\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: -0.0075\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: -0.0070\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: -0.0054\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: -0.0086\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: -0.0085\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: -0.0081\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: -0.0077\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: -0.0088\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: -0.0093\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 173us/step - loss: 0.0033\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 0.0018\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 0.0015\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.0012\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 6.1451e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 7.4870e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 3.1891e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 4.8550e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 4.2244e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 5, itr: 0, action=11, reward=0.0, q val=[[0.05120075]]\n",
            "at episode: 5, itr: 10, action=11, reward=0.0, q val=[[-0.09813619]]\n",
            "at episode: 5, itr: 20, action=13, reward=0.0, q val=[[-0.0914505]]\n",
            "at episode: 5, itr: 30, action=1, reward=0.0, q val=[[-0.09715774]]\n",
            "at episode: 5, itr: 40, action=11, reward=0.0, q val=[[-0.10010155]]\n",
            "at episode: 5, itr: 50, action=10, reward=0.0, q val=[[-0.0653343]]\n",
            "at episode: 5, itr: 60, action=7, reward=0.0, q val=[[-0.11448088]]\n",
            "at episode: 5, itr: 70, action=2, reward=0.0, q val=[[-0.05283366]]\n",
            "at episode: 5, itr: 80, action=14, reward=0.0, q val=[[0.01280069]]\n",
            "at episode: 5, itr: 90, action=11, reward=0.0, q val=[[-0.00069106]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0038\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0036\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0042\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0041\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0030\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0046\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.0039\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.0056\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0037\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0035\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 186us/step - loss: 0.0014\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 9.4897e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 8.9484e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 298us/step - loss: 7.4760e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 5.2112e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 3.6316e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 294us/step - loss: 2.9265e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 2.5731e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 2.4142e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 2.2588e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 6, itr: 0, action=13, reward=0.0, q val=[[-0.02438053]]\n",
            "at episode: 6, itr: 10, action=1, reward=0.0, q val=[[-0.01981918]]\n",
            "at episode: 6, itr: 20, action=17, reward=0.0, q val=[[-0.0524934]]\n",
            "at episode: 6, itr: 30, action=13, reward=0.0, q val=[[-0.05117393]]\n",
            "at episode: 6, itr: 40, action=7, reward=0.0, q val=[[-0.06328911]]\n",
            "at episode: 6, itr: 50, action=0, reward=0.0, q val=[[-0.07625768]]\n",
            "at episode: 6, itr: 60, action=2, reward=0.0, q val=[[-0.08439536]]\n",
            "at episode: 6, itr: 70, action=13, reward=-1.0, q val=[[-0.1132112]]\n",
            "at episode: 6, itr: 80, action=5, reward=0.0, q val=[[-0.01984531]]\n",
            "at episode: 6, itr: 90, action=7, reward=0.0, q val=[[-0.02545043]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: -0.0035\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: -0.0031\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: -0.0025\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: -0.0037\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: -0.0040\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: -0.0026\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: -0.0022\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: -0.0043\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 338us/step - loss: -0.0042\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 346us/step - loss: -0.0044\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0555\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.0508\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0376\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0388\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.0314\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0281\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0274\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 0.0256\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0225\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0222\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 7, itr: 0, action=16, reward=0.0, q val=[[-0.01980326]]\n",
            "at episode: 7, itr: 10, action=7, reward=0.0, q val=[[-0.02135823]]\n",
            "at episode: 7, itr: 20, action=2, reward=0.0, q val=[[-0.01302693]]\n",
            "at episode: 7, itr: 30, action=16, reward=0.0, q val=[[-0.06754124]]\n",
            "at episode: 7, itr: 40, action=17, reward=0.0, q val=[[-0.08635449]]\n",
            "at episode: 7, itr: 50, action=13, reward=0.0, q val=[[-0.09670313]]\n",
            "at episode: 7, itr: 60, action=11, reward=0.0, q val=[[-0.0958505]]\n",
            "at episode: 7, itr: 70, action=2, reward=0.0, q val=[[-0.09188021]]\n",
            "at episode: 7, itr: 80, action=2, reward=0.0, q val=[[-0.08884722]]\n",
            "at episode: 7, itr: 90, action=16, reward=0.0, q val=[[-0.01519886]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0054\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0044\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0043\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0040\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0034\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0038\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 309us/step - loss: 0.0034\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0033\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 275us/step - loss: 0.0037\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0050\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 176us/step - loss: 0.0014\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 9.1497e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 7.3236e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 5.4598e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 5.2687e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 4.9676e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 192us/step - loss: 5.1173e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 4.6919e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 4.1303e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 3.9846e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 8, itr: 0, action=16, reward=0.0, q val=[[0.01926666]]\n",
            "at episode: 8, itr: 10, action=13, reward=0.0, q val=[[-0.04465049]]\n",
            "at episode: 8, itr: 20, action=2, reward=0.0, q val=[[0.05844608]]\n",
            "at episode: 8, itr: 30, action=7, reward=0.0, q val=[[-0.12546255]]\n",
            "at episode: 8, itr: 40, action=1, reward=0.0, q val=[[0.09527519]]\n",
            "at episode: 8, itr: 50, action=14, reward=0.0, q val=[[-0.0573508]]\n",
            "at episode: 8, itr: 60, action=8, reward=0.0, q val=[[0.00127216]]\n",
            "at episode: 8, itr: 70, action=15, reward=0.0, q val=[[-0.24550556]]\n",
            "at episode: 8, itr: 80, action=7, reward=0.0, q val=[[-0.29337043]]\n",
            "at episode: 8, itr: 90, action=1, reward=0.0, q val=[[-0.34240922]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0214\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0213\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0207\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0210\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0210\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0210\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0206\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0215\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0214\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0211\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.0077\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0078\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 0.0063\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0059\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0058\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0062\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 0.0061\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0063\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 0.0049\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 196us/step - loss: 0.0054\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 9, itr: 0, action=14, reward=0.0, q val=[[-0.2983707]]\n",
            "at episode: 9, itr: 10, action=17, reward=0.0, q val=[[0.01576186]]\n",
            "at episode: 9, itr: 20, action=13, reward=0.0, q val=[[0.03625976]]\n",
            "at episode: 9, itr: 30, action=11, reward=0.0, q val=[[0.07458546]]\n",
            "at episode: 9, itr: 40, action=16, reward=0.0, q val=[[0.06314722]]\n",
            "at episode: 9, itr: 50, action=14, reward=0.0, q val=[[0.07601873]]\n",
            "at episode: 9, itr: 60, action=2, reward=0.0, q val=[[0.09401948]]\n",
            "at episode: 9, itr: 70, action=7, reward=0.0, q val=[[0.09773642]]\n",
            "at episode: 9, itr: 80, action=6, reward=0.0, q val=[[0.10502454]]\n",
            "at episode: 9, itr: 90, action=9, reward=0.0, q val=[[0.10922008]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0019\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0024\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0013\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0039\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 286us/step - loss: 0.0024\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0016\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0020\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0019\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0016\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0015\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 0.0021\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 0.0010\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 8.8432e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 7.3882e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 6.4924e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 5.4631e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 4.9668e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 4.5338e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 4.0294e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 10, itr: 0, action=12, reward=0.0, q val=[[0.10154304]]\n",
            "at episode: 10, itr: 10, action=10, reward=0.0, q val=[[0.01986333]]\n",
            "at episode: 10, itr: 20, action=1, reward=0.0, q val=[[0.05597422]]\n",
            "at episode: 10, itr: 30, action=14, reward=0.0, q val=[[0.08356638]]\n",
            "at episode: 10, itr: 40, action=14, reward=0.0, q val=[[0.08807545]]\n",
            "at episode: 10, itr: 50, action=6, reward=0.0, q val=[[0.09179124]]\n",
            "at episode: 10, itr: 60, action=9, reward=0.0, q val=[[0.09537093]]\n",
            "at episode: 10, itr: 70, action=18, reward=0.0, q val=[[0.09656361]]\n",
            "at episode: 10, itr: 80, action=13, reward=0.0, q val=[[0.11187627]]\n",
            "at episode: 10, itr: 90, action=3, reward=0.0, q val=[[0.12226348]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0043\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.0041\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0042\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0042\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0039\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0040\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.0039\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0036\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0036\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 278us/step - loss: 0.0035\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 181us/step - loss: 2.9324e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 2.4869e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 2.2255e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 2.4923e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 1.4239e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 1.5010e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 186us/step - loss: 1.3983e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 1.1835e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 1.5033e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 1.1152e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 11, itr: 0, action=3, reward=0.0, q val=[[0.12611833]]\n",
            "at episode: 11, itr: 10, action=8, reward=0.0, q val=[[0.06087405]]\n",
            "at episode: 11, itr: 20, action=17, reward=0.0, q val=[[0.05965709]]\n",
            "at episode: 11, itr: 30, action=14, reward=0.0, q val=[[-0.01186029]]\n",
            "at episode: 11, itr: 40, action=10, reward=0.0, q val=[[-0.03949243]]\n",
            "at episode: 11, itr: 50, action=16, reward=0.0, q val=[[-0.0732616]]\n",
            "at episode: 11, itr: 60, action=16, reward=0.0, q val=[[-0.1291474]]\n",
            "at episode: 11, itr: 70, action=11, reward=0.0, q val=[[-0.15668137]]\n",
            "at episode: 11, itr: 80, action=13, reward=0.0, q val=[[0.05435655]]\n",
            "at episode: 11, itr: 90, action=0, reward=0.0, q val=[[0.05964494]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0077\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.0077\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.0071\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0071\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0071\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.0067\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0077\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0073\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0070\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0070\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 0.0030\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0028\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0017\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0020\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 0.0015\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 9.3405e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 6.4205e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 7.7254e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 8.4690e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 7.2206e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 12, itr: 0, action=13, reward=0.0, q val=[[0.04662348]]\n",
            "at episode: 12, itr: 10, action=3, reward=0.0, q val=[[0.01291744]]\n",
            "at episode: 12, itr: 20, action=9, reward=0.0, q val=[[0.02572405]]\n",
            "at episode: 12, itr: 30, action=8, reward=0.0, q val=[[0.03114069]]\n",
            "at episode: 12, itr: 40, action=3, reward=0.0, q val=[[0.0329843]]\n",
            "at episode: 12, itr: 50, action=16, reward=0.0, q val=[[0.02906299]]\n",
            "at episode: 12, itr: 60, action=7, reward=0.0, q val=[[0.02330414]]\n",
            "at episode: 12, itr: 70, action=12, reward=0.0, q val=[[0.02024197]]\n",
            "at episode: 12, itr: 80, action=16, reward=0.0, q val=[[0.01897562]]\n",
            "at episode: 12, itr: 90, action=3, reward=0.0, q val=[[0.01787177]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 8.9151e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 254us/step - loss: 9.7722e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 9.3772e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 4.9503e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 7.5991e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0012\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 7.0176e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0018\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 290us/step - loss: 0.0025\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 1.7103e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 1.3586e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 9.9787e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 1.1226e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 5.8384e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 4.3819e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 3.5620e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 4.2093e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 2.4201e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 296us/step - loss: 1.8501e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 13, itr: 0, action=7, reward=0.0, q val=[[0.01799508]]\n",
            "at episode: 13, itr: 10, action=14, reward=0.0, q val=[[0.01662792]]\n",
            "at episode: 13, itr: 20, action=16, reward=0.0, q val=[[-0.05193334]]\n",
            "at episode: 13, itr: 30, action=7, reward=0.0, q val=[[-0.10649361]]\n",
            "at episode: 13, itr: 40, action=5, reward=0.0, q val=[[-0.10188505]]\n",
            "at episode: 13, itr: 50, action=12, reward=0.0, q val=[[-0.0519994]]\n",
            "at episode: 13, itr: 60, action=12, reward=0.0, q val=[[-0.03375717]]\n",
            "at episode: 13, itr: 70, action=6, reward=0.0, q val=[[-0.02587149]]\n",
            "at episode: 13, itr: 80, action=17, reward=0.0, q val=[[-0.00577435]]\n",
            "at episode: 13, itr: 90, action=2, reward=0.0, q val=[[-0.00116685]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 275us/step - loss: 0.0011\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 264us/step - loss: 9.9861e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 9.4782e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0012\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 6.9243e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0025\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0028\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0016\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0013\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 8.6328e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 7.7362e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 258us/step - loss: 5.8675e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 5.8263e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 5.6865e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 5.0495e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 323us/step - loss: 2.9710e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 273us/step - loss: 2.6745e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 2.2883e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 2.0324e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 14, itr: 0, action=16, reward=0.0, q val=[[0.00981748]]\n",
            "at episode: 14, itr: 10, action=7, reward=0.0, q val=[[-0.02812017]]\n",
            "at episode: 14, itr: 20, action=14, reward=0.0, q val=[[-0.05814683]]\n",
            "at episode: 14, itr: 30, action=11, reward=0.0, q val=[[-0.05991081]]\n",
            "at episode: 14, itr: 40, action=8, reward=0.0, q val=[[-0.07202009]]\n",
            "at episode: 14, itr: 50, action=6, reward=0.0, q val=[[-0.0927035]]\n",
            "at episode: 14, itr: 60, action=9, reward=0.0, q val=[[-0.10324334]]\n",
            "at episode: 14, itr: 70, action=14, reward=0.0, q val=[[-0.117388]]\n",
            "at episode: 14, itr: 80, action=8, reward=0.0, q val=[[-0.11680015]]\n",
            "at episode: 14, itr: 90, action=4, reward=0.0, q val=[[-0.11095607]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0124\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0116\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0116\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0113\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 274us/step - loss: 0.0113\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0110\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0111\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0103\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0101\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 320us/step - loss: 0.0105\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 3.1262e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 2.2507e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 2.0450e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 1.8594e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 1.0375e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 1.2219e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 8.5269e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 8.6694e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 5.2547e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 278us/step - loss: 4.2905e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 15, itr: 0, action=3, reward=0.0, q val=[[-0.0923528]]\n",
            "at episode: 15, itr: 10, action=7, reward=0.0, q val=[[-0.02721648]]\n",
            "at episode: 15, itr: 20, action=11, reward=0.0, q val=[[-0.01249046]]\n",
            "at episode: 15, itr: 30, action=13, reward=0.0, q val=[[-0.00286322]]\n",
            "at episode: 15, itr: 40, action=7, reward=0.0, q val=[[0.00642383]]\n",
            "at episode: 15, itr: 50, action=7, reward=0.0, q val=[[0.01622748]]\n",
            "at episode: 15, itr: 60, action=5, reward=0.0, q val=[[0.02607528]]\n",
            "at episode: 15, itr: 70, action=6, reward=0.0, q val=[[0.03446382]]\n",
            "at episode: 15, itr: 80, action=4, reward=0.0, q val=[[0.07080961]]\n",
            "at episode: 15, itr: 90, action=6, reward=0.0, q val=[[0.06798373]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 2.4281e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 8.3927e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0010\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0016\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 1.9609e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 8.8301e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 9.5636e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: -0.0012\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0019\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 2.7689e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 284us/step - loss: 1.3410e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 9.6311e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 8.1758e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 1.8166e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 265us/step - loss: 1.6152e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 1.2191e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 7.4129e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 5.2067e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 3.5732e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 16, itr: 0, action=18, reward=0.0, q val=[[0.06338713]]\n",
            "at episode: 16, itr: 10, action=7, reward=0.0, q val=[[-0.00710583]]\n",
            "at episode: 16, itr: 20, action=3, reward=0.0, q val=[[0.00461514]]\n",
            "at episode: 16, itr: 30, action=7, reward=0.0, q val=[[0.01137881]]\n",
            "at episode: 16, itr: 40, action=12, reward=0.0, q val=[[0.01972546]]\n",
            "at episode: 16, itr: 50, action=8, reward=0.0, q val=[[0.02995336]]\n",
            "at episode: 16, itr: 60, action=3, reward=0.0, q val=[[0.03994123]]\n",
            "at episode: 16, itr: 70, action=4, reward=0.0, q val=[[0.05730798]]\n",
            "at episode: 16, itr: 80, action=14, reward=0.0, q val=[[0.057257]]\n",
            "at episode: 16, itr: 90, action=7, reward=0.0, q val=[[0.05956942]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: -4.6060e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: -0.0010\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: -6.0397e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 268us/step - loss: -5.6261e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: -7.8638e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 1.9041e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: -8.5812e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: -9.1774e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: -0.0012\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 265us/step - loss: 3.5173e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 1.8055e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 1.0281e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 5.6050e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 4.6632e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 3.9916e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 1.0226e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 7.1091e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 4.7391e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 4.8493e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 4.5416e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 17, itr: 0, action=6, reward=0.0, q val=[[0.04318174]]\n",
            "at episode: 17, itr: 10, action=16, reward=0.0, q val=[[0.01273812]]\n",
            "at episode: 17, itr: 20, action=2, reward=0.0, q val=[[0.02212904]]\n",
            "at episode: 17, itr: 30, action=18, reward=0.0, q val=[[0.02827235]]\n",
            "at episode: 17, itr: 40, action=16, reward=0.0, q val=[[0.00981246]]\n",
            "at episode: 17, itr: 50, action=3, reward=0.0, q val=[[0.00149431]]\n",
            "at episode: 17, itr: 60, action=3, reward=0.0, q val=[[-0.00189349]]\n",
            "at episode: 17, itr: 70, action=8, reward=0.0, q val=[[-0.0041006]]\n",
            "at episode: 17, itr: 80, action=11, reward=0.0, q val=[[-0.0039558]]\n",
            "at episode: 17, itr: 90, action=14, reward=0.0, q val=[[-0.00447866]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 268us/step - loss: 0.0015\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.0010\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0014\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0019\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0012\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 9.1381e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0015\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 8.3443e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 8.2989e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 181us/step - loss: 7.8472e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 6.9634e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 6.7153e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 5.1866e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 3.8325e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 257us/step - loss: 3.2998e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 2.4078e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 2.5602e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 189us/step - loss: 2.7619e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 2.0139e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 18, itr: 0, action=6, reward=0.0, q val=[[-0.00183122]]\n",
            "at episode: 18, itr: 10, action=14, reward=0.0, q val=[[0.01545944]]\n",
            "at episode: 18, itr: 20, action=8, reward=0.0, q val=[[0.02971163]]\n",
            "at episode: 18, itr: 30, action=14, reward=0.0, q val=[[0.01564609]]\n",
            "at episode: 18, itr: 40, action=1, reward=0.0, q val=[[0.00980529]]\n",
            "at episode: 18, itr: 50, action=11, reward=0.0, q val=[[0.01577892]]\n",
            "at episode: 18, itr: 60, action=4, reward=0.0, q val=[[0.01490058]]\n",
            "at episode: 18, itr: 70, action=8, reward=0.0, q val=[[0.01556318]]\n",
            "at episode: 18, itr: 80, action=4, reward=0.0, q val=[[0.0158339]]\n",
            "at episode: 18, itr: 90, action=4, reward=0.0, q val=[[0.01366968]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 272us/step - loss: 2.1257e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 274us/step - loss: 4.0817e-06\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 3.0517e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: 7.5315e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 3.9580e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 4.4577e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 1.0537e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 6.7329e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: -1.1623e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: 4.3344e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 2.7500e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 192us/step - loss: 2.9395e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 2.5178e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 2.9964e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 3.0585e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 3.1100e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 2.6967e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 189us/step - loss: 3.1683e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 2.4280e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 2.5151e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 19, itr: 0, action=7, reward=0.0, q val=[[0.00973967]]\n",
            "at episode: 19, itr: 10, action=3, reward=0.0, q val=[[0.00853382]]\n",
            "at episode: 19, itr: 20, action=13, reward=0.0, q val=[[-0.06565201]]\n",
            "at episode: 19, itr: 30, action=14, reward=0.0, q val=[[-0.04314081]]\n",
            "at episode: 19, itr: 40, action=7, reward=0.0, q val=[[-0.02080836]]\n",
            "at episode: 19, itr: 50, action=6, reward=0.0, q val=[[0.00703835]]\n",
            "at episode: 19, itr: 60, action=4, reward=0.0, q val=[[-0.34312487]]\n",
            "at episode: 19, itr: 70, action=7, reward=0.0, q val=[[-0.3156087]]\n",
            "at episode: 19, itr: 80, action=13, reward=0.0, q val=[[0.00316903]]\n",
            "at episode: 19, itr: 90, action=6, reward=0.0, q val=[[0.0161515]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: -0.0076\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: -0.0112\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: -0.0205\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: -0.0222\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: -0.0226\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: -0.0234\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: -0.0250\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 306us/step - loss: -0.0248\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: -0.0256\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: -0.0250\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.0073\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 0.0042\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 0.0039\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0023\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 0.0012\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 185us/step - loss: 8.7260e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 178us/step - loss: 7.2212e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 7.5594e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 258us/step - loss: 6.7422e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 4.9190e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 20, itr: 0, action=13, reward=0.0, q val=[[0.01684099]]\n",
            "at episode: 20, itr: 10, action=7, reward=0.0, q val=[[-0.02541524]]\n",
            "at episode: 20, itr: 20, action=14, reward=0.0, q val=[[-0.00340273]]\n",
            "at episode: 20, itr: 30, action=6, reward=0.0, q val=[[-0.00681098]]\n",
            "at episode: 20, itr: 40, action=7, reward=0.0, q val=[[-0.01010228]]\n",
            "at episode: 20, itr: 50, action=7, reward=0.0, q val=[[-0.01443166]]\n",
            "at episode: 20, itr: 60, action=7, reward=0.0, q val=[[-0.01898566]]\n",
            "at episode: 20, itr: 70, action=13, reward=0.0, q val=[[-0.02337603]]\n",
            "at episode: 20, itr: 80, action=14, reward=0.0, q val=[[-0.02859065]]\n",
            "at episode: 20, itr: 90, action=14, reward=0.0, q val=[[-0.03127397]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 291us/step - loss: 2.9030e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 264us/step - loss: 0.0038\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.0035\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0017\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0016\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.0022\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0012\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 308us/step - loss: 0.0029\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.0029\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 1.1573e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 9.3134e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 6.4895e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 5.9297e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 5.5100e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 4.3411e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 3.7194e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 4.3820e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 3.7216e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 2.6346e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 21, itr: 0, action=2, reward=0.0, q val=[[-0.03608558]]\n",
            "at episode: 21, itr: 10, action=14, reward=0.0, q val=[[-0.04722548]]\n",
            "at episode: 21, itr: 20, action=14, reward=0.0, q val=[[-0.03193202]]\n",
            "at episode: 21, itr: 30, action=5, reward=0.0, q val=[[-0.04691555]]\n",
            "at episode: 21, itr: 40, action=16, reward=0.0, q val=[[-0.05429246]]\n",
            "at episode: 21, itr: 50, action=5, reward=0.0, q val=[[-0.0163311]]\n",
            "at episode: 21, itr: 60, action=2, reward=0.0, q val=[[-0.12715553]]\n",
            "at episode: 21, itr: 70, action=5, reward=0.0, q val=[[-0.0073403]]\n",
            "at episode: 21, itr: 80, action=6, reward=0.0, q val=[[-0.03158826]]\n",
            "at episode: 21, itr: 90, action=7, reward=0.0, q val=[[-0.01848116]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0015\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0020\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0045\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0043\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 257us/step - loss: 9.0573e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0011\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0010\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.0013\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 8.9173e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 7.6855e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 180us/step - loss: 6.2257e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 6.1791e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 8.8274e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 8.3722e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 5.3016e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 3.7332e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 252us/step - loss: 4.7297e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 4.6997e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 22, itr: 0, action=2, reward=0.0, q val=[[-0.03456126]]\n",
            "at episode: 22, itr: 10, action=3, reward=0.0, q val=[[-0.05693609]]\n",
            "at episode: 22, itr: 20, action=8, reward=0.0, q val=[[-0.06066444]]\n",
            "at episode: 22, itr: 30, action=1, reward=0.0, q val=[[-0.12105799]]\n",
            "at episode: 22, itr: 40, action=14, reward=0.0, q val=[[-0.03607993]]\n",
            "at episode: 22, itr: 50, action=4, reward=0.0, q val=[[-0.04127555]]\n",
            "at episode: 22, itr: 60, action=7, reward=0.0, q val=[[-0.04213131]]\n",
            "at episode: 22, itr: 70, action=3, reward=0.0, q val=[[-0.03475146]]\n",
            "at episode: 22, itr: 80, action=3, reward=0.0, q val=[[-0.0300154]]\n",
            "at episode: 22, itr: 90, action=2, reward=0.0, q val=[[-0.04237135]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: -1.0306e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 268us/step - loss: -7.7111e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 6.1627e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: -4.4668e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: -4.8930e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: -7.8213e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 6.5809e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0011\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 6.8726e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: -4.0746e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 189us/step - loss: 5.5524e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 4.3705e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 6.1830e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 2.3894e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 3.6243e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 189us/step - loss: 1.6093e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 1.3207e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 1.5591e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 1.0578e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 8.7932e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 23, itr: 0, action=3, reward=0.0, q val=[[-0.02831885]]\n",
            "at episode: 23, itr: 10, action=14, reward=0.0, q val=[[-0.03374069]]\n",
            "at episode: 23, itr: 20, action=14, reward=0.0, q val=[[-0.02881595]]\n",
            "at episode: 23, itr: 30, action=10, reward=0.0, q val=[[-0.02739219]]\n",
            "at episode: 23, itr: 40, action=7, reward=0.0, q val=[[-0.00999126]]\n",
            "at episode: 23, itr: 50, action=8, reward=0.0, q val=[[-0.00797885]]\n",
            "at episode: 23, itr: 60, action=17, reward=0.0, q val=[[-0.0065436]]\n",
            "at episode: 23, itr: 70, action=4, reward=0.0, q val=[[0.00075588]]\n",
            "at episode: 23, itr: 80, action=13, reward=0.0, q val=[[-0.0048332]]\n",
            "at episode: 23, itr: 90, action=11, reward=0.0, q val=[[-0.00459509]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: -5.4089e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 291us/step - loss: 1.7887e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 279us/step - loss: -4.1741e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: -4.5158e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 7.0789e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: -5.8020e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: -4.4359e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: -6.2157e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: -8.6217e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: -8.9841e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 7.5974e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 6.6480e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 186us/step - loss: 2.9918e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 4.1007e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 2.9794e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 1.2399e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 1.1869e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 187us/step - loss: 1.3922e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 8.7853e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 6.9220e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 24, itr: 0, action=4, reward=0.0, q val=[[-0.00696591]]\n",
            "at episode: 24, itr: 10, action=6, reward=0.0, q val=[[-0.02018436]]\n",
            "at episode: 24, itr: 20, action=14, reward=0.0, q val=[[-0.01169896]]\n",
            "at episode: 24, itr: 30, action=12, reward=0.0, q val=[[-0.00887978]]\n",
            "at episode: 24, itr: 40, action=17, reward=0.0, q val=[[-0.00622251]]\n",
            "at episode: 24, itr: 50, action=7, reward=0.0, q val=[[-0.00457331]]\n",
            "at episode: 24, itr: 60, action=6, reward=0.0, q val=[[-0.00287031]]\n",
            "at episode: 24, itr: 70, action=12, reward=0.0, q val=[[-0.00209225]]\n",
            "at episode: 24, itr: 80, action=5, reward=0.0, q val=[[-0.00565513]]\n",
            "at episode: 24, itr: 90, action=14, reward=0.0, q val=[[-0.00299839]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.0030\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.0026\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0027\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0029\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.0024\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.0022\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 274us/step - loss: 0.0019\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.0037\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.0028\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0027\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 2.2259e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 1.7398e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 277us/step - loss: 1.2437e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 1.0418e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 7.6871e-06\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 1.2335e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 8.1449e-06\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 183us/step - loss: 5.2587e-06\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 5.3290e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 4.9655e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 25, itr: 0, action=14, reward=0.0, q val=[[0.00553606]]\n",
            "at episode: 25, itr: 10, action=3, reward=0.0, q val=[[-0.01351808]]\n",
            "at episode: 25, itr: 20, action=17, reward=0.0, q val=[[-0.01208907]]\n",
            "at episode: 25, itr: 30, action=17, reward=0.0, q val=[[-0.01972235]]\n",
            "at episode: 25, itr: 40, action=2, reward=0.0, q val=[[-0.02468872]]\n",
            "at episode: 25, itr: 50, action=13, reward=0.0, q val=[[-0.01869809]]\n",
            "at episode: 25, itr: 60, action=7, reward=0.0, q val=[[-0.03186753]]\n",
            "at episode: 25, itr: 70, action=2, reward=0.0, q val=[[-0.02816097]]\n",
            "at episode: 25, itr: 80, action=3, reward=0.0, q val=[[-0.02225778]]\n",
            "at episode: 25, itr: 90, action=3, reward=0.0, q val=[[-0.02186848]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0019\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0015\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0012\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0018\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 276us/step - loss: 0.0010\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 262us/step - loss: 9.8031e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 7.3650e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 1.1651e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 2.2475e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 2.1099e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 289us/step - loss: 1.8403e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 1.9191e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 1.5212e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 1.3725e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 1.3730e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 1.6333e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 186us/step - loss: 1.7148e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 1.2849e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 26, itr: 0, action=13, reward=0.0, q val=[[-0.01977669]]\n",
            "at episode: 26, itr: 10, action=14, reward=0.0, q val=[[-0.0046946]]\n",
            "at episode: 26, itr: 20, action=13, reward=0.0, q val=[[0.00292366]]\n",
            "at episode: 26, itr: 30, action=17, reward=0.0, q val=[[0.00135442]]\n",
            "at episode: 26, itr: 40, action=16, reward=0.0, q val=[[-0.00065894]]\n",
            "at episode: 26, itr: 50, action=18, reward=0.0, q val=[[-0.00137711]]\n",
            "at episode: 26, itr: 60, action=12, reward=0.0, q val=[[-0.00112709]]\n",
            "at episode: 26, itr: 70, action=7, reward=0.0, q val=[[0.00402366]]\n",
            "at episode: 26, itr: 80, action=17, reward=0.0, q val=[[0.00976637]]\n",
            "at episode: 26, itr: 90, action=7, reward=0.0, q val=[[0.01029477]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0017\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0019\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 8.4502e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 9.4658e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: -4.4421e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0019\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 7.9153e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 6.3625e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 6.1719e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 7.3666e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 165us/step - loss: 1.7802e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 186us/step - loss: 1.7241e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 1.3070e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 1.3593e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 1.1169e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 1.0587e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 187us/step - loss: 1.4013e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 1.1045e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 8.1103e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 1.0044e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 27, itr: 0, action=12, reward=0.0, q val=[[0.01080835]]\n",
            "at episode: 27, itr: 10, action=5, reward=0.0, q val=[[0.00602687]]\n",
            "at episode: 27, itr: 20, action=7, reward=0.0, q val=[[0.0212684]]\n",
            "at episode: 27, itr: 30, action=11, reward=0.0, q val=[[0.02261451]]\n",
            "at episode: 27, itr: 40, action=2, reward=0.0, q val=[[0.02879149]]\n",
            "at episode: 27, itr: 50, action=1, reward=0.0, q val=[[-0.0051938]]\n",
            "at episode: 27, itr: 60, action=17, reward=0.0, q val=[[-0.00136236]]\n",
            "at episode: 27, itr: 70, action=1, reward=0.0, q val=[[0.0047549]]\n",
            "at episode: 27, itr: 80, action=6, reward=0.0, q val=[[-0.00788761]]\n",
            "at episode: 27, itr: 90, action=7, reward=0.0, q val=[[-0.03053267]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0090\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0090\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0089\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0084\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0086\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0077\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0083\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.0083\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 327us/step - loss: 0.0083\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0086\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 261us/step - loss: 1.6864e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 1.5673e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 1.5417e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 1.6866e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 1.7182e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 1.2080e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 8.2933e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 1.2595e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 1.0190e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 6.7151e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 28, itr: 0, action=18, reward=0.0, q val=[[-0.05790731]]\n",
            "at episode: 28, itr: 10, action=11, reward=0.0, q val=[[-0.01117195]]\n",
            "at episode: 28, itr: 20, action=6, reward=0.0, q val=[[-0.02077186]]\n",
            "at episode: 28, itr: 30, action=2, reward=0.0, q val=[[-0.03646344]]\n",
            "at episode: 28, itr: 40, action=6, reward=0.0, q val=[[-0.04435441]]\n",
            "at episode: 28, itr: 50, action=14, reward=0.0, q val=[[-0.01340229]]\n",
            "at episode: 28, itr: 60, action=7, reward=0.0, q val=[[-0.03201267]]\n",
            "at episode: 28, itr: 70, action=13, reward=0.0, q val=[[-0.03407585]]\n",
            "at episode: 28, itr: 80, action=17, reward=0.0, q val=[[-0.05269311]]\n",
            "at episode: 28, itr: 90, action=8, reward=0.0, q val=[[-0.03748136]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: -0.0148\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: -0.0154\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: -0.0155\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: -0.0161\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: -0.0151\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: -0.0156\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: -0.0155\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 298us/step - loss: -0.0167\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: -0.0168\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: -0.0172\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 323us/step - loss: 2.9980e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 2.3112e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 189us/step - loss: 1.7569e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 1.5450e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 1.2492e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 1.1237e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 7.6731e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 266us/step - loss: 1.5297e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 1.0392e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: 1.2366e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 29, itr: 0, action=16, reward=0.0, q val=[[-0.02243161]]\n",
            "at episode: 29, itr: 10, action=1, reward=0.0, q val=[[-0.02085686]]\n",
            "at episode: 29, itr: 20, action=17, reward=0.0, q val=[[-0.01409393]]\n",
            "at episode: 29, itr: 30, action=6, reward=0.0, q val=[[-0.0031613]]\n",
            "at episode: 29, itr: 40, action=14, reward=0.0, q val=[[-0.00664256]]\n",
            "at episode: 29, itr: 50, action=11, reward=0.0, q val=[[-0.01849676]]\n",
            "at episode: 29, itr: 60, action=6, reward=0.0, q val=[[-0.01581864]]\n",
            "at episode: 29, itr: 70, action=7, reward=0.0, q val=[[-0.02547909]]\n",
            "at episode: 29, itr: 80, action=4, reward=0.0, q val=[[-0.01878852]]\n",
            "at episode: 29, itr: 90, action=18, reward=0.0, q val=[[-0.0315]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: -3.6141e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 260us/step - loss: -3.8930e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 1.0059e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 292us/step - loss: -8.3068e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 7.3380e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.0021\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.0017\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 5.1886e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: -3.1441e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: -4.8881e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 5.4284e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 6.6416e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 9.2585e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 4.6854e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 196us/step - loss: 3.4492e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 2.3576e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 3.1483e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 2.6898e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 1.9874e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 1.6297e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 30, itr: 0, action=14, reward=0.0, q val=[[-0.04543363]]\n",
            "at episode: 30, itr: 10, action=16, reward=0.0, q val=[[-0.01590645]]\n",
            "at episode: 30, itr: 20, action=12, reward=0.0, q val=[[-0.01015067]]\n",
            "at episode: 30, itr: 30, action=3, reward=0.0, q val=[[-0.00560132]]\n",
            "at episode: 30, itr: 40, action=11, reward=0.0, q val=[[-0.01191498]]\n",
            "at episode: 30, itr: 50, action=6, reward=0.0, q val=[[-0.02343297]]\n",
            "at episode: 30, itr: 60, action=12, reward=0.0, q val=[[-0.02708849]]\n",
            "at episode: 30, itr: 70, action=17, reward=0.0, q val=[[-0.02772753]]\n",
            "at episode: 30, itr: 80, action=3, reward=0.0, q val=[[-0.04382915]]\n",
            "at episode: 30, itr: 90, action=11, reward=0.0, q val=[[-0.04665336]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0023\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0018\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0040\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0059\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0030\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 279us/step - loss: 0.0031\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0023\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0023\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 321us/step - loss: 0.0020\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0027\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 178us/step - loss: 5.7870e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 4.0500e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 4.8023e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 5.4825e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 4.6838e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 3.1792e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 2.0566e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 1.3690e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 2.0532e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 183us/step - loss: 1.6967e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 31, itr: 0, action=2, reward=0.0, q val=[[-0.04001408]]\n",
            "at episode: 31, itr: 10, action=9, reward=0.0, q val=[[-0.00526429]]\n",
            "at episode: 31, itr: 20, action=13, reward=0.0, q val=[[-0.0022708]]\n",
            "at episode: 31, itr: 30, action=16, reward=0.0, q val=[[-0.00360187]]\n",
            "at episode: 31, itr: 40, action=2, reward=0.0, q val=[[-0.00674626]]\n",
            "at episode: 31, itr: 50, action=13, reward=0.0, q val=[[-0.00955457]]\n",
            "at episode: 31, itr: 60, action=3, reward=0.0, q val=[[-0.01557154]]\n",
            "at episode: 31, itr: 70, action=16, reward=0.0, q val=[[-0.02101869]]\n",
            "at episode: 31, itr: 80, action=14, reward=0.0, q val=[[-0.02572612]]\n",
            "at episode: 31, itr: 90, action=2, reward=0.0, q val=[[-0.02861659]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 292us/step - loss: -8.1725e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 4.8506e-06\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0019\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 1.8476e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: -7.6994e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: -6.7438e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 252us/step - loss: -8.2879e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: -8.9626e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: -6.9505e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: -7.3918e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 2.9150e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 3.4420e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 176us/step - loss: 1.6314e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 1.7381e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 185us/step - loss: 1.3536e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 187us/step - loss: 1.2586e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 7.9008e-06\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 1.0060e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 186us/step - loss: 9.0743e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 5.4972e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 32, itr: 0, action=5, reward=0.0, q val=[[-0.02660957]]\n",
            "at episode: 32, itr: 10, action=6, reward=0.0, q val=[[-0.00095517]]\n",
            "at episode: 32, itr: 20, action=4, reward=0.0, q val=[[-0.00448397]]\n",
            "at episode: 32, itr: 30, action=14, reward=0.0, q val=[[-0.01276312]]\n",
            "at episode: 32, itr: 40, action=2, reward=0.0, q val=[[-0.02001639]]\n",
            "at episode: 32, itr: 50, action=10, reward=0.0, q val=[[-0.0237785]]\n",
            "at episode: 32, itr: 60, action=2, reward=0.0, q val=[[-0.02628433]]\n",
            "at episode: 32, itr: 70, action=12, reward=0.0, q val=[[-0.02992383]]\n",
            "at episode: 32, itr: 80, action=4, reward=0.0, q val=[[-0.03189876]]\n",
            "at episode: 32, itr: 90, action=2, reward=0.0, q val=[[-0.03259333]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: -2.8703e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 258us/step - loss: -3.4241e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: -4.3228e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 250us/step - loss: -3.9784e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: -7.2273e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: -6.6112e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: -7.8042e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: -9.5305e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: -9.1254e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 320us/step - loss: -8.8351e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 2.9061e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 190us/step - loss: 2.4639e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 2.0260e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 189us/step - loss: 2.6151e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 180us/step - loss: 2.0675e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 1.2892e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 1.5884e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 189us/step - loss: 1.6691e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 1.4772e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 190us/step - loss: 2.0901e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 33, itr: 0, action=1, reward=0.0, q val=[[-0.02903031]]\n",
            "at episode: 33, itr: 10, action=12, reward=0.0, q val=[[-0.00355964]]\n",
            "at episode: 33, itr: 20, action=8, reward=0.0, q val=[[-0.01115719]]\n",
            "at episode: 33, itr: 30, action=1, reward=0.0, q val=[[-0.0161914]]\n",
            "at episode: 33, itr: 40, action=16, reward=0.0, q val=[[-0.02127859]]\n",
            "at episode: 33, itr: 50, action=12, reward=0.0, q val=[[-0.0235332]]\n",
            "at episode: 33, itr: 60, action=11, reward=0.0, q val=[[-0.02153255]]\n",
            "at episode: 33, itr: 70, action=2, reward=0.0, q val=[[-0.01973872]]\n",
            "at episode: 33, itr: 80, action=8, reward=0.0, q val=[[-0.02011356]]\n",
            "at episode: 33, itr: 90, action=13, reward=0.0, q val=[[-0.01866627]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 1.2802e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 2.4158e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: -3.8136e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: -3.3252e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: -3.8613e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: -3.4080e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: -2.8212e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: -2.5071e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 273us/step - loss: -4.6298e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: -6.6038e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 2.5825e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 2.0155e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 1.5949e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 1.4072e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 3.6171e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 2.1914e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 1.4373e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 1.0852e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 181us/step - loss: 9.1865e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 7.4190e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 34, itr: 0, action=5, reward=0.0, q val=[[-0.01552989]]\n",
            "at episode: 34, itr: 10, action=14, reward=0.0, q val=[[-0.00615196]]\n",
            "at episode: 34, itr: 20, action=2, reward=0.0, q val=[[-0.01340058]]\n",
            "at episode: 34, itr: 30, action=3, reward=0.0, q val=[[-0.01067629]]\n",
            "at episode: 34, itr: 40, action=5, reward=0.0, q val=[[-0.01469727]]\n",
            "at episode: 34, itr: 50, action=5, reward=0.0, q val=[[0.00063703]]\n",
            "at episode: 34, itr: 60, action=10, reward=0.0, q val=[[0.00424655]]\n",
            "at episode: 34, itr: 70, action=3, reward=0.0, q val=[[0.06143912]]\n",
            "at episode: 34, itr: 80, action=3, reward=0.0, q val=[[-0.00788039]]\n",
            "at episode: 34, itr: 90, action=3, reward=0.0, q val=[[-0.0085018]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 254us/step - loss: -0.0014\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: -0.0013\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 287us/step - loss: -0.0011\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: -0.0011\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 304us/step - loss: -0.0014\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 294us/step - loss: -0.0014\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 265us/step - loss: -0.0014\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: -0.0015\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: -0.0018\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 250us/step - loss: -0.0015\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 192us/step - loss: 9.5394e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 8.9079e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 6.4964e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 5.7006e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 3.1891e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 2.6411e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 2.2273e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 267us/step - loss: 2.5925e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 259us/step - loss: 1.8568e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 2.2522e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 35, itr: 0, action=14, reward=0.0, q val=[[-0.02011708]]\n",
            "at episode: 35, itr: 10, action=11, reward=0.0, q val=[[-0.00869343]]\n",
            "at episode: 35, itr: 20, action=12, reward=0.0, q val=[[-0.01289658]]\n",
            "at episode: 35, itr: 30, action=16, reward=0.0, q val=[[-0.00675835]]\n",
            "at episode: 35, itr: 40, action=6, reward=0.0, q val=[[-0.02078623]]\n",
            "at episode: 35, itr: 50, action=11, reward=0.0, q val=[[-0.02188741]]\n",
            "at episode: 35, itr: 60, action=1, reward=0.0, q val=[[-0.01973673]]\n",
            "at episode: 35, itr: 70, action=13, reward=0.0, q val=[[-0.01396955]]\n",
            "at episode: 35, itr: 80, action=17, reward=0.0, q val=[[-0.00494473]]\n",
            "at episode: 35, itr: 90, action=1, reward=0.0, q val=[[4.085357e-05]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: -5.7220e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: -6.9921e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: -7.1388e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: -0.0012\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: -3.3038e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: -0.0011\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: -0.0014\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: -9.3399e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: -5.9512e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 281us/step - loss: -0.0013\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 4.8545e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 4.3310e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 2.6339e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 2.3758e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 1.9334e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 1.9200e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 1.3674e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 1.4273e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 1.4264e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 1.1690e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 36, itr: 0, action=2, reward=0.0, q val=[[-0.01131745]]\n",
            "at episode: 36, itr: 10, action=4, reward=0.0, q val=[[-0.01893047]]\n",
            "at episode: 36, itr: 20, action=11, reward=0.0, q val=[[-0.01360594]]\n",
            "at episode: 36, itr: 30, action=11, reward=0.0, q val=[[-0.01157958]]\n",
            "at episode: 36, itr: 40, action=12, reward=0.0, q val=[[-0.01348401]]\n",
            "at episode: 36, itr: 50, action=10, reward=0.0, q val=[[-0.01294595]]\n",
            "at episode: 36, itr: 60, action=16, reward=0.0, q val=[[-0.01197529]]\n",
            "at episode: 36, itr: 70, action=7, reward=0.0, q val=[[-0.0065752]]\n",
            "at episode: 36, itr: 80, action=10, reward=0.0, q val=[[-0.00218885]]\n",
            "at episode: 36, itr: 90, action=4, reward=0.0, q val=[[0.00087661]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: 3.4234e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 9.9273e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0015\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 268us/step - loss: 0.0012\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.0011\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 9.4814e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 9.3265e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 4.8943e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 5.6039e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 270us/step - loss: 3.7800e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 1.7334e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 1.1268e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 6.1302e-06\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 5.4683e-06\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 4.9186e-06\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 4.4910e-06\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 9.1084e-06\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 263us/step - loss: 6.5909e-06\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 4.2349e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 2.6771e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 37, itr: 0, action=5, reward=0.0, q val=[[0.0119191]]\n",
            "at episode: 37, itr: 10, action=16, reward=0.0, q val=[[-0.01397897]]\n",
            "at episode: 37, itr: 20, action=13, reward=0.0, q val=[[-0.00359057]]\n",
            "at episode: 37, itr: 30, action=4, reward=0.0, q val=[[-0.00571171]]\n",
            "at episode: 37, itr: 40, action=1, reward=0.0, q val=[[-0.01069043]]\n",
            "at episode: 37, itr: 50, action=1, reward=0.0, q val=[[-0.09106186]]\n",
            "at episode: 37, itr: 60, action=14, reward=0.0, q val=[[-0.05464466]]\n",
            "at episode: 37, itr: 70, action=5, reward=0.0, q val=[[-0.01461757]]\n",
            "at episode: 37, itr: 80, action=14, reward=0.0, q val=[[-0.00423368]]\n",
            "at episode: 37, itr: 90, action=8, reward=0.0, q val=[[-0.00067712]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: -0.0032\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: -0.0062\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 257us/step - loss: -0.0050\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 297us/step - loss: -0.0038\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: -0.0051\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: -0.0060\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: -0.0073\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: -0.0085\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: -0.0074\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 252us/step - loss: -0.0076\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 9.1114e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0018\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 0.0018\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 8.4211e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 3.9757e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 9.6181e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 4.3852e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 8.1187e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 6.7255e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 2.8193e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 38, itr: 0, action=18, reward=0.0, q val=[[-0.01350216]]\n",
            "at episode: 38, itr: 10, action=6, reward=0.0, q val=[[-0.01489216]]\n",
            "at episode: 38, itr: 20, action=1, reward=0.0, q val=[[-0.00255192]]\n",
            "at episode: 38, itr: 30, action=8, reward=0.0, q val=[[-0.00434537]]\n",
            "at episode: 38, itr: 40, action=7, reward=0.0, q val=[[0.01158046]]\n",
            "at episode: 38, itr: 50, action=17, reward=0.0, q val=[[0.00961322]]\n",
            "at episode: 38, itr: 60, action=15, reward=0.0, q val=[[0.00754297]]\n",
            "at episode: 38, itr: 70, action=14, reward=0.0, q val=[[-0.00324195]]\n",
            "at episode: 38, itr: 80, action=2, reward=0.0, q val=[[-0.00620108]]\n",
            "at episode: 38, itr: 90, action=11, reward=0.0, q val=[[-0.00988069]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: -0.0011\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: -4.1121e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: -5.3412e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 250us/step - loss: -3.5666e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: -7.7929e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: -0.0011\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: -0.0012\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: -0.0012\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 271us/step - loss: -0.0011\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: -0.0012\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 5.9117e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 4.5803e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 4.3591e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 4.2619e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: 4.2513e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 3.4485e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 289us/step - loss: 4.3349e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 2.7473e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 3.0996e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 287us/step - loss: 2.1525e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 39, itr: 0, action=12, reward=0.0, q val=[[-0.01118102]]\n",
            "at episode: 39, itr: 10, action=14, reward=0.0, q val=[[-1.4596357e-05]]\n",
            "at episode: 39, itr: 20, action=3, reward=0.0, q val=[[-0.00149141]]\n",
            "at episode: 39, itr: 30, action=12, reward=0.0, q val=[[-0.00136149]]\n",
            "at episode: 39, itr: 40, action=17, reward=0.0, q val=[[0.00066857]]\n",
            "at episode: 39, itr: 50, action=3, reward=0.0, q val=[[-0.00037028]]\n",
            "at episode: 39, itr: 60, action=2, reward=0.0, q val=[[-0.0034856]]\n",
            "at episode: 39, itr: 70, action=16, reward=0.0, q val=[[-0.00554485]]\n",
            "at episode: 39, itr: 80, action=17, reward=0.0, q val=[[-0.00722155]]\n",
            "at episode: 39, itr: 90, action=16, reward=0.0, q val=[[-0.00661501]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 1.4290e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 304us/step - loss: 1.4211e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 2.1772e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 5.1692e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 6.2667e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 6.6108e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 302us/step - loss: -5.6366e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 254us/step - loss: 3.2909e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 2.4797e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 1.4211e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 1.5032e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 9.0531e-06\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 1.3918e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 7.7701e-06\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 6.3521e-06\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 2.2574e-06\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 2.1928e-06\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 257us/step - loss: 3.0890e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 3.4826e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 40, itr: 0, action=13, reward=0.0, q val=[[-0.00938658]]\n",
            "at episode: 40, itr: 10, action=11, reward=0.0, q val=[[0.00133723]]\n",
            "at episode: 40, itr: 20, action=11, reward=0.0, q val=[[0.00261066]]\n",
            "at episode: 40, itr: 30, action=16, reward=0.0, q val=[[0.00129221]]\n",
            "at episode: 40, itr: 40, action=9, reward=0.0, q val=[[0.0020938]]\n",
            "at episode: 40, itr: 50, action=1, reward=0.0, q val=[[-0.0024163]]\n",
            "at episode: 40, itr: 60, action=1, reward=0.0, q val=[[-0.00171173]]\n",
            "at episode: 40, itr: 70, action=12, reward=0.0, q val=[[0.0102539]]\n",
            "at episode: 40, itr: 80, action=3, reward=0.0, q val=[[0.02962311]]\n",
            "at episode: 40, itr: 90, action=8, reward=0.0, q val=[[0.02852677]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 2.5002e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 2.1680e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 1.2940e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 4.1520e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 6.3241e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 1.3477e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 5.8887e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 3.1972e-06\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0019\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 323us/step - loss: 5.8765e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 5.9148e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 3.7872e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 2.6962e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 2.2537e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 1.3335e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 1.0743e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 9.5194e-06\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 174us/step - loss: 9.2460e-06\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 187us/step - loss: 8.7532e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 8.1544e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 41, itr: 0, action=6, reward=0.0, q val=[[0.03181435]]\n",
            "at episode: 41, itr: 10, action=7, reward=0.0, q val=[[0.0069941]]\n",
            "at episode: 41, itr: 20, action=5, reward=0.0, q val=[[0.00896493]]\n",
            "at episode: 41, itr: 30, action=1, reward=0.0, q val=[[0.01244313]]\n",
            "at episode: 41, itr: 40, action=5, reward=0.0, q val=[[0.01767099]]\n",
            "at episode: 41, itr: 50, action=1, reward=0.0, q val=[[0.01731271]]\n",
            "at episode: 41, itr: 60, action=17, reward=0.0, q val=[[-0.00090088]]\n",
            "at episode: 41, itr: 70, action=16, reward=0.0, q val=[[0.02406175]]\n",
            "at episode: 41, itr: 80, action=6, reward=0.0, q val=[[-0.00083079]]\n",
            "at episode: 41, itr: 90, action=14, reward=0.0, q val=[[-0.0020094]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0027\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.0023\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.0020\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.0018\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 315us/step - loss: 0.0016\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0016\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0016\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0018\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0016\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0014\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 1.3482e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 1.1532e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 8.4846e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 5.5014e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: 3.4081e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 3.0203e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 2.3022e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 2.1718e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 4.4510e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 2.5294e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 42, itr: 0, action=8, reward=0.0, q val=[[0.00443652]]\n",
            "at episode: 42, itr: 10, action=8, reward=0.0, q val=[[0.01357055]]\n",
            "at episode: 42, itr: 20, action=13, reward=0.0, q val=[[0.01321044]]\n",
            "at episode: 42, itr: 30, action=8, reward=0.0, q val=[[0.00331125]]\n",
            "at episode: 42, itr: 40, action=11, reward=0.0, q val=[[-0.01957331]]\n",
            "at episode: 42, itr: 50, action=7, reward=0.0, q val=[[-0.01816102]]\n",
            "at episode: 42, itr: 60, action=3, reward=0.0, q val=[[-0.01067645]]\n",
            "at episode: 42, itr: 70, action=4, reward=0.0, q val=[[6.974125e-05]]\n",
            "at episode: 42, itr: 80, action=7, reward=0.0, q val=[[-0.02405175]]\n",
            "at episode: 42, itr: 90, action=17, reward=0.0, q val=[[-0.00363866]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: -0.0015\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: -0.0015\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: -0.0014\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: -7.0464e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: -4.6524e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: -0.0014\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 293us/step - loss: -0.0015\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: -0.0015\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: -0.0017\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: -0.0010\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 7.1980e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 5.5602e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 4.3723e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 4.5133e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 185us/step - loss: 3.2569e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 3.6407e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 4.1280e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 5.6227e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 4.1409e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 2.8646e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 43, itr: 0, action=1, reward=0.0, q val=[[-0.00445657]]\n",
            "at episode: 43, itr: 10, action=1, reward=0.0, q val=[[-0.00207137]]\n",
            "at episode: 43, itr: 20, action=5, reward=0.0, q val=[[0.00533196]]\n",
            "at episode: 43, itr: 30, action=13, reward=0.0, q val=[[0.01202375]]\n",
            "at episode: 43, itr: 40, action=1, reward=0.0, q val=[[0.00432037]]\n",
            "at episode: 43, itr: 50, action=4, reward=0.0, q val=[[0.00704486]]\n",
            "at episode: 43, itr: 60, action=4, reward=0.0, q val=[[0.00710666]]\n",
            "at episode: 43, itr: 70, action=6, reward=0.0, q val=[[0.00770224]]\n",
            "at episode: 43, itr: 80, action=3, reward=0.0, q val=[[0.00607659]]\n",
            "at episode: 43, itr: 90, action=3, reward=0.0, q val=[[0.00678106]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 6.6840e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0015\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0019\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.0017\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0012\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 3.4586e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 5.5531e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0012\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 286us/step - loss: 0.0012\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 1.1645e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 1.1235e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 1.1266e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: 3.7932e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 1.5679e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 2.0199e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 9.5882e-06\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 1.1221e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 273us/step - loss: 1.1265e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 7.0321e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 44, itr: 0, action=5, reward=0.0, q val=[[0.00046915]]\n",
            "at episode: 44, itr: 10, action=11, reward=0.0, q val=[[0.00332199]]\n",
            "at episode: 44, itr: 20, action=4, reward=0.0, q val=[[0.00057219]]\n",
            "at episode: 44, itr: 30, action=16, reward=0.0, q val=[[-0.01622569]]\n",
            "at episode: 44, itr: 40, action=8, reward=0.0, q val=[[-0.01912326]]\n",
            "at episode: 44, itr: 50, action=8, reward=0.0, q val=[[0.00116906]]\n",
            "at episode: 44, itr: 60, action=13, reward=0.0, q val=[[-0.00533751]]\n",
            "at episode: 44, itr: 70, action=1, reward=0.0, q val=[[-0.00665671]]\n",
            "at episode: 44, itr: 80, action=14, reward=0.0, q val=[[-0.05156659]]\n",
            "at episode: 44, itr: 90, action=3, reward=0.0, q val=[[-0.03748159]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0069\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0075\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0069\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0073\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 295us/step - loss: 0.0077\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0066\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 280us/step - loss: 0.0065\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0069\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.0066\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0071\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 0.0748\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0726\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 0.0930\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 0.0587\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 0.0540\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 0.0485\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0452\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 0.0539\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 0.0618\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 180us/step - loss: 0.0523\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 45, itr: 0, action=4, reward=0.0, q val=[[-0.11838229]]\n",
            "at episode: 45, itr: 10, action=10, reward=0.0, q val=[[-0.07606979]]\n",
            "at episode: 45, itr: 20, action=4, reward=0.0, q val=[[-0.07313953]]\n",
            "at episode: 45, itr: 30, action=8, reward=0.0, q val=[[-0.04172959]]\n",
            "at episode: 45, itr: 40, action=3, reward=0.0, q val=[[-0.0196736]]\n",
            "at episode: 45, itr: 50, action=6, reward=0.0, q val=[[-0.02462324]]\n",
            "at episode: 45, itr: 60, action=2, reward=0.0, q val=[[-0.03211325]]\n",
            "at episode: 45, itr: 70, action=16, reward=0.0, q val=[[-0.04488024]]\n",
            "at episode: 45, itr: 80, action=12, reward=0.0, q val=[[-0.05951916]]\n",
            "at episode: 45, itr: 90, action=3, reward=0.0, q val=[[-0.0729847]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.0027\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.0017\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0015\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0018\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0019\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0014\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0015\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.0017\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0013\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 0.0076\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 187us/step - loss: 0.0064\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0038\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 0.0028\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0021\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 6.8610e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 5.4409e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 4.1867e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 2.2417e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 46, itr: 0, action=1, reward=0.0, q val=[[-0.08775532]]\n",
            "at episode: 46, itr: 10, action=5, reward=0.0, q val=[[-0.35936043]]\n",
            "at episode: 46, itr: 20, action=2, reward=0.0, q val=[[-0.44133505]]\n",
            "at episode: 46, itr: 30, action=16, reward=0.0, q val=[[-0.45189553]]\n",
            "at episode: 46, itr: 40, action=7, reward=0.0, q val=[[-0.29514083]]\n",
            "at episode: 46, itr: 50, action=11, reward=0.0, q val=[[-0.24772517]]\n",
            "at episode: 46, itr: 60, action=12, reward=0.0, q val=[[-0.41497663]]\n",
            "at episode: 46, itr: 70, action=6, reward=0.0, q val=[[-0.03848789]]\n",
            "at episode: 46, itr: 80, action=14, reward=0.0, q val=[[-0.02863633]]\n",
            "at episode: 46, itr: 90, action=1, reward=0.0, q val=[[-0.01120402]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0437\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0438\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0432\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0433\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0434\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0431\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0431\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.0429\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0425\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0432\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 0.0198\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 182us/step - loss: 0.0167\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.0098\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 0.0076\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0071\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0066\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 0.0047\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0047\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0046\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0054\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 47, itr: 0, action=13, reward=0.0, q val=[[-0.02322713]]\n",
            "at episode: 47, itr: 10, action=17, reward=0.0, q val=[[-0.24569549]]\n",
            "at episode: 47, itr: 20, action=14, reward=0.0, q val=[[-0.2747953]]\n",
            "at episode: 47, itr: 30, action=8, reward=0.0, q val=[[-0.2928709]]\n",
            "at episode: 47, itr: 40, action=5, reward=0.0, q val=[[-0.32364693]]\n",
            "at episode: 47, itr: 50, action=7, reward=0.0, q val=[[-0.26491198]]\n",
            "at episode: 47, itr: 60, action=2, reward=0.0, q val=[[-0.26990563]]\n",
            "at episode: 47, itr: 70, action=7, reward=0.0, q val=[[-0.09275611]]\n",
            "at episode: 47, itr: 80, action=6, reward=0.0, q val=[[-0.26573953]]\n",
            "at episode: 47, itr: 90, action=5, reward=0.0, q val=[[-0.28284883]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0405\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0401\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0402\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 344us/step - loss: 0.0398\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0399\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0407\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0403\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0394\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.0405\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.0395\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 0.0117\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0106\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 0.0071\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0035\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 196us/step - loss: 0.0028\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 0.0024\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0020\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 0.0017\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0020\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0019\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 48, itr: 0, action=7, reward=0.0, q val=[[-0.24305446]]\n",
            "at episode: 48, itr: 10, action=4, reward=0.0, q val=[[-0.07988166]]\n",
            "at episode: 48, itr: 20, action=16, reward=0.0, q val=[[-0.21235083]]\n",
            "at episode: 48, itr: 30, action=6, reward=0.0, q val=[[-0.1811665]]\n",
            "at episode: 48, itr: 40, action=6, reward=0.0, q val=[[-0.2581927]]\n",
            "at episode: 48, itr: 50, action=2, reward=0.0, q val=[[-0.1515742]]\n",
            "at episode: 48, itr: 60, action=4, reward=0.0, q val=[[-0.19655968]]\n",
            "at episode: 48, itr: 70, action=16, reward=0.0, q val=[[-0.25070077]]\n",
            "at episode: 48, itr: 80, action=8, reward=0.0, q val=[[-0.26559633]]\n",
            "at episode: 48, itr: 90, action=4, reward=0.0, q val=[[-0.2732817]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0206\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.0207\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.0207\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.0212\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 285us/step - loss: 0.0212\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.0213\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0219\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.0203\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0204\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.0204\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 0.0084\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.0063\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 0.0052\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0039\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 0.0028\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0018\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0019\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 0.0014\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0020\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 0.0020\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 49, itr: 0, action=16, reward=0.0, q val=[[-0.12431498]]\n",
            "at episode: 49, itr: 10, action=9, reward=0.0, q val=[[-0.12125594]]\n",
            "at episode: 49, itr: 20, action=10, reward=0.0, q val=[[-0.17816885]]\n",
            "at episode: 49, itr: 30, action=16, reward=0.0, q val=[[-0.16720437]]\n",
            "at episode: 49, itr: 40, action=16, reward=0.0, q val=[[-0.17444989]]\n",
            "at episode: 49, itr: 50, action=11, reward=0.0, q val=[[-0.15481459]]\n",
            "at episode: 49, itr: 60, action=5, reward=0.0, q val=[[-0.16117008]]\n",
            "at episode: 49, itr: 70, action=17, reward=0.0, q val=[[-0.16349085]]\n",
            "at episode: 49, itr: 80, action=8, reward=0.0, q val=[[-0.12439413]]\n",
            "at episode: 49, itr: 90, action=3, reward=0.0, q val=[[-0.11055927]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.0142\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.0134\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.0131\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.0135\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.0127\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.0140\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0132\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0126\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0135\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.0121\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 0.0033\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 0.0019\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0014\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 0.0011\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 7.0722e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 0.0010\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 9.6970e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 176us/step - loss: 6.0851e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 4.6455e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 50, itr: 0, action=3, reward=0.0, q val=[[-0.07159505]]\n",
            "at episode: 50, itr: 10, action=15, reward=0.0, q val=[[-0.10834555]]\n",
            "at episode: 50, itr: 20, action=11, reward=0.0, q val=[[-0.09724101]]\n",
            "at episode: 50, itr: 30, action=16, reward=0.0, q val=[[-0.12445439]]\n",
            "at episode: 50, itr: 40, action=12, reward=0.0, q val=[[-0.09926779]]\n",
            "at episode: 50, itr: 50, action=6, reward=0.0, q val=[[0.0084253]]\n",
            "at episode: 50, itr: 60, action=6, reward=0.0, q val=[[-0.09564929]]\n",
            "at episode: 50, itr: 70, action=14, reward=0.0, q val=[[-0.13321826]]\n",
            "at episode: 50, itr: 80, action=3, reward=0.0, q val=[[-0.13301021]]\n",
            "at episode: 50, itr: 90, action=2, reward=0.0, q val=[[-0.09170341]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0029\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.0013\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.0017\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.0011\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: 9.8230e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: -4.5924e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: -0.0017\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: -0.0019\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: -0.0021\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 0.0029\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 169us/step - loss: 0.0015\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 192us/step - loss: 0.0034\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 0.0021\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.0017\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0023\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 0.0021\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0015\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0016\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 51, itr: 0, action=5, reward=0.0, q val=[[-0.05865084]]\n",
            "at episode: 51, itr: 10, action=3, reward=0.0, q val=[[-0.08519871]]\n",
            "at episode: 51, itr: 20, action=12, reward=0.0, q val=[[-0.05447616]]\n",
            "at episode: 51, itr: 30, action=6, reward=0.0, q val=[[-0.06899799]]\n",
            "at episode: 51, itr: 40, action=8, reward=0.0, q val=[[-0.03732426]]\n",
            "at episode: 51, itr: 50, action=12, reward=0.0, q val=[[-0.03147242]]\n",
            "at episode: 51, itr: 60, action=1, reward=0.0, q val=[[-0.03498303]]\n",
            "at episode: 51, itr: 70, action=8, reward=0.0, q val=[[-0.03391305]]\n",
            "at episode: 51, itr: 80, action=11, reward=0.0, q val=[[-0.03087336]]\n",
            "at episode: 51, itr: 90, action=2, reward=0.0, q val=[[-0.02635401]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: -0.0065\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: -0.0072\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: -0.0072\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: -0.0066\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: -0.0070\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: -0.0075\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: -0.0068\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 273us/step - loss: -0.0081\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: -0.0075\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: -0.0075\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 4.1226e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 2.4600e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 3.1075e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 2.6223e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 1.7509e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 9.8084e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 5.1899e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 3.1479e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 2.4955e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 2.8325e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 52, itr: 0, action=11, reward=0.0, q val=[[-0.01201882]]\n",
            "at episode: 52, itr: 10, action=2, reward=0.0, q val=[[-0.03955646]]\n",
            "at episode: 52, itr: 20, action=2, reward=0.0, q val=[[-0.0352631]]\n",
            "at episode: 52, itr: 30, action=2, reward=0.0, q val=[[-0.01150223]]\n",
            "at episode: 52, itr: 40, action=14, reward=0.0, q val=[[-0.0129065]]\n",
            "at episode: 52, itr: 50, action=16, reward=0.0, q val=[[-0.01219366]]\n",
            "at episode: 52, itr: 60, action=18, reward=0.0, q val=[[-0.01158419]]\n",
            "at episode: 52, itr: 70, action=8, reward=0.0, q val=[[-0.01220161]]\n",
            "at episode: 52, itr: 80, action=2, reward=0.0, q val=[[-0.03133553]]\n",
            "at episode: 52, itr: 90, action=12, reward=0.0, q val=[[-0.01629829]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 6.1216e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 3.4320e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 3.5179e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 263us/step - loss: 3.1424e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 3.2380e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 6.1666e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 266us/step - loss: 2.8305e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: 2.7721e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 280us/step - loss: -1.2358e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: -4.1985e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 1.2640e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 1.0557e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 5.7255e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 4.6272e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 4.5840e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 271us/step - loss: 3.2965e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 3.1438e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 3.0573e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 192us/step - loss: 2.6789e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 2.2527e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 53, itr: 0, action=4, reward=0.0, q val=[[-0.0392735]]\n",
            "at episode: 53, itr: 10, action=8, reward=0.0, q val=[[-0.01845334]]\n",
            "at episode: 53, itr: 20, action=3, reward=0.0, q val=[[-0.01257932]]\n",
            "at episode: 53, itr: 30, action=11, reward=0.0, q val=[[-0.01233663]]\n",
            "at episode: 53, itr: 40, action=8, reward=0.0, q val=[[-0.00964583]]\n",
            "at episode: 53, itr: 50, action=12, reward=0.0, q val=[[-0.01477791]]\n",
            "at episode: 53, itr: 60, action=6, reward=0.0, q val=[[-0.0080509]]\n",
            "at episode: 53, itr: 70, action=6, reward=0.0, q val=[[-0.01531465]]\n",
            "at episode: 53, itr: 80, action=16, reward=0.0, q val=[[-0.01531865]]\n",
            "at episode: 53, itr: 90, action=2, reward=0.0, q val=[[-0.00887135]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 3.2873e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 3.9124e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 2.8298e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0010\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 2.8918e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 261us/step - loss: 1.6363e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 2.3620e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0011\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 289us/step - loss: 9.2768e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 5.1957e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 183us/step - loss: 1.4606e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 1.0622e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 179us/step - loss: 8.8372e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 192us/step - loss: 6.7251e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 5.9624e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 190us/step - loss: 4.9852e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 6.5421e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 6.1708e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 5.6451e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 6.3011e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 54, itr: 0, action=1, reward=0.0, q val=[[-0.00584851]]\n",
            "at episode: 54, itr: 10, action=1, reward=0.0, q val=[[-0.01162721]]\n",
            "at episode: 54, itr: 20, action=6, reward=0.0, q val=[[0.0002211]]\n",
            "at episode: 54, itr: 30, action=1, reward=0.0, q val=[[0.00394257]]\n",
            "at episode: 54, itr: 40, action=1, reward=0.0, q val=[[0.00635073]]\n",
            "at episode: 54, itr: 50, action=16, reward=0.0, q val=[[0.00784454]]\n",
            "at episode: 54, itr: 60, action=3, reward=0.0, q val=[[0.00766713]]\n",
            "at episode: 54, itr: 70, action=16, reward=0.0, q val=[[0.00816275]]\n",
            "at episode: 54, itr: 80, action=8, reward=0.0, q val=[[0.00868487]]\n",
            "at episode: 54, itr: 90, action=11, reward=0.0, q val=[[0.00941221]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0020\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.0020\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0018\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0016\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0014\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0010\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0012\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 268us/step - loss: 0.0021\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0015\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0011\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 2.9511e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 2.5638e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 182us/step - loss: 1.5305e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 180us/step - loss: 1.2347e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 192us/step - loss: 9.5334e-06\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 4.9553e-06\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 3.3271e-06\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 2.6763e-06\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 2.1532e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 1.8726e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 55, itr: 0, action=8, reward=0.0, q val=[[0.00925023]]\n",
            "at episode: 55, itr: 10, action=8, reward=0.0, q val=[[0.00133374]]\n",
            "at episode: 55, itr: 20, action=14, reward=0.0, q val=[[-0.01857667]]\n",
            "at episode: 55, itr: 30, action=13, reward=0.0, q val=[[-0.00324597]]\n",
            "at episode: 55, itr: 40, action=11, reward=0.0, q val=[[-0.00466598]]\n",
            "at episode: 55, itr: 50, action=17, reward=0.0, q val=[[-0.00467736]]\n",
            "at episode: 55, itr: 60, action=16, reward=0.0, q val=[[4.4095526e-05]]\n",
            "at episode: 55, itr: 70, action=4, reward=0.0, q val=[[0.00104829]]\n",
            "at episode: 55, itr: 80, action=13, reward=0.0, q val=[[0.00175932]]\n",
            "at episode: 55, itr: 90, action=3, reward=0.0, q val=[[0.00265608]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0024\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0022\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0028\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0022\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.0022\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 314us/step - loss: 0.0022\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.0019\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.0022\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.0021\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 2.6873e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 190us/step - loss: 3.4732e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 2.1700e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 1.6496e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 1.7832e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 1.7081e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 1.3488e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 293us/step - loss: 1.2775e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 1.2607e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 1.3069e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 56, itr: 0, action=11, reward=0.0, q val=[[0.00531559]]\n",
            "at episode: 56, itr: 10, action=8, reward=0.0, q val=[[-0.0081927]]\n",
            "at episode: 56, itr: 20, action=3, reward=0.0, q val=[[-0.01006805]]\n",
            "at episode: 56, itr: 30, action=2, reward=0.0, q val=[[-0.00274886]]\n",
            "at episode: 56, itr: 40, action=6, reward=0.0, q val=[[-0.00463848]]\n",
            "at episode: 56, itr: 50, action=6, reward=0.0, q val=[[0.00346073]]\n",
            "at episode: 56, itr: 60, action=3, reward=0.0, q val=[[0.01731744]]\n",
            "at episode: 56, itr: 70, action=1, reward=0.0, q val=[[0.0168725]]\n",
            "at episode: 56, itr: 80, action=6, reward=0.0, q val=[[0.01505557]]\n",
            "at episode: 56, itr: 90, action=4, reward=0.0, q val=[[-0.01301584]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: -1.7559e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.0011\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 260us/step - loss: 5.6679e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 2.1418e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 3.5133e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 4.0781e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0030\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0021\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 286us/step - loss: 2.1858e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 274us/step - loss: 3.3448e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 1.4172e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 1.0381e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 8.6718e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 5.1288e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 3.8067e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 3.7639e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 3.2782e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 3.3780e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 2.5256e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 2.2830e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 57, itr: 0, action=11, reward=0.0, q val=[[-0.03169773]]\n",
            "at episode: 57, itr: 10, action=13, reward=0.0, q val=[[-0.00301649]]\n",
            "at episode: 57, itr: 20, action=8, reward=0.0, q val=[[-0.00147481]]\n",
            "at episode: 57, itr: 30, action=4, reward=0.0, q val=[[-0.00118429]]\n",
            "at episode: 57, itr: 40, action=13, reward=0.0, q val=[[0.00133449]]\n",
            "at episode: 57, itr: 50, action=5, reward=0.0, q val=[[0.03673963]]\n",
            "at episode: 57, itr: 60, action=15, reward=0.0, q val=[[0.07941971]]\n",
            "at episode: 57, itr: 70, action=8, reward=0.0, q val=[[0.0002837]]\n",
            "at episode: 57, itr: 80, action=6, reward=0.0, q val=[[-0.00869094]]\n",
            "at episode: 57, itr: 90, action=12, reward=0.0, q val=[[-0.00452203]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: -0.0048\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: -0.0064\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: -0.0063\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 262us/step - loss: -0.0058\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: -0.0069\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: -0.0073\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: -0.0084\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 320us/step - loss: -0.0060\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 365us/step - loss: -0.0020\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 270us/step - loss: -0.0020\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 3.0601e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 1.9562e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 1.4353e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 190us/step - loss: 1.0012e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 192us/step - loss: 8.9434e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 4.7989e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 4.6926e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 4.7875e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 4.7007e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 4.7209e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 58, itr: 0, action=6, reward=0.0, q val=[[0.0022973]]\n",
            "at episode: 58, itr: 10, action=10, reward=0.0, q val=[[-0.00361034]]\n",
            "at episode: 58, itr: 20, action=2, reward=0.0, q val=[[0.00202494]]\n",
            "at episode: 58, itr: 30, action=1, reward=0.0, q val=[[0.00290638]]\n",
            "at episode: 58, itr: 40, action=2, reward=0.0, q val=[[0.00295234]]\n",
            "at episode: 58, itr: 50, action=16, reward=0.0, q val=[[0.00743262]]\n",
            "at episode: 58, itr: 60, action=5, reward=0.0, q val=[[0.00564594]]\n",
            "at episode: 58, itr: 70, action=17, reward=0.0, q val=[[0.00456347]]\n",
            "at episode: 58, itr: 80, action=12, reward=0.0, q val=[[0.00300801]]\n",
            "at episode: 58, itr: 90, action=5, reward=0.0, q val=[[0.00673031]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 7.0790e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 8.0260e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0019\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 6.6523e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 6.2802e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0039\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0023\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0014\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 250us/step - loss: 8.7593e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 1.4606e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 1.6191e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 1.1970e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 1.0259e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 189us/step - loss: 1.0881e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 7.3319e-06\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 7.8720e-06\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 6.6563e-06\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 6.0139e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 6.3462e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 59, itr: 0, action=12, reward=0.0, q val=[[0.00544619]]\n",
            "at episode: 59, itr: 10, action=2, reward=0.0, q val=[[0.0095212]]\n",
            "at episode: 59, itr: 20, action=17, reward=0.0, q val=[[0.01597081]]\n",
            "at episode: 59, itr: 30, action=4, reward=0.0, q val=[[0.01621072]]\n",
            "at episode: 59, itr: 40, action=6, reward=0.0, q val=[[0.01588018]]\n",
            "at episode: 59, itr: 50, action=12, reward=0.0, q val=[[0.01458266]]\n",
            "at episode: 59, itr: 60, action=14, reward=0.0, q val=[[0.01137559]]\n",
            "at episode: 59, itr: 70, action=14, reward=0.0, q val=[[0.00970212]]\n",
            "at episode: 59, itr: 80, action=1, reward=0.0, q val=[[0.00726958]]\n",
            "at episode: 59, itr: 90, action=12, reward=0.0, q val=[[0.00533286]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 4.5688e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0024\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.0015\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: -2.0726e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0022\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0015\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0014\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0011\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0014\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 359us/step - loss: 0.0011\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 1.4701e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 1.5572e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 1.6095e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 2.0437e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 1.9170e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 178us/step - loss: 2.0483e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 178us/step - loss: 1.5939e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 180us/step - loss: 2.2233e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 182us/step - loss: 1.8106e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 187us/step - loss: 1.4403e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 60, itr: 0, action=7, reward=0.0, q val=[[-0.00070654]]\n",
            "at episode: 60, itr: 10, action=6, reward=0.0, q val=[[-0.00189285]]\n",
            "at episode: 60, itr: 20, action=17, reward=0.0, q val=[[0.00807288]]\n",
            "at episode: 60, itr: 30, action=1, reward=0.0, q val=[[0.012243]]\n",
            "at episode: 60, itr: 40, action=16, reward=0.0, q val=[[-0.0076548]]\n",
            "at episode: 60, itr: 50, action=8, reward=0.0, q val=[[0.00572889]]\n",
            "at episode: 60, itr: 60, action=8, reward=0.0, q val=[[0.00736019]]\n",
            "at episode: 60, itr: 70, action=7, reward=0.0, q val=[[0.01009637]]\n",
            "at episode: 60, itr: 80, action=12, reward=0.0, q val=[[0.01246087]]\n",
            "at episode: 60, itr: 90, action=14, reward=0.0, q val=[[0.00996455]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 275us/step - loss: 0.0088\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.0077\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.0103\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.0127\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 291us/step - loss: 0.0092\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0084\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.0082\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.0090\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.0082\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0082\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 0.0696\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 294us/step - loss: 0.0552\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.0559\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.0481\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0466\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0349\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0495\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0493\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 0.0429\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0357\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 61, itr: 0, action=12, reward=0.0, q val=[[0.08185002]]\n",
            "at episode: 61, itr: 10, action=13, reward=0.0, q val=[[0.12237909]]\n",
            "at episode: 61, itr: 20, action=12, reward=0.0, q val=[[0.17623839]]\n",
            "at episode: 61, itr: 30, action=8, reward=0.0, q val=[[0.18671612]]\n",
            "at episode: 61, itr: 40, action=4, reward=0.0, q val=[[0.18792967]]\n",
            "at episode: 61, itr: 50, action=1, reward=0.0, q val=[[0.18595551]]\n",
            "at episode: 61, itr: 60, action=1, reward=0.0, q val=[[0.17889105]]\n",
            "at episode: 61, itr: 70, action=8, reward=0.0, q val=[[0.1716768]]\n",
            "at episode: 61, itr: 80, action=1, reward=0.0, q val=[[0.16705419]]\n",
            "at episode: 61, itr: 90, action=4, reward=0.0, q val=[[0.16230902]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.0150\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.0153\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0152\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0159\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0152\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0153\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0147\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0155\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0170\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 306us/step - loss: 0.0164\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 6.4370e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 4.2014e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 3.0934e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 3.0056e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 189us/step - loss: 2.6149e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 2.0110e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 1.8036e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 1.8686e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 1.5796e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 1.2134e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 62, itr: 0, action=12, reward=0.0, q val=[[0.14019166]]\n",
            "at episode: 62, itr: 10, action=12, reward=0.0, q val=[[0.11329232]]\n",
            "at episode: 62, itr: 20, action=1, reward=0.0, q val=[[0.1622866]]\n",
            "at episode: 62, itr: 30, action=15, reward=0.0, q val=[[0.16513658]]\n",
            "at episode: 62, itr: 40, action=5, reward=0.0, q val=[[0.16470768]]\n",
            "at episode: 62, itr: 50, action=8, reward=0.0, q val=[[0.16156073]]\n",
            "at episode: 62, itr: 60, action=5, reward=0.0, q val=[[0.1583464]]\n",
            "at episode: 62, itr: 70, action=11, reward=0.0, q val=[[0.15494391]]\n",
            "at episode: 62, itr: 80, action=12, reward=0.0, q val=[[0.15229271]]\n",
            "at episode: 62, itr: 90, action=4, reward=0.0, q val=[[0.14957184]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0123\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0125\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0121\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.0123\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0128\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0120\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0125\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0120\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0121\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.0121\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 3.3619e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 2.5949e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 2.7362e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 2.2848e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 1.7138e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 181us/step - loss: 1.3269e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 179us/step - loss: 1.4540e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 1.3991e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 1.7566e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 178us/step - loss: 1.0212e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 63, itr: 0, action=1, reward=0.0, q val=[[0.13381171]]\n",
            "at episode: 63, itr: 10, action=1, reward=0.0, q val=[[0.03737312]]\n",
            "at episode: 63, itr: 20, action=12, reward=0.0, q val=[[0.10605378]]\n",
            "at episode: 63, itr: 30, action=8, reward=0.0, q val=[[0.13287935]]\n",
            "at episode: 63, itr: 40, action=2, reward=0.0, q val=[[0.13736431]]\n",
            "at episode: 63, itr: 50, action=12, reward=0.0, q val=[[0.13641304]]\n",
            "at episode: 63, itr: 60, action=18, reward=0.0, q val=[[0.13624181]]\n",
            "at episode: 63, itr: 70, action=12, reward=0.0, q val=[[0.13812567]]\n",
            "at episode: 63, itr: 80, action=8, reward=0.0, q val=[[0.14967579]]\n",
            "at episode: 63, itr: 90, action=5, reward=0.0, q val=[[0.01934668]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0086\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.0085\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0083\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0081\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0088\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.0089\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0077\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.0080\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.0078\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0074\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0013\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0013\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 8.4279e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 8.1690e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 6.0485e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 276us/step - loss: 4.1899e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 325us/step - loss: 3.6169e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 196us/step - loss: 3.1681e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 2.9337e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 2.3522e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 64, itr: 0, action=11, reward=0.0, q val=[[0.06344]]\n",
            "at episode: 64, itr: 10, action=5, reward=0.0, q val=[[0.06532874]]\n",
            "at episode: 64, itr: 20, action=2, reward=0.0, q val=[[0.04822274]]\n",
            "at episode: 64, itr: 30, action=1, reward=0.0, q val=[[0.08657118]]\n",
            "at episode: 64, itr: 40, action=16, reward=0.0, q val=[[0.09816349]]\n",
            "at episode: 64, itr: 50, action=12, reward=0.0, q val=[[0.09938844]]\n",
            "at episode: 64, itr: 60, action=17, reward=0.0, q val=[[0.09352157]]\n",
            "at episode: 64, itr: 70, action=12, reward=0.0, q val=[[0.08054438]]\n",
            "at episode: 64, itr: 80, action=16, reward=0.0, q val=[[0.07451817]]\n",
            "at episode: 64, itr: 90, action=14, reward=0.0, q val=[[0.00425257]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0021\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.0022\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0068\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0032\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0028\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0023\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0024\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0026\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0023\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.0024\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 297us/step - loss: 0.0015\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 8.5921e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 5.9581e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 181us/step - loss: 4.6615e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 4.7251e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 4.1242e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 4.2648e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 2.9938e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 2.5494e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 2.2968e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 65, itr: 0, action=1, reward=0.0, q val=[[-0.03270925]]\n",
            "at episode: 65, itr: 10, action=4, reward=0.0, q val=[[0.0772255]]\n",
            "at episode: 65, itr: 20, action=6, reward=0.0, q val=[[-0.07495473]]\n",
            "at episode: 65, itr: 30, action=11, reward=0.0, q val=[[0.03181361]]\n",
            "at episode: 65, itr: 40, action=1, reward=0.0, q val=[[0.03575102]]\n",
            "at episode: 65, itr: 50, action=1, reward=0.0, q val=[[0.01889013]]\n",
            "at episode: 65, itr: 60, action=4, reward=0.0, q val=[[0.02956353]]\n",
            "at episode: 65, itr: 70, action=12, reward=0.0, q val=[[0.0803647]]\n",
            "at episode: 65, itr: 80, action=14, reward=0.0, q val=[[-0.03009051]]\n",
            "at episode: 65, itr: 90, action=3, reward=0.0, q val=[[0.05642736]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0012\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0021\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0017\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0017\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0011\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 309us/step - loss: 0.0015\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0027\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0021\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 252us/step - loss: 6.3307e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 0.0012\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 0.0011\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 5.8924e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 5.4071e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 189us/step - loss: 4.6938e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 3.8881e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 3.6323e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 3.4037e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 272us/step - loss: 2.5963e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 2.6961e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 66, itr: 0, action=7, reward=0.0, q val=[[0.01577743]]\n",
            "at episode: 66, itr: 10, action=17, reward=0.0, q val=[[0.02071525]]\n",
            "at episode: 66, itr: 20, action=12, reward=0.0, q val=[[-0.0129495]]\n",
            "at episode: 66, itr: 30, action=12, reward=0.0, q val=[[0.0091446]]\n",
            "at episode: 66, itr: 40, action=4, reward=0.0, q val=[[0.00479277]]\n",
            "at episode: 66, itr: 50, action=11, reward=0.0, q val=[[-0.00677761]]\n",
            "at episode: 66, itr: 60, action=3, reward=0.0, q val=[[-0.01298037]]\n",
            "at episode: 66, itr: 70, action=12, reward=0.0, q val=[[-0.02462068]]\n",
            "at episode: 66, itr: 80, action=14, reward=0.0, q val=[[-0.03221448]]\n",
            "at episode: 66, itr: 90, action=5, reward=0.0, q val=[[-0.03943535]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 8.5147e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 7.1343e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 9.4154e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 7.0425e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 264us/step - loss: 6.2312e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 273us/step - loss: 4.7593e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.0024\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0044\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0016\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: 1.9087e-04\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 7.8357e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 7.5630e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 7.3436e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 5.1238e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 212us/step - loss: 3.9338e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 3.2333e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 2.6242e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 190us/step - loss: 2.8245e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 2.5410e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 2.2003e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 67, itr: 0, action=6, reward=0.0, q val=[[-0.04051888]]\n",
            "at episode: 67, itr: 10, action=5, reward=0.0, q val=[[0.02686053]]\n",
            "at episode: 67, itr: 20, action=11, reward=0.0, q val=[[0.02338098]]\n",
            "at episode: 67, itr: 30, action=12, reward=0.0, q val=[[0.02093737]]\n",
            "at episode: 67, itr: 40, action=6, reward=0.0, q val=[[0.0150205]]\n",
            "at episode: 67, itr: 50, action=16, reward=0.0, q val=[[0.00869865]]\n",
            "at episode: 67, itr: 60, action=1, reward=0.0, q val=[[0.00319864]]\n",
            "at episode: 67, itr: 70, action=11, reward=0.0, q val=[[-0.00055149]]\n",
            "at episode: 67, itr: 80, action=5, reward=0.0, q val=[[-0.00220174]]\n",
            "at episode: 67, itr: 90, action=8, reward=0.0, q val=[[-0.00611542]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 7.0568e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0024\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.0016\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 258us/step - loss: 5.7409e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 8.2647e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: 5.2187e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 322us/step - loss: 5.7737e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 270us/step - loss: 2.2145e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.0010\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.0017\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 1.2782e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 1.1529e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 9.9955e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 8.4557e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 7.6883e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 7.1280e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 5.4399e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 6.5342e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 267us/step - loss: 4.8273e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 3.5526e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 68, itr: 0, action=17, reward=0.0, q val=[[-0.00985181]]\n",
            "at episode: 68, itr: 10, action=11, reward=0.0, q val=[[0.00260568]]\n",
            "at episode: 68, itr: 20, action=11, reward=0.0, q val=[[0.00876827]]\n",
            "at episode: 68, itr: 30, action=5, reward=0.0, q val=[[0.00097797]]\n",
            "at episode: 68, itr: 40, action=1, reward=0.0, q val=[[0.00528024]]\n",
            "at episode: 68, itr: 50, action=6, reward=0.0, q val=[[0.00841892]]\n",
            "at episode: 68, itr: 60, action=16, reward=0.0, q val=[[-0.01504022]]\n",
            "at episode: 68, itr: 70, action=8, reward=0.0, q val=[[-0.00735862]]\n",
            "at episode: 68, itr: 80, action=17, reward=0.0, q val=[[0.01628732]]\n",
            "at episode: 68, itr: 90, action=8, reward=0.0, q val=[[0.01328523]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 259us/step - loss: -1.4850e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 344us/step - loss: -6.0906e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 259us/step - loss: -7.1067e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: -4.0642e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.0011\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: -0.0011\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: -0.0015\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 261us/step - loss: -0.0016\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 2.9621e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: -0.0013\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 2.2412e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 270us/step - loss: 1.7877e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 1.1150e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 9.1984e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 7.6650e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 6.6888e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: 6.0059e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 7.8932e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 7.3827e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 9.0809e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 69, itr: 0, action=16, reward=0.0, q val=[[0.00716427]]\n",
            "at episode: 69, itr: 10, action=16, reward=0.0, q val=[[0.01337544]]\n",
            "at episode: 69, itr: 20, action=6, reward=0.0, q val=[[0.00286451]]\n",
            "at episode: 69, itr: 30, action=10, reward=0.0, q val=[[0.00746429]]\n",
            "at episode: 69, itr: 40, action=6, reward=0.0, q val=[[0.00226001]]\n",
            "at episode: 69, itr: 50, action=8, reward=0.0, q val=[[0.00043841]]\n",
            "at episode: 69, itr: 60, action=16, reward=0.0, q val=[[-0.24121967]]\n",
            "at episode: 69, itr: 70, action=12, reward=0.0, q val=[[0.01446515]]\n",
            "at episode: 69, itr: 80, action=1, reward=0.0, q val=[[0.02468504]]\n",
            "at episode: 69, itr: 90, action=17, reward=0.0, q val=[[0.01687117]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: -0.0173\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 260us/step - loss: -0.0238\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: -0.0291\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: -0.0300\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: -0.0298\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 258us/step - loss: -0.0315\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 389us/step - loss: -0.0331\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 270us/step - loss: -0.0327\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 289us/step - loss: -0.0335\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 259us/step - loss: -0.0338\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0034\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0045\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0027\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0025\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0019\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 7.1133e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 3.6922e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 5.7298e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 257us/step - loss: 5.8850e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 70, itr: 0, action=11, reward=0.0, q val=[[0.00227456]]\n",
            "at episode: 70, itr: 10, action=1, reward=0.0, q val=[[-0.04171965]]\n",
            "at episode: 70, itr: 20, action=1, reward=0.0, q val=[[-0.04274]]\n",
            "at episode: 70, itr: 30, action=4, reward=0.0, q val=[[-0.05448885]]\n",
            "at episode: 70, itr: 40, action=3, reward=0.0, q val=[[-0.06404576]]\n",
            "at episode: 70, itr: 50, action=11, reward=0.0, q val=[[-0.07174807]]\n",
            "at episode: 70, itr: 60, action=14, reward=0.0, q val=[[-0.07678499]]\n",
            "at episode: 70, itr: 70, action=17, reward=0.0, q val=[[-0.08158743]]\n",
            "at episode: 70, itr: 80, action=6, reward=0.0, q val=[[-0.08542248]]\n",
            "at episode: 70, itr: 90, action=11, reward=0.0, q val=[[-0.08793896]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.0016\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.0024\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0013\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.0037\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.0015\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 283us/step - loss: 0.0016\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.0017\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 274us/step - loss: 0.0016\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.0017\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.0015\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 7.1053e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 7.7729e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 5.1593e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 3.7268e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 5.2457e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 300us/step - loss: 2.3764e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 2.5480e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 1.8032e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 1.7095e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 240us/step - loss: 1.5042e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 71, itr: 0, action=1, reward=0.0, q val=[[-0.0853496]]\n",
            "at episode: 71, itr: 10, action=10, reward=0.0, q val=[[-0.05348792]]\n",
            "at episode: 71, itr: 20, action=8, reward=0.0, q val=[[-0.04521274]]\n",
            "at episode: 71, itr: 30, action=12, reward=0.0, q val=[[-0.05576978]]\n",
            "at episode: 71, itr: 40, action=3, reward=0.0, q val=[[-0.02287368]]\n",
            "at episode: 71, itr: 50, action=16, reward=0.0, q val=[[-0.02508774]]\n",
            "at episode: 71, itr: 60, action=8, reward=0.0, q val=[[-0.03166996]]\n",
            "at episode: 71, itr: 70, action=1, reward=0.0, q val=[[-0.04060704]]\n",
            "at episode: 71, itr: 80, action=12, reward=0.0, q val=[[-0.0451103]]\n",
            "at episode: 71, itr: 90, action=5, reward=0.0, q val=[[-0.04504309]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0040\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0033\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0038\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0038\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 307us/step - loss: 0.0036\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0027\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0022\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0035\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 301us/step - loss: 0.0036\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.0028\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 1.4573e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 1.0909e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 8.3509e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 268us/step - loss: 5.9950e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: 6.1523e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 5.9000e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 177us/step - loss: 7.6213e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 7.0227e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 4.3850e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 3.5438e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 72, itr: 0, action=14, reward=0.0, q val=[[-0.04330505]]\n",
            "at episode: 72, itr: 10, action=3, reward=0.0, q val=[[-0.04121408]]\n",
            "at episode: 72, itr: 20, action=5, reward=0.0, q val=[[-0.04263733]]\n",
            "at episode: 72, itr: 30, action=4, reward=0.0, q val=[[-0.05486432]]\n",
            "at episode: 72, itr: 40, action=6, reward=0.0, q val=[[-0.04439588]]\n",
            "at episode: 72, itr: 50, action=16, reward=0.0, q val=[[-0.0418857]]\n",
            "at episode: 72, itr: 60, action=7, reward=0.0, q val=[[-0.02470249]]\n",
            "at episode: 72, itr: 70, action=12, reward=0.0, q val=[[-0.02809087]]\n",
            "at episode: 72, itr: 80, action=1, reward=0.0, q val=[[-0.03108674]]\n",
            "at episode: 72, itr: 90, action=5, reward=0.0, q val=[[-0.03454268]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0152\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0152\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0150\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0153\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 276us/step - loss: 0.0136\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.0142\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0123\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0144\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0147\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0128\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 2.3424e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 1.6884e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 1.4881e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 7.4904e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 252us/step - loss: 4.6794e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: 4.2334e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 258us/step - loss: 3.9067e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 3.3398e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 3.2216e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 2.5984e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 73, itr: 0, action=1, reward=0.0, q val=[[-0.04086598]]\n",
            "at episode: 73, itr: 10, action=17, reward=0.0, q val=[[-0.02021104]]\n",
            "at episode: 73, itr: 20, action=16, reward=0.0, q val=[[-0.00546425]]\n",
            "at episode: 73, itr: 30, action=3, reward=0.0, q val=[[-0.00929448]]\n",
            "at episode: 73, itr: 40, action=17, reward=0.0, q val=[[-0.00954252]]\n",
            "at episode: 73, itr: 50, action=11, reward=0.0, q val=[[-0.07570555]]\n",
            "at episode: 73, itr: 60, action=4, reward=0.0, q val=[[-0.11205396]]\n",
            "at episode: 73, itr: 70, action=3, reward=0.0, q val=[[-0.02967724]]\n",
            "at episode: 73, itr: 80, action=16, reward=0.0, q val=[[-0.02232731]]\n",
            "at episode: 73, itr: 90, action=18, reward=0.0, q val=[[-0.01037608]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0125\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0120\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0144\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0139\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0121\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 323us/step - loss: 0.0114\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 286us/step - loss: 0.0122\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.0109\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0117\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0132\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 0.0010\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 4.9518e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 3.7231e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 3.0641e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 1.8116e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: 1.1406e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 9.2380e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 1.0395e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 182us/step - loss: 8.9504e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 7.5708e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 74, itr: 0, action=6, reward=0.0, q val=[[-0.02309806]]\n",
            "at episode: 74, itr: 10, action=16, reward=0.0, q val=[[-0.00961271]]\n",
            "at episode: 74, itr: 20, action=17, reward=0.0, q val=[[-0.00609761]]\n",
            "at episode: 74, itr: 30, action=3, reward=0.0, q val=[[-0.02620926]]\n",
            "at episode: 74, itr: 40, action=11, reward=0.0, q val=[[-0.02411717]]\n",
            "at episode: 74, itr: 50, action=3, reward=0.0, q val=[[-0.04158649]]\n",
            "at episode: 74, itr: 60, action=3, reward=0.0, q val=[[-0.02104365]]\n",
            "at episode: 74, itr: 70, action=1, reward=0.0, q val=[[-0.03491151]]\n",
            "at episode: 74, itr: 80, action=16, reward=0.0, q val=[[-0.04258864]]\n",
            "at episode: 74, itr: 90, action=3, reward=0.0, q val=[[-0.04501358]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0021\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0027\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0029\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0028\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0039\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0053\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.0047\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0038\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0037\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 283us/step - loss: 0.0034\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 4.8012e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 4.0925e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 200us/step - loss: 4.3312e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 173us/step - loss: 3.2581e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 185us/step - loss: 2.9646e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 2.7743e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 2.2536e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 2.2724e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 2.1510e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 185us/step - loss: 1.8433e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 75, itr: 0, action=8, reward=0.0, q val=[[-0.04833965]]\n",
            "at episode: 75, itr: 10, action=3, reward=0.0, q val=[[-0.01612727]]\n",
            "at episode: 75, itr: 20, action=4, reward=0.0, q val=[[-0.02189929]]\n",
            "at episode: 75, itr: 30, action=8, reward=0.0, q val=[[-0.01827032]]\n",
            "at episode: 75, itr: 40, action=17, reward=0.0, q val=[[-0.0348566]]\n",
            "at episode: 75, itr: 50, action=6, reward=0.0, q val=[[-0.03470143]]\n",
            "at episode: 75, itr: 60, action=11, reward=0.0, q val=[[-0.05851855]]\n",
            "at episode: 75, itr: 70, action=4, reward=0.0, q val=[[-0.01506348]]\n",
            "at episode: 75, itr: 80, action=6, reward=0.0, q val=[[-0.00109602]]\n",
            "at episode: 75, itr: 90, action=3, reward=0.0, q val=[[-0.00676558]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: -6.6689e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.0027\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: -0.0012\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 230us/step - loss: -0.0019\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: -0.0012\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: -6.0021e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: -0.0013\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: -6.2535e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 7.1340e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0014\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 178us/step - loss: 1.4973e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 185us/step - loss: 1.2100e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 161us/step - loss: 1.0112e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 213us/step - loss: 1.4718e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 196us/step - loss: 7.4889e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 187us/step - loss: 6.8139e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 5.5846e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 268us/step - loss: 5.1496e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 4.5611e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 3.9969e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 76, itr: 0, action=3, reward=0.0, q val=[[0.01621582]]\n",
            "at episode: 76, itr: 10, action=16, reward=0.0, q val=[[-0.01044777]]\n",
            "at episode: 76, itr: 20, action=1, reward=0.0, q val=[[0.00347211]]\n",
            "at episode: 76, itr: 30, action=8, reward=0.0, q val=[[-0.00404793]]\n",
            "at episode: 76, itr: 40, action=8, reward=0.0, q val=[[-0.00882649]]\n",
            "at episode: 76, itr: 50, action=2, reward=0.0, q val=[[-0.01362804]]\n",
            "at episode: 76, itr: 60, action=2, reward=0.0, q val=[[-0.01877839]]\n",
            "at episode: 76, itr: 70, action=11, reward=0.0, q val=[[-0.02437263]]\n",
            "at episode: 76, itr: 80, action=17, reward=0.0, q val=[[-0.02685759]]\n",
            "at episode: 76, itr: 90, action=16, reward=0.0, q val=[[-0.02894766]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0041\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0028\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0028\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0039\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0049\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0040\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0040\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0045\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 276us/step - loss: 0.0031\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0036\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 2.6703e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 2.4012e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 3.0219e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 206us/step - loss: 3.7600e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 3.5281e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 3.1075e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 1.7865e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 244us/step - loss: 1.0815e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 1.1124e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 8.6753e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 77, itr: 0, action=11, reward=0.0, q val=[[-0.03006611]]\n",
            "at episode: 77, itr: 10, action=16, reward=0.0, q val=[[-0.01110882]]\n",
            "at episode: 77, itr: 20, action=5, reward=0.0, q val=[[-0.00290816]]\n",
            "at episode: 77, itr: 30, action=8, reward=0.0, q val=[[-0.00836177]]\n",
            "at episode: 77, itr: 40, action=17, reward=0.0, q val=[[-0.01277179]]\n",
            "at episode: 77, itr: 50, action=3, reward=0.0, q val=[[-0.01317837]]\n",
            "at episode: 77, itr: 60, action=1, reward=0.0, q val=[[-0.01109812]]\n",
            "at episode: 77, itr: 70, action=4, reward=0.0, q val=[[-0.01508149]]\n",
            "at episode: 77, itr: 80, action=16, reward=0.0, q val=[[-0.01781698]]\n",
            "at episode: 77, itr: 90, action=2, reward=0.0, q val=[[-0.02122346]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: -0.0032\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: -0.0039\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: -0.0037\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: -0.0040\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: -0.0034\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: -0.0025\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: -0.0037\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: -0.0033\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 256us/step - loss: -0.0033\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: -0.0029\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 177us/step - loss: 1.3287e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 184us/step - loss: 1.4086e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 1.0177e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 1.0343e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 9.0720e-06\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 8.1615e-06\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 6.9950e-06\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 7.5139e-06\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 5.8364e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 5.6334e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 78, itr: 0, action=14, reward=0.0, q val=[[-0.03055774]]\n",
            "at episode: 78, itr: 10, action=17, reward=0.0, q val=[[0.00063482]]\n",
            "at episode: 78, itr: 20, action=6, reward=0.0, q val=[[-0.01443233]]\n",
            "at episode: 78, itr: 30, action=1, reward=0.0, q val=[[-0.00689003]]\n",
            "at episode: 78, itr: 40, action=17, reward=0.0, q val=[[-0.01473463]]\n",
            "at episode: 78, itr: 50, action=16, reward=0.0, q val=[[-0.01816146]]\n",
            "at episode: 78, itr: 60, action=8, reward=0.0, q val=[[-0.01776903]]\n",
            "at episode: 78, itr: 70, action=4, reward=0.0, q val=[[-0.00178119]]\n",
            "at episode: 78, itr: 80, action=6, reward=0.0, q val=[[-0.01406245]]\n",
            "at episode: 78, itr: 90, action=12, reward=0.0, q val=[[-0.00457072]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: -0.0043\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 261us/step - loss: -0.0046\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 269us/step - loss: -0.0048\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 249us/step - loss: -0.0052\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: -0.0054\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 329us/step - loss: -0.0041\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 237us/step - loss: -0.0046\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: -0.0050\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 239us/step - loss: -0.0042\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: -0.0047\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 5.6978e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 5.1133e-05\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: 3.6334e-05\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: 4.6323e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 188us/step - loss: 2.6753e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 196us/step - loss: 3.4148e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 218us/step - loss: 1.7383e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 1.3872e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 1.3006e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 1.1468e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 79, itr: 0, action=6, reward=0.0, q val=[[0.0004761]]\n",
            "at episode: 79, itr: 10, action=1, reward=0.0, q val=[[-0.00450442]]\n",
            "at episode: 79, itr: 20, action=12, reward=0.0, q val=[[-0.02659555]]\n",
            "at episode: 79, itr: 30, action=12, reward=0.0, q val=[[-0.01356835]]\n",
            "at episode: 79, itr: 40, action=4, reward=0.0, q val=[[0.00671615]]\n",
            "at episode: 79, itr: 50, action=3, reward=0.0, q val=[[-0.00185262]]\n",
            "at episode: 79, itr: 60, action=12, reward=0.0, q val=[[-0.03379802]]\n",
            "at episode: 79, itr: 70, action=8, reward=0.0, q val=[[-0.03435355]]\n",
            "at episode: 79, itr: 80, action=11, reward=0.0, q val=[[-0.02327877]]\n",
            "at episode: 79, itr: 90, action=6, reward=0.0, q val=[[-0.01895666]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0027\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0028\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0030\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0027\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0025\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0023\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0028\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0025\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0026\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0030\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 203us/step - loss: 1.6283e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 204us/step - loss: 2.0019e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 1.0589e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 209us/step - loss: 5.3836e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 182us/step - loss: 4.7110e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 183us/step - loss: 4.9187e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 201us/step - loss: 4.3764e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 4.6055e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 185us/step - loss: 4.6106e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 4.2016e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 80, itr: 0, action=6, reward=0.0, q val=[[-0.00876441]]\n",
            "at episode: 80, itr: 10, action=6, reward=0.0, q val=[[-0.01567944]]\n",
            "at episode: 80, itr: 20, action=16, reward=0.0, q val=[[-0.01272676]]\n",
            "at episode: 80, itr: 30, action=8, reward=0.0, q val=[[-0.01890471]]\n",
            "at episode: 80, itr: 40, action=7, reward=0.0, q val=[[-0.02365418]]\n",
            "at episode: 80, itr: 50, action=3, reward=0.0, q val=[[-0.02799923]]\n",
            "at episode: 80, itr: 60, action=1, reward=0.0, q val=[[-0.02936328]]\n",
            "at episode: 80, itr: 70, action=11, reward=0.0, q val=[[-0.02885194]]\n",
            "at episode: 80, itr: 80, action=8, reward=0.0, q val=[[-0.0308831]]\n",
            "at episode: 80, itr: 90, action=6, reward=0.0, q val=[[-0.03085534]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: -0.0016\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: -0.0016\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 255us/step - loss: -4.4922e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 280us/step - loss: -0.0019\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: -2.1385e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 225us/step - loss: 7.8868e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 261us/step - loss: -0.0027\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: -0.0025\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 222us/step - loss: -0.0013\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: -0.0029\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 202us/step - loss: 1.6194e-05\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 9.7878e-06\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 5.5043e-06\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 5.4706e-06\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 193us/step - loss: 5.4169e-06\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 6.3721e-06\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 5.8108e-06\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 5.4374e-06\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 6.6128e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 4.8621e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 81, itr: 0, action=12, reward=0.0, q val=[[-0.02885893]]\n",
            "at episode: 81, itr: 10, action=16, reward=0.0, q val=[[-0.01662096]]\n",
            "at episode: 81, itr: 20, action=8, reward=0.0, q val=[[-0.01494193]]\n",
            "at episode: 81, itr: 30, action=6, reward=0.0, q val=[[-0.01855767]]\n",
            "at episode: 81, itr: 40, action=11, reward=0.0, q val=[[-0.02256068]]\n",
            "at episode: 81, itr: 50, action=4, reward=0.0, q val=[[-0.02670707]]\n",
            "at episode: 81, itr: 60, action=8, reward=0.0, q val=[[-0.0307229]]\n",
            "at episode: 81, itr: 70, action=11, reward=0.0, q val=[[-0.02740489]]\n",
            "at episode: 81, itr: 80, action=3, reward=0.0, q val=[[-0.03198847]]\n",
            "at episode: 81, itr: 90, action=4, reward=0.0, q val=[[-0.03248399]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 233us/step - loss: -0.0025\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 214us/step - loss: -0.0028\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 217us/step - loss: -0.0019\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: -7.9645e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 223us/step - loss: -0.0016\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: -0.0020\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: -0.0028\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 290us/step - loss: -0.0019\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 250us/step - loss: 8.0863e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 251us/step - loss: -0.0017\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 220us/step - loss: 8.0135e-06\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 196us/step - loss: 7.5854e-06\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 8.1774e-06\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 195us/step - loss: 6.6858e-06\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 5.8765e-06\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 6.2252e-06\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 192us/step - loss: 9.7435e-06\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 7.0020e-06\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 6.2932e-06\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 181us/step - loss: 7.7062e-06\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 82, itr: 0, action=4, reward=0.0, q val=[[-0.0386608]]\n",
            "at episode: 82, itr: 10, action=3, reward=0.0, q val=[[-0.01444107]]\n",
            "at episode: 82, itr: 20, action=16, reward=0.0, q val=[[-0.02346662]]\n",
            "at episode: 82, itr: 30, action=3, reward=0.0, q val=[[-0.01583306]]\n",
            "at episode: 82, itr: 40, action=12, reward=0.0, q val=[[-0.0230401]]\n",
            "at episode: 82, itr: 50, action=8, reward=0.0, q val=[[-0.02579333]]\n",
            "at episode: 82, itr: 60, action=11, reward=0.0, q val=[[-0.03027453]]\n",
            "at episode: 82, itr: 70, action=3, reward=0.0, q val=[[-0.02486151]]\n",
            "at episode: 82, itr: 80, action=11, reward=0.0, q val=[[-0.01656194]]\n",
            "at episode: 82, itr: 90, action=6, reward=0.0, q val=[[-0.01726879]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0038\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0020\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0028\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0041\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0084\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0038\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 320us/step - loss: 0.0028\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 301us/step - loss: 0.0021\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.0027\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 190us/step - loss: 1.4213e-04\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 1.2213e-04\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 186us/step - loss: 1.0292e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 182us/step - loss: 8.7711e-05\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 207us/step - loss: 8.4063e-05\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 194us/step - loss: 8.5254e-05\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 197us/step - loss: 6.9439e-05\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 219us/step - loss: 8.6148e-05\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 199us/step - loss: 6.8836e-05\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 198us/step - loss: 7.6521e-05\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=0.0\n",
            "at episode: 83, itr: 0, action=13, reward=0.0, q val=[[-0.05660366]]\n",
            "at episode: 83, itr: 10, action=3, reward=0.0, q val=[[-0.01052673]]\n",
            "at episode: 83, itr: 20, action=8, reward=0.0, q val=[[-0.0020294]]\n",
            "at episode: 83, itr: 30, action=8, reward=0.0, q val=[[0.00039358]]\n",
            "at episode: 83, itr: 40, action=6, reward=0.0, q val=[[0.00302527]]\n",
            "at episode: 83, itr: 50, action=5, reward=0.0, q val=[[-0.06758927]]\n",
            "at episode: 83, itr: 60, action=12, reward=0.0, q val=[[-0.17996123]]\n",
            "at episode: 83, itr: 70, action=8, reward=0.0, q val=[[-0.01977083]]\n",
            "at episode: 83, itr: 80, action=5, reward=0.0, q val=[[-0.00971616]]\n",
            "at episode: 83, itr: 90, action=11, reward=0.0, q val=[[-0.0034004]]\n",
            "fitting actor net (PPO loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0195\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0171\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0141\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0140\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 324us/step - loss: 0.0149\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.0150\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.0130\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0131\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0130\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0136\n",
            "fitting critic net (MSE loss)...\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 177us/step - loss: 0.0018\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 288us/step - loss: 0.0021\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 186us/step - loss: 6.5721e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 191us/step - loss: 5.5949e-04\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 8.0082e-04\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 208us/step - loss: 3.9748e-04\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 205us/step - loss: 4.6994e-04\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 215us/step - loss: 3.4547e-04\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 3.0666e-04\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 210us/step - loss: 3.4657e-04\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "total test reward=1.0\n",
            "best reward=1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icme3OBZzlTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c26917d8-685d-47f5-890d-0a8af302bf1a"
      },
      "source": [
        "# testing and plotting rewards for the trained model\n",
        "env = football_env.create_environment(env_name='academy_empty_goal', representation='simple115')\n",
        "reward_rec = []\n",
        "\n",
        "for i in range(100):\n",
        "  total_reward = test_reward()\n",
        "  reward_rec.append(total_reward)\n",
        "\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n",
            "testing...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3AoY0UL7jOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "37ecdb7c-2b06-4dbf-9545-697ca9c76d04"
      },
      "source": [
        "# plot reward and cum reward\n",
        "plt.plot(range(len(reward_rec)),reward_rec)\n",
        "plt.xlabel('Test run')\n",
        "plt.ylabel('Reward')\n",
        "plt.show()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwCdLHgL7l93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "d9b3564b-a07e-41a0-eee1-844ed62ebcce"
      },
      "source": [
        "cum_reward = np.cumsum(reward_rec)\n",
        "plt.plot(range(len(cum_reward)),cum_reward)\n",
        "plt.xlabel('Test run')\n",
        "plt.ylabel('Cumulative Reward')\n",
        "plt.show()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kppi363byf0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot losses\n",
        "\n",
        "policy_loss = np.zeros((len(actor_loss_rec),))\n",
        "for i in range(len(actor_loss_rec)):\n",
        "  policy_loss[i] = np.mean(actor_loss_rec[i].history['loss'])\n",
        "value_loss = np.zeros((len(critic_loss_rec),))\n",
        "for i in range(len(critic_loss_rec)):\n",
        "  value_loss[i] = np.mean(critic_loss_rec[i].history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej54CP3W8pdV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "eae271f2-285e-4cfa-aa6b-bb5ee8b0585f"
      },
      "source": [
        "plt.plot(range(len(policy_loss)),policy_loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXycV3X4/8+ZVfsu71a8J3EW24kTZ4WQBcKaFAIJ0BLWQGgKlAIN7a+UUmiBHwUKhCWFQEogIQQCoSwhZF8d70mcxLtsybGtfdfs9/vH8zyjkTSSZkaaecbWeb9eflkzeiRdj0dz5txz77lijEEppZTKlsftASillDo+aQBRSimVEw0gSimlcqIBRCmlVE40gCillMqJz+0BFFJDQ4NZsmSJ28NQSqnjypYtWzqMMY1j759VAWTJkiVs3rzZ7WEopdRxRUQOprtfp7CUUkrlRAOIUkqpnLgaQETkShHZJSJ7ReTmNJ8Pisgv7M9vFJElKZ87U0SeFpGdIvK8iJQUcuxKKTXbuRZARMQL3AK8HlgNvFNEVo+57ANAtzFmBfAN4Cv21/qAO4CPGGNOAy4BogUaulJKKdzNQM4F9hpj9htjIsBdwFVjrrkKuN3++B7gMhER4LXAc8aYHQDGmE5jTLxA41ZKKYW7AWQh0JJyu9W+L+01xpgY0AvUA6sAIyL3i8hWEfnMRD9ERG4Qkc0isrm9vX1G/wFKKTWbHa9FdB9wEfBu+++/EpHL0l1ojLnVGLPeGLO+sXHcMmallFI5cjOAHAYWp9xeZN+X9hq77lENdGJlK48ZYzqMMUPAH4Cz8j5iwBjDPVtaCUV1xkwpNbu5GUA2AStFZKmIBIDrgPvGXHMfcL398TXAQ8Y6wOR+4AwRKbMDy6uBFwsx6H3tA3zqlzt48KW2Qvw4pZQqWq7tRDfGxETkJqxg4AVuM8bsFJEvAJuNMfcBPwJ+KiJ7gS6sIIMxpltEvo4VhAzwB2PM7wsx7qGIlXkMhmOF+HFKKVW0XG1lYoz5A9b0U+p9n0v5OAS8fYKvvQNrKW9BhWMJAEIxncJSSs1ux2sR3TURO4AMRzSAKKVmNw0gWQrbmcewFtGVUrOcBpAsORlIKJpweSRKKeUuDSBZStZANANRSs1yGkCypAFEKaUsGkCylCyiawBRSs1yGkCypBmIUkpZNIBkaSQD0SK6Ump20wCSJWcZr2YgSqnZTgNIliI6haWUUoAGkKxpDUQppSwaQLKkq7CUUsqiASRLIzUQLaIrpWY3DSBZStZAtJmiUmqW0wCSJW3nrpRSFg0gWXIykGjcEIvrNJZSavbSAJKlSErQCMU0gCilZi8NIFkKpxTP9VAppdRspgEkS+HUDESX8iqlZjENIFkKpwQNDSBKqdlMA0iWIvEEJX7rYdO9IEqp2UwDSJbC0QTVpX5Ad6MrpWY3DSBZisRHAohOYSmlZjMNIFkKR+OagSilFBpAsqYZiFJKWTSAZMEYQziWoEoDiFJKaQDJRixhMIaUDERXYSmlZi8NIFlw+mBpDUQppTSAZCU8JoDoFJZSajbTAJIFJwMp8XsJ+DyagSilZjUNIFlwTiMMeD2U+DyjGisq5aawnk+jXKABJAtOBhL0eygNeLUbryoKHQNhzvj8n/nt9sNuD0XNMhpAsuDUQAJeDyV+r55KqIrCsb4QkViCr/5pl2YiqqA0gGQhnMxAvJT6NQNRxcFZzHG4Z5i7nm1xeTRqNtEAkoXUGkjQ79UiuioKwxHrjU1tmZ9vP7SXoUjM5RGp2UIDSBZG1UD8WkRXxcF5I/Pxy1bSMRDmx082uzsgNWu4GkBE5EoR2SUie0Xk5jSfD4rIL+zPbxSRJWM+3yQiAyLyqUKMd2wNRDMQVQyc5+FFKxu47JQ5/ODRffQORV0elZoNXAsgIuIFbgFeD6wG3ikiq8dc9gGg2xizAvgG8JUxn/868Md8j9Uxsg/EQ6nfqxsJVVEI2bW4Er+XT73uZPpCMW59fJ/Lo1KzgZsZyLnAXmPMfmNMBLgLuGrMNVcBt9sf3wNcJiICICJXAweAnQUabzKABLx2EV0DiCoCzvOw1O/l1PlVvOnM+fz4yWZicZ1iVfnlZgBZCKQuGWm170t7jTEmBvQC9SJSAfwj8G9T/RARuUFENovI5vb29mkNOJxSAwn6vdpMURWFZAAJeAHYsKyeoUicrqGIm8NSs8DxWkT/PPANY8zAVBcaY241xqw3xqxvbGyc1g+NpKzC0iksVSyc5eQlPiuA1JcHAOgc0ACi8svn4s8+DCxOub3Ivi/dNa0i4gOqgU5gA3CNiHwVqAESIhIyxnwnnwNOFtF9Hkr8Hg0gqiiEonGCPg8ejwAjAaRrUAOIyi83A8gmYKWILMUKFNcB7xpzzX3A9cDTwDXAQ8YYA1zsXCAinwcG8h08IGUZr8/KQGIJQzSewO89XhM5dSIYjsaT01cA9RVBwGpxolQ+uRZAjDExEbkJuB/wArcZY3aKyBeAzcaY+4AfAT8Vkb1AF1aQcU04lsAj4LOX8YL17k8DiHLTcCROqT8lgOgUlioQNzMQjDF/AP4w5r7PpXwcAt4+xff4fF4Gl0YkniBozzOX2O/4hqNxKkv8hRqCUuMMR0cHkOpSP16P0DmoGYjKL33rnIVwNE7AZz1kJfbfuhtduS0UjSczYgCPR6grD2gNROWdBpAsWBmI9ZCVpmQgSrlpOBqnLKUGAtY0VodOYak80wCShXA0kZKBjNRAlHLTcGR0ER2gviJApxbRVZ5pAMlCOF0Goi3dlcuGo4lRU1gA9eVBOnUKS+WZBpAsRGIJAk4R3W89dKGY1kCUu4YjsVFFdLAykC6dwlJ5pgEkC+HYSAbivOPTDES5bewqLICGiiD94ZhOsaq80gCShUgsZRWW/QurR4gqt6WrgdTpbnRVABpAspCagZRqBqKKRChtDUQDiMo/DSBZiKSZwtIpAuWmWDxBJJ5IUwPRdiYq/zSAZCEcG1nGm8xAdCOhcpGziKM0MPpXWduZqELQAJIFKwOxAoeTiWgGotzkTKGmW4UFaDsTlVcaQLIQjsUJ2I0TPR4h6NOW7spdzvNvbA2kIugj4PPoXhCVVxpAshCJJQj6Rx6yEj1USrls7GmEDhGhoTygU1gqrzSAZCEcSyQzEEDPRVeum2gKC6BO25moPNMAkoXxGYhHz0VXrkpmIGkCiLYzUfmmASRD8YQhljAEvCO/qCWagSiXTTSFBU5DRQ0gKn80gGQoeZyt1kBUEQlFJg4gDRVBOgfDWKdAKzXzNIBkyAkgY2sgGkCUmyabwqorDxCKJhjSbgkqTzSAZMjpeZWagZQGvFoDUa6avAaimwlVfmkAyVA4TQZS4vdoDUS5ylmFVTLBFBboZkKVPxpAMpQMIL7RNRBtpqjcFJpiCgs0A1H5owEkQ8kium/0Kixt567cNBSJ4/MIfu/4X2VtZ6LyTQNIhpI1EN+YjYSagSgXpTtMylFf7nTk1QxE5YcGkAyNZCBjNhLGErpMUrkmFI2nrX+AtcijPODVM0FU3mgAyVAkPr4GUur3Ek8YonENIModw5GJMxDQdiYqvzSAZCgcTV8DAQhpHUS5ZLIpLNB2Jiq/NIBkKF0GkgwgWgdRLhmOJiacwgJoqAhoDUTljQaQDKUroo8ca6ubCZU7QpE4pf6Jf43ry4N06SoslScaQDIUSbMPZORYW81AlDummsKqsxsq6kIPlQ8aQDIUnmAVFuixtso9w9F42kaKjvryALGEoW84VsBRqdlCA0iGNANRxchaheWb8PNOO5MOncZSeaABJEPhNDvRg8kaiAYQ5Y5QNE5pYOJfY6edie4FUfmgASRDTgDxeyV5X6kGEOWyKZfxOu1MdC+IygMNIBkKx+IEfB5ERgLISA1EV2GpwjPGTBlAklNYupRX5YEGkAxFYolRBXQYOQVOayDKDeFYAmPSt3J31JZpR16VPxpAMpQugJT48jeF1TUY4am9HTP+fdWJY7JW7o6Az0NViU/3gqi8cDWAiMiVIrJLRPaKyM1pPh8UkV/Yn98oIkvs+68QkS0i8rz996X5Hms4lhhVQIf8ZiA/eaqZ99z2rLaLVxOa7DTCVA0VQdq1BqLywLUAIiJe4Bbg9cBq4J0isnrMZR8Auo0xK4BvAF+x7+8A3myMOQO4HvhpvscbiSVGLeGFkT0h+aiBHOkZJpYwdA9GZ/x7qxODc5TAZPtAAJbPqeDlI/2FGJKaZdzMQM4F9hpj9htjIsBdwFVjrrkKuN3++B7gMhERY8w2Y8wr9v07gVIRCeZzsOFYfNwUlohYLd3zkIE47xg79J2jmoCTgZRMkYGsXVzD/o5Beof0zYiaWW4GkIVAS8rtVvu+tNcYY2JAL1A/5pq3AVuNMWlfaUXkBhHZLCKb29vbcx5sugwErF/efASQtj7rn6OdVNVEkhlIBgEEYEdrT97HpGaX47qILiKnYU1rfXiia4wxtxpj1htj1jc2Nub8s8JpiuiQv1MJnQxE1++riSRrIFNMYZ2xqBoR2N6iAUTNLDcDyGFgccrtRfZ9aa8RER9QDXTatxcB9wLvMcbsy/dgJ8pASv1eQrGZrYHEEyYZOHT5pZpIphlIVYmf5Y0VGkDUjHMzgGwCVorIUhEJANcB94255j6sIjnANcBDxhgjIjXA74GbjTFPFmKw6VZhgdXOZKYzkM7BMAm7ear2MFITybQGAtY01o6WHu3Kq2ZURgFERMpFxGN/vEpE3iIi/un8YLumcRNwP/AScLcxZqeIfEFE3mJf9iOgXkT2Ap8EnKW+NwErgM+JyHb7z5zpjGcqkViCgDddBuKZ8aW2Tv0DNANREwtlOIUFVgDpHIzQ2j2c72GpWWTiNp6jPQZcLCK1wJ+xsodrgXdP54cbY/4A/GHMfZ9L+TgEvD3N130R+OJ0fna2wrE4wTQH95TkIQNx6h8e0RqImlimU1gwUkjf1tLD4rqyvI5LzR6ZTmGJMWYIeCvwXWPM24HT8jes4jNxBuKd8TPR2+0MZGlDua7CUhMatvcflWWQgZw8r5Kgz8MOrYOoGZRxABGR87Eyjt/b9039rD2BROITL+PNVwZyyvwqncJSE3JqIOlWB47l93o4Y2G1FtLVjMo0gHwC+Cxwr12nWAY8nL9hFZ9wNH0R3doHMrOrsNr6QlSW+FhUU0rnYFgLnyqtkN2JN7VD9GTWLK7hhcO9ROPaPVrNjIwCiDHmUWPMW4wxX7GL6R3GmI/leWxFJTxhBjLzO9HbB8I0VgaprwgQiiYYysM+E3X8G45MfpztWGsX1xCOJdh19Phpa9I5EOY1X3uEJ7WxaFHKdBXWz0WkSkTKgReAF0Xk0/kdWvEwxqTtxgt2DWSGA0hbX5g5lUHqy63uLDqNpdKZ6iyQsVIL6ceLJ/Z2cKBjkP/840uaieeoYyBMS9cQicTMP36ZTmGtNsb0AVcDfwSWAn8z46MpUpH4+PPQHaUBL4OROB+7cxu3PLyXB186xmA4Nq2fZ2UgJcnT5HQviEpnOBpPHmqWiUW1pdSXB9h+6PgJIM/s7wTghcN9PPRym8ujSS+eMHl5cZ4pv9zcysVffZjByPRel9LJdBmv3973cTXwHWNMVESK9xGbYSPnoY//ZX396fPZ+UofWw52c98Oq7/jW89ayNffsTann2WMSWYgzmlymoGodEJZTmGJiLWh8DjqifX0vk4uObmR/e2D/PeDe7j0lDkZ13wK5QO3b2I4Euf295+b0abOQmvuGKShIkBlybS27qWV6duXHwDNQDnwmIicBPTN+GiKVGSSALJ6QRW3vfccnrz5Up77/Gs5Y2E1R3pCOf+swUic4WicxsogdeV6nrWaWLZTWGBNY+1rH6AvVPydeY/0DtPcOcRFKxq46TUreK61l4d3FVcWYoxhy8FuNh7o4mN3biNehJnIgc5BTqovz8v3zrSI/i1jzEJjzBuM5SDwmryMqAiNZCBT9xyaV11C91DuGUNbnxV85qQGEN0LotKwprCyCyBrFtdgDDzX0punUc0cZ/rqvGX1/NVZC1lcV8p//2VPUdVCOgYi9IdirFlcw59fPMa//PaFohofWBnIEjcDiIhUi8jXnbboIvJfWNnIrOBkIOlqIGPVlvmnFUDa+61so7EySInfS2XQp2eCqLSGI9lnIKfMrwRgX/tAPoY0o57Z10V1qZ/V86vwez3c9JoV7Gjt5ZFduR/LMNMOdAwC8MkrVvGRVy/n5xsP8e2H9ro8qhFDkRht/WGWNuSn+0CmU1i3Af3AO+w/fcCP8zKiIuT0uspkw1ZtWYDuoWjO70La7AAyp7IEgPqKgNZAVFqhaHY1EIDGiiBBn4fW7qE8jWrmPL2/k3OX1uHxWDWPt561iEW1pXzzweLJQg50WIF4WUM5/3jlyVb984HdPLWvOJYdN3dY/89LGlzMQIDlxph/tU8P3G+M+TdgWV5GVISyyUBqygJEYomcz0lPzUAA6iuCdOoqLJXGUA4ZiIiwqLaUlq7ibqp4uGeYQ11DnL9s5Pw4v9fDR169nB0tPWwtkpVk+9sHCfg8LKgpRUT40tVn4BF4Zl+n20MDoLnTypBcncIChkXkIueGiFwIFPczcAZlO4UF0JVj3aKtP4zfK9SUWt+nvlwzEJVeLjUQgMV1ZbT2FHcG4rwAn7ds9AGkV69bSHnAy883HnJjWOPs7xhkSX0ZXjtLKg14WdZYwYtFcga9M8XmdgbyEeAWEWkWkWbgO0xyCuCJJtMiOkCtXfjuyfH86fb+MA0VwWTaXl8RpGMGA8hvtx/mDf/9eFGuFlHZyWUKC6z9IMXe1v2Z/Z3UlPk5ZV7lqPsrgj6uWreQ/3vulaI44/1AxyBLx7w4nzq/ipeOFMciVWsJb5CKYKY7NrKT6SqsHcaYNcCZwJnGmHXApXkZURHKLgOxAkiuhfS2/hBz7OkrgIaKAF2D4RnbqPTIrnZePNLH4SJ/AVGTi8YTROOGshwykEW1ZfQMRekv4qW8T+/vZENK/SPVu85tIhxL8OttrS6MbEQ8YTjYOcjShopR9586v5LDPcP0Drv/+B7sHMpbAR2yPJHQGNNn70gH64CnWSG7Iro19dQ9jQykMSWA1JcHSBjomaEn4+5jVmp9PKzCURPL5jCpsRbXWi8oxZqFtHQN0do9PKr+ker0hdWsWVTNzzcecrWY3to9RDRuWJYmAwF4uQiykAOd+VvCC9M70ra4toPmUTjLIjpAd441ECuAlCRv1yd3o0+/kB5PGPa2WYHD+Vsdn7I5znasRbWlQPEGkOT+j+XpAwjAuzY0sadtgM0Huws1rHH22/WFpY2jX6BX2wHE7WmsgXCM9v5w3uofML0AMmsm0SdrZTJWTTIDyT6AROMJuoYiozMQpx/WDNRBWrqGkv8WzUCOb6GI9f+Y7SosSA0gxVlIf2Z/F3XlAVbNqZzwmjevWUBl0OdqMf1AuxVAxmYgzibgl1wupDc7Ac6tACIi/SLSl+ZPP7Agb6MqMtnUQPxeD5UlvpyK6J0DEYxhTA3EzkBmYCmvM31VEfQdtxlIOBbXBQCMZCC5TGHVlQcoC3iLdinvpuYuzl2Svv7hKAv4uHrdQn7//JGcs/3pOtAxSFWJL9kxwiEinDKvkpeOupuB5HsJL0wRQIwxlcaYqjR/Ko0x+SnrF6FsVmGBs5kw+yf12D0gYNVAYGYaKu6xg8alp8xhb/tA0WzGysZ7fvQs/3rfC24Pw3XJAJJDBuLsBSnGDKRrMMKhriHWNtVMee27NjQRiSX49bbDBRjZePs7BljaWJG2ueOp86vYdbSfmIuHdx3sdDYRFkkRfbaarJliOlY7k+wzkLb+kT5YjpqyAB6ZmX5Yu4/1s7CmlDWLa+gZiua8V8Utg+EYm5q72G9PHcxmzjHKuXZ/XVRbVpQ1kOfsTsFrFk0dQE6dX8WaRdX8xqUAcqB9cNz0lePU+VWEY4lkFuCGAx2DzKkMUhbI33t9DSAZcFZhBbwZBpDyQE5pdboMxOsR6soDkxbRQ9E4e9umnm/dfWyAlXMrWDHHWnZ4vE1jPdfaS8JQFMsj3TadVVhA0WYgO1p6EYEzFlVndP3rTp/H84d7OdJb2GA4HInzSm9okgBi1W/c3FDY3DGY1wI6aADJSCSWwO+VSedkU+U6hdWWJoAA1JcHJ53C+vx9O3nDt56Y9IU1Fk+wr22AVXMrWW6vGtl3nL2T326fpDcbA8izB7r49C93JPcDTWcKC6ylvH2hWNE9ljtae1jRWJHxxrfXrp4LwF9ePJbPYY3jZBZjV2A5VsypwOcRV1diNXcOsjSP9Q/QAJIR6zjbzH9Ra8r8ORXR2/vDVJf6x/2suvLAhEX0lq4h7tnSSiSWSC5/TOdg1xCReIKVcypYUF1Kqd973GUg2w5ZSzaL7UWvEG5/qplfbmlNHgblTGHlGkCKcSWWMYYdLT2sWTz19JVjeWMFSxvKeeClwp4T4kyjTrTCKejzsmJOhWsBpD8UpWMgohlIMQjHEhmtwHLUlgUYCMeStZNMjd2F7pisI+93H9mLR4QSv4cn907cAXSPvQJr1dxKPB5hWWP5cbWU1xiTPMu7PxSbVSux4gnDE/b/7QP2O+3kPpBAbr/Ci4pwM+HhnmE6ByOsyXD6CqwFAVesnsvT+zoKurPe6cI72QonN1uaOAX0fO5CBw0gGYnEEhnXPyC1H1Z201hjd6E7GiqCac8Eae0e4pebW7nu3MWct6yeJ/ZMHEB2H7Oe8E79Y8WciuMqA3mlN0R7fzj5jq9vFmUhO1p76B2OEvR5+MtLVgAJTXcKq87KQFq6iicD2WEfcpVNBgJwxeq5ROOGR3cX7pyQ/R2DzKsqoXySqbZT51dyrC/symKVfDdRdGgAyUA4FifozyYDya2dSVt/OH0GUh6gLzQ+o/nuI/sQgY+8ejkXrWhgf8cgh3vSv6PcfayfRbWlySf88sYKDvcMJ6dCit12u333q1c1ArNrGuux3e2IwIdftYzdxwY42Dk47VVY1aV+KoK+ospAdrT2EPB6OGVeVVZfd1ZTLXXlgWR2VggHOgZZNkH9w3GqizvSnU2EJ9VpAHFdJJ5lBpJDQ0VjzIQZiNPOJPWdzOGeYX65uYV3rF/MgppSLl5pvbA+OUEWsufYACfPHdnZ62Qix8s01rZD3QR8Hs5bVgfMvgBy5sJq3r5+MWBNYw1H4/i9gj+L52Wqkb0gRRRAWno4dUFVVtPFYK1UvPSUOTz8chvRAuy7MMawv318F96x3AwgBzqtDCnXVXqZ0gCSgXA0kVUG4rQzyWYKqy8UIxxLJE8iTDXSzmRkGut7j1jHZn70NSsAWDW3gsbKII+nqYNE4wn2dwywMiWALG88vgLI9pYezlhYndyZP1sCSO9QlO0tPbxqVSOL68o4ZV4lD7x4jKFIbmeBpLL2ghTHFFY8YXj+cC9rs6h/pLpi9Vz6QjGePdA1wyMbr3soSu9wdMoA0lARpLEyyIsuBJCDnUN53UDo0ACSgWwzEKe1Qdfg6Be53+14hau+80TaAvDRXnsTYVW6Goi9G93OQHYd7efuTa1cc/ZiFtZYc9kiwkUrGnhqb8e41u8HOweJxg2r5o60nV7SUIZHYN9xUAeJxhPWi8viGqrtg7ZmSwB5cl8HCQOvsqfuLj91LpsPdnOkd5iyab67dDKQYuhIsLdtgKFIPOv6h+PilQ0EfZ6CTGMlj7GdYgoLnEJ6+r0giYTh7k0teSn+N6c5pyQfNIBkIBzNbhnvRFNYj+9pZ0drb7InVSpnB67TyTNVfflIR962/hDv/8kmasr8fOLylaOuu2hFA52DkXE9eJwC+qqUDCTo89JUV3Zc7AV5+Ug/4ViCdU2zL4A8trudyqCPtfYL6xWr5xJPWAXjXAvojkW1pQyEi2MviLM8+cwMdqCnUxbwcfHKBh548VjeA6Kz+GTsOSDpnDq/kr1t/QyEY+M+99DLbXzmV89x9+aZPdekLxSlczCS1x5YDg0gGQjHs1vGW+L3UuL3jJvCaraX1m1Lc57z9pYeKoO+5NRSKmcKq6VrmA/evpmuwQi3vfcc5laNnu66cEUDwLjlvLuO9iPCuO9dLCuxYvHEpL/021us/R9rF9dQlUUA+c22w5MubS52xhge293OBSvqk7WOMxZWM6cySCiamPYU1uK64lnKu8N+/k+0szsTV6yey+Ge4eRy73zY3NzFf/zhZRZUl7DY3kszmStPm0c0brh36/gg8bONBwHYcjCzabdMD5V7dr/1/VYvyG4xQi40gGQgHI1n3AfLYe1GH/0i56yMcDbEpdp2qIe1TTVpd7tXBH0EfB5ueWQvzx/u5dvvXMfpC8fPFc+rLmHlnAoeH1NI39PWT1Nd2biC2vLGCg50DLq6pyKeMLzte0/xtu89NWH7l22HemioCLKwppQSv5egzzNlAHm+tZdP3r2dj925jaHI+Hd/x4N97QO80htKTl8BeDzCZadau6+nWyB1NhMWw1LeHa09nLGoOuNuD+lcsXoedeUB3vfjTTy+Z+aX9N6/8yjv/uFG6soD/OLD5+PLYFp7XVMtaxZV85Onmke9SWrtHuKR3e34PMKWg91TZk1t/SHO+Pz9GU3R/WnnUapKfGxYOvF5KjNFA0gGasr8yZVQmaotG90PazAcS7YqGfsOaSgS4+WjfclpirFEhIbyAJFYgs+9aTWX2+0b0rlwRQObmruS+wTAmsJKnb5yLJ9TQSSemJEXkEd3t3PlNx/j/T/ZxL/9bie3P9U84ZLiVL/e2sqO1l62t/Rw3a3P0NYXGnfN9pYe1jXVJLueVpf6Jz0PO54w/PNvnqc84KNzMMLPnnHvzIjJJBJm0kD46G7rjcCrVjaOut9p3zH9KayZyUD2tg3w9Qd2885bn+GPzx/J+utD0TgvH+nPuf7hqCsP8JuPXsj86hKuv+1Zfvj4/hmbzvrZxoPceMcWTplfxT0fOT+ZvWXivRcuYV/7YHIzKMBdz7YgwAcvXsaxvvCUvysb93cxGInz4ycPTHpdLJ7gLy8d4/JT52a9mi0XGkAycNcN5/Ofbz0jq6+pLfePqoE4O0NPnV/F3raBUS+Az9tNAtdN0sL6TWsW8LHLVlWUmG4AACAASURBVPK+C5dO+nMvXtlAKJpgq31SW89QhOaOwVEFdMdMrsR6am8He9oGONIb4hebWvjX+3by1u8+ySuT/GKEonG++Zc9nLmomp9+YAMt3UNc8/2nRwW0nqEI+zsGRwXX6lL/pC+8P994kOdae/niX53ORSsa+MFj+4puv0vvcJS/uW0jF375oeQCirEe293OsobycS9W5y+vpyzgnfYUVnWpn6oSX04rseIJw882HuSN33qcy7/+KN9+aA/7Owa48Wdb+c5De6Z84X6+tZfnW3s51hfi+cO9xBImow68U2mqL+NXN17AFavn8sXfv8SNd2zl7s0tvHC4N9kUNVvH+kL8870vcNHKRu780Ias30y+4Yz5NFQE+MmTzYC1KOQXm1u45OQ5vHnNfAC2THGyojPt/dS+Tg5O0uH32QNd9AxFed3p87IaY65mzZkehVZTFuBIz0gx22m+9tZ1C/nSkT62t/YkN8U5GcnaxbUTfr9/esOpGf3cDcvq8XmEm3/9PJFYgqP2O/rV88dPea1oHOnK60yLpPr9c0e4d9thPvqa5ZzVNPHYAHqGojRUBPjjxy/GGGtJ5rv/ZyPv+/Emfnnj+VSV+Md9zR3PHORwzzBfveZMLlzRwM8+uIH3/ngT13z/Kd6yZgGLasuSO85Tg2tN2cQBpK0/xFfv38WFK+p5y5oFLKgp5e3ff5qfbTzIBy9eNum/oVBau4d434830dw5iDHw7Yf28KW/Gv0GJRSNs/FAJ9ed0zTu60v8Xj7/5tNoTLNiL1u5tHXffayff/zVc2w71MPpC6v4lzet5k1nzqe61M/Nv3qOr/15N3vbBvjy285MG+T2tvXz5u88Me7+NYtzW8I7VnnQx/fefTbfeXgv3390H3/aeRQAn0dY2lDO8sYKls8pZ9XcSl532rwpA7HTJfuvNzTl1Bo96PPyrg0n8e2H9nCwc5AXX+mjvT/Muzc0cfLcSsoDXrYc7OaqtQsn/B5bD3WzrLGc5o5B7t7cwqdfd0ra6/608yglfs+4rDVfXA0gInIl8N+AF/ihMebLYz4fBP4XOBvoBK41xjTbn/ss8AEgDnzMGHN/AYc+JetMkJEMxGktcNXaBfzHH19i26HukQByqJsl9WXjTjbLRUXQx7XnLGZ7Sw+r5layam4lp8yvTPuEqi7z01AR5Ml9nXzgoqWj5nQfevkYH79rGwlj+MtLx3jjmfO5+cpTJkzde4Yj1JRa4xcRzlxUw/f++mze++Nn+egdW/nx+84ZtemtPxTllof3ctGKhmTxf11TLXd/+Hz+4Zfb+d+nD46cRe/1jFqdU13q55We9O/a/+P3LxGOJvj3q05HRDhnSR0XLK/nB4/t56/PO2na79qHI3E+dc8O1iyq5oZXLc/6659r7eH9P9lMOBbn9vefy59eOMrPNx7ihlct46SUVTPfenAPoWiCKyd4J/mOcxbn/G9Itai2NOMzKzoGwvz06YN895G9VAR9fOPaNVy9duGoA5W+ce1aVsyp4Gt/3s0rvSHu+tB54+oaz9hF3i+/9QyiCUN7X4jqsgDzq6cuSmfK4xE+dtlK/vY1KzjYOchLR/p58Ugve44NsKetn7+8dIxYwnDxygb+5z3rJ31eOCuoMu0QnM67NzTx3Yf38r9PH2T3sX4WVJdwyclz8HqEdU21bG6eOAMJx+K8+Eof77toCXuODXDPllb+/vJV42owiYTh/p1HuWTVnLxvIHS4FkBExAvcAlwBtAKbROQ+Y8yLKZd9AOg2xqwQkeuArwDXishq4DrgNKyjdf8iIquMMUUzT1FXFqB3OEo8YfB6hIOdgzRWBplTVcLJcyuTKakxhm2Herhg+cwVvMa+m53Mey84ia/9eTfvue1ZbnnXWdSWB9jU3MWNd2zl1PlV/Oj69dyx8RC3PraPB3Ye46vXnMnV68a/U+oZiiY3UDouWtnAf771DD59z3P806+f5ytvOzP5YvI/jx+geyjKZ648edTXnDyvkv/7OyuL6RiI0No9RInfO+qXt6rUn3Zt/TP7O/nN9lf42KUrWJay4uzjl63k2luf4ecbD/H+iyafApxMOBbnw3ds4bHd7bxwuHfKAGKM9Qv9xN4ODnYOcahriJauIRbUlHLXDRtYMaeSFY0V3L25hW/+ZQ/fuHYtYL2h+P6j+3j72Ys4b1l+C6GL68p4Ym8HxphxJ+vFE4Zv/mU32w718PLRPjrshp5Xr13Av7xpddqpHBHhpktXEvR5+dIfXmLXsf7kjmzHloPdNFYGufacxWlP85tJXo+wrLGCZY0VvPHM+cn7o/EEv9rSymfvfZ4P/e/mSYPIoB1AJut7NZW5VSW8/oz53PnsIYYicT55xSq89u/CWSfV8p2H9jAQjqUNUi8c7iMST3BWUy1nNdXy4Z+28eju9nGzBttbezjWF57wTUc+uFkDORfYa4zZb4yJAHcBV4255irgdvvje4DLxHrGXQXcZYwJG2MOAHvt71c0asoCJMxI07/mjiGW1Fvv3tc11bLtUDeJhOFIb4i2/jDrppgiypebLl3J196+hs3N3Vx1y5P8bscrvP8nm1hYU8pP3ncOc6pK+OQVq3jkU69hbnWQeyc4/S1dAAF4+/rFfOyylfxySytnffEBPvzTzfzw8f388PH9vPGM+ROu+xcRGiuDrGuqHfcCNFEN5OFdbQS8nuTufMeGZfWct6yO7z+6j2N9oVHz88YYmjsGuXdbK8+39k74OMXiCT525zYe293OuUvqONg5lLbg7+gYCHPjHVv5yB1b+e32V+gdjnLGwmpuunQl9370QlbMsRY1zKkq4b0XLOU32w+z62g/w5E4/3D3DuZVlfAvb1494fefKcsayxmKxNOej771UDfffmgvbf0hXnPyHP6/N57KvR+9gG9et27KOsAb7Bfrp/eNP2JgU3MX60+qzXvwmIzf6+G6c5v4/69ZwxN7O/jQ/24etfAkVTIDKZne++33XrCEoUgcr0e4NiWDPPukWhLGWsqcjrNqc11TDZeeMoeGiiB3bWoZd939O4/i8wivOWXOtMaZDTensBYCqY9CK7BhomuMMTER6QXq7fufGfO1aScQReQG4AaApqbx88n5UlvuNFSMUFse4EDnIJfYU1brmmq489lD7O8YZNfR/uR9brnm7EUsayznwz/dwt/duY351SX89IOji4XzqktY1lAxYX8vawor/b/h7y9fyclzK3lkVxtP7+/k/p3H8HmET752VU7jrS71MxCOEYsnRqXxbX1WL7F07yQ/cfkqrrv1GTb8x4PUlvk5eV4lFUE/21u6k++sPXZjyk9cvmrUCpZEwvCZe57j/p3H+NybVnP2SbVcdcuTPNvcxZvOXDDuZ/3phSP8870v0B+K8dnXn8IHL16WfLeZzkdevYyfPXOQ//rzLhbVlrG/Y5A7PrAhbd1opjmLE7a1dNNUP3p60nnh+vmHzku2kMnUwppSTqov46l9naOyvqO9IVq7h6dcDFIo15y9CIBP37ODG+/Ywm3vPWdcYJuJKSyAs5pq2LC0jgU1paP2cFkrDGFzc3dyOjfVtkM9LKotTbY5etvZC/nh4wdo6wsxx/4+xhjuf+EoF6xoSG62LYQTvohujLkVuBVg/fr1BdvwUJPcjR5lMByjvT+cbK18lh0sth3qZtfRfoK+7DuQzrSzmmr53U0X8d1H9vKe85ckW6SkqisPsL8j/YqtiTIQsLKJN545PzmF0NI1xHA0nnbTZCacX5C+UGxU3ehYX4i5ExSWz1tWz303XciWg93sPtbPrqP97O8f4FUrG1m/pM5aCfb0Qb77yD4e2dXO169dw2A4xp93HuP+nUdp7hziH65YxfsvWkosnqAs4GXTgfEB5O7NLXzmnuc4fWEVd75jbdrl02PVlAW44VXL+K8HdgPwnvNP4qKV419I8uHkuZWU+r1sO9Qzroi79WAPTXVlWQcPxwXL6/m/544kp3EBNtub5taf5E7Gnc41Zy9ib9sA3390H4OR+LhAMRNTWGD9Htz5ofMYm3hVlfg5eW4lW9LsDwMrE1y/pC55+9r1i/nBo/v51dbD3HiJNY2661g/zZ1DOdXlpsPNAHIYSK0ELrLvS3dNq4j4gGqsYnomX+sqp51Jz1AkWaR0Wgssa6igssTHtpYedh/t5/SF1QVZsz2VedUlfOGq0yf8vLW3ZfzUUSgaJxxLJIPmVLJZQ5+OE6h6h6PjAshkL9hnLqqZtFXGV645k8tOncNnf/08V37zccBauXP+8no+fvlKrrZfYH1eD2c11fJsmsLn3ZtaWDW3gns/emFWnXLfd9FSfvJUMxUlPm5+ffoVNvng83o4c1H1uM2txhi2Hurm/GnU5s5bVs+dz7aw85Xe5OO+ubmbUr+3ILuks9FkPycHQuPrEAOhGCJQNs0FGMCEGyXPOqmW321/ZVSwBTjSO8yR3lDyTSfAssYKzl1Sx0+eOsBwNE5TXRmbm7sQsXbjF5KbAWQTsFJElmK9+F8HvGvMNfcB1wNPA9cADxljjIjcB/xcRL6OVURfCTxbsJFnoK7MaagYIRS1VhM53TE9HmHt4hqePdBFS9cQf3PeSa6NMxu1ZdbUUTgWH9UbzDm+d6IMZKZN1A+rrT+cbGufq9eeNo91TbX89JmDLG8s55KT56SdEjhnSR3ffHA3vcPR5Ofb+kNsOdTNJy5blXWb9Yqgj9/87YWUBrw5LRWdjnVNtfzoif2EoiMdfpO1uWls7nOCz1P7OkcCyMEu1i6uybkNfb5U2vWN/lCUedWjWwQNhOOUB3zT2iU/lbObavn5xkPsaesfNRvhLLYZWyP9+ytW8el7dvDth/bglPTOXVqX9jiIfHItgNg1jZuA+7GW8d5mjNkpIl8ANhtj7gN+BPxURPYCXVhBBvu6u4EXgRjwt8W0Agugptxp6R5N7kBPbW62rqmWxx/ck/z4eDBy0mKUuVUjAcSpi9QUaO41XQAZisToD8XSdjPOVmNlkE9eMXl95pyltRgDWw92J4uWViM/cl4FM93MLFfrmmqIxg07X+njbHtqyXnhOmsaU01zKq3WOk/t6+Qjr17OYDjGS0f6+eglhZ1myYRTIO9P0/RwMByjPJjfZbHrl1iP85aD3aMCyNaD3QR9nnFNVs9fXs8T/3gpkViCwz3DHOoaGnXeT6G4+jbAGPMHY8wqY8xyY8yX7Ps+ZwcPjDEhY8zbjTErjDHnGmP2p3ztl+yvO9kY80e3/g0TqQz68HmEbnsn+JzK4Kg51NSUdK2LBfRsjLSpH11IdzKQahczkLY+K0jPTXOeSj6sW1yL3ytsTDl/4k8vHGVpQ3naXf/FzMkyUqexth7qnpHa3PnL69l0oItILMH2lh7iCTNqPr9YVCUzkPEBZKLltTPJqjUF2DJmWnSbfQ7ORFPcAZ+HpQ3lvHpV47jMqRCKK488gYgINWV+uoeiNHcOjmut7Kx+mVMZZIEL//G5mKhNfe+wk4FMfyNkJpIdeVPGccxeUju2Q3G+lAa8nL6wmk3NXfZYojy9r5PXnTbP1eWpuZhTVcLCmtJRPdq2Heqe9IUrUxcsr2c4Gue51h422fP0bq44nEhF0HpODbgUQESEs5pq2XSwK7nMPBKzzsEpxsfLoQEkj5yGigc6xp8OVlMW4LQFVZy/vP64ecFxMpCxhXQnA3GWLudbugzkmD1NONEqrHw4d0kdz7X2EIrGefBla2fz604rbBFzpqxtqkmeOx+OxXnhlb5pTV85NiytR8SqgzjTM4VYnpyt1BrIWNYUVv5n+y85eQ4tXcPcZHeQfvFIH5FYYso2Qm464Zfxuqm2LEBrzxAdAyNLeFP97IMbiq6YOJlae4qqa0wG4rStL1QGEvRZ562MnsJyTnQsXDZ3zpI6fvDYfra39PCnF44yr6pkRhoCumHd4hp+/9wRjvWFONIbIhJLTKuA7qgtD3DqvCqe2NPBzld6eetZi2ZgtDPPqYGkO/hpIByjqTz/9al3nruY3uEoX73/Zfa1DXDB8pEWP8Xq+Hn1Og7VlPl52W65sTTN6WA1ZYGCvLOZKcm9LWNrIMMRAj4PJVmcGz/tsZQGRmcgfSFK/J7kXHYhOIXPR3e38+judl532ty8rtTJJ+dFatuhnmQn55l64bpgeT3PNlvtyJ3HrNhU2Cvf+lyawgJrGuvGS5bzk/edyys9w9z25AEWVJe4UtvIlAaQPKotCxCzD2s6qQDHS+ZbwOehMugbV0TvHYpSU+ov6FTc2HYmx/rCzKksKegYasoCnDy3ktufaiYcSxSshXY+nLagCr9X2NbSzbaWnhl94bpgxchekmIsoIO1tL4i6EtbAynUFJbj1asa+d3fXcTaxTWj+ncVo+Pn7e9xqDZlk9vYGsjxqrY8MO6o3sl2oefL+AAy8S70fDpnaS27jvVTW+bn3CJ9ccxEid/L6gXVbDvUwys9wzM6bXLOkjq8HmFOZTBth4NiUVniS1sDGQjHpt0HK1sn1Zfzm7+9sKA/MxeageSRUzOYWxUs+OawfKktD9A15jTAnuFIxrvQZ0pVqZ/e4ZF3i+394YLWPxzn2EHjitVzMzritJitW2wV0lu7h2d05U9liZ8rTp3LG84o7nfTFUHfuBpIOBYnGjcFmcI6Hh3fz/gi5yx7HbuE93hWW+YfXwOxp7AKyTrWdvQy3kLtAUl10YoGljWUj+querxa11RDJJ6wP57ZWsX3/+Zs/uVN+e8uPB1WBjI6gAyGrf3J5QU6X+N4o2E1j5xpnRMpgNSVBdhzbHRDxZ6hKGcucm8KayAcYzASd2UKq74iyEOfuqTgPzcf1tknYvq9wmlF1quqECpKxh8T4NREKopw6XEx0Awkj5x9E+mW8B6vassD4zYSujGFVVPmZzASJxpPFHwT4YlqcV0p9eUBTltQPe2TG49HlUEfA2NqICOt3Gff45EJzUDyqKm+jKDPk+wvdCKoKw8wFIknG++FonFC0URBzyCAlJbuw9FkAJmJPlizmYjw71efXvD/y2KRdgorMjOt3E9U+qjk0ZzKEl78wpWTHiZ0vBlpUx9lXrU3mfLXFjgDSd2NnuyDpRnItBV7oTuf0hXRk1NYGkDS0imsPDuRggek7Ea3C+nJTrwuLOMFK4DoFJaaCZUlfoYicWL2QgKYudMIT1QaQFRWnL0tTuBIngVS4GmPqlEBJEx5wKu/5GpanL0ezsor62OdwpqMBhCVlbEt3Qvdyt0xKgPpD2n2oabNaajYl1JIT2YgBd5IeLzQAKKyMrale7KVu6s1kFDBT2JTJ57K4PiGis7H5SfIRuCZpgFEZcWpdTgt3ZOt3N3KQOwTHzUDUdNVae/1SF2JNRiOUer3nnC1zJmiAURlxe/1UFniS2Yg3UNRAl4PpQXeNxDweSgLeJNFdDc2EaoTy0hL99FTWDp9NTENICprdeWBZA2kdzhCdVlhO/E6qkv9tHQPEYomNANR01aZ5ljbgXBcF2dMQgOIylptWWDUKqxCr8ByVJf6k21V3GikqE4sTg1k7BSWBpCJaQBRWUvNQHqGogXfROioKvXT3DkIwFwtoqtpSlcDGQjFKNc2JhPSAKKyVlsWSBbPe4ajBV/C66gu9WOf16VTWGraSvwevB4ZXwPRDGRCGkBU1mrL/CkZSMS1KazUn6t9sNR0ici4fliDEQ0gk9EAorJWWx5gOBpnOBJ35TRCh7OUt7LEd8Ic2KXcNfZYW2sKS59bE9EAorLm7EY/2hdiOBov+CZChxNAdPpKzZTKEj99odEbCTUDmZgGEJU1p2je3GEVsF3LQFKODFZqJlQGfckaSDSeIBxLaACZhAYQlTUnAzngBJBSdzOQOS4cZatOTKk1EG2kODUNICprTtuS/R3WHgy3MhCnI68W0NVMqSgZORNEW7lPTQOIylrtmAzErRPskjUQzUDUDBmdgVht3bWVycQ0gKisOctnD7S7WwNZXFtGid/DaQuqXPn56sRTEfQnV2E5tRCdwpqYPjIqaz6vh+pSP6/0WicBurUTvbEyyAuffx0+r74PUjOjssRHJJ4gFI0z4GQguhN9Qvqbp3Li1EH8XqEs4N4vmAYPNZMqS0bOBBlM1kDcybCPB/rbp3Li1EGqSwOudOJVKh9SO/I6U1naC2tiGkBUTursaSu36h9K5YOTbQyEYroKKwMaQFROnAzErT5YSuXDSAYS1X0gGXAlgIhInYg8ICJ77L9rJ7juevuaPSJyvX1fmYj8XkReFpGdIvLlwo5ewchmQrfamCiVD0620R+2MpCgz4Nf62wTcuuRuRl40BizEnjQvj2KiNQB/wpsAM4F/jUl0HzNGHMKsA64UEReX5hhK4czdaVTWOpEUpVyJoj2wZqaWwHkKuB2++PbgavTXPM64AFjTJcxpht4ALjSGDNkjHkYwBgTAbYCiwowZpUiWQPRKSx1Akmei25PYekmwsm5FUDmGmOO2B8fBeamuWYh0JJyu9W+L0lEaoA3Y2UxqoCSNRDNQNQJpCLlWNuBcIxyPSZgUnl7dETkL8C8NJ/659QbxhgjIiaH7+8D7gS+ZYzZP8l1NwA3ADQ1NWX7Y9QEnBpItdZA1Akk4PMQ9HkYCOsUViby9ugYYy6f6HMickxE5htjjojIfKAtzWWHgUtSbi8CHkm5fSuwxxjzzSnGcat9LevXr886UKn0FteW4fcKS+vL3R6KUjOqssRHXyjGYDhOY6U26pyMW1NY9wHX2x9fD/w2zTX3A68VkVq7eP5a+z5E5ItANfCJAoxVpTGvuoRN/3w5F66od3soSs2oyhJ/MgPRJbyTcyuAfBm4QkT2AJfbtxGR9SLyQwBjTBfw78Am+88XjDFdIrIIaxpsNbBVRLaLyAfd+EfMdjVlugtdnXgqgj76Q1F7Ckt3oU/GlfBqjOkELktz/2bggym3bwNuG3NNK6CvWkqpvKgssc5FH9QayJR0h4xSSqWoCProHY4yFInrFNYUNIAopVSKyhI/R/usowo0A5mcBhCllEqReiqhBpDJaQBRSqkUlSm7z3UKa3IaQJRSKkVq1qEZyOQ0gCilVIrKkpH2PNoLa3IaQJRSKkVq0NBeWJPTAKKUUilSayA6hTU5DSBKKZWiMrUGolNYk9IAopRSKVJrIOXaymRSGkCUUiqFk3X4vULQpwFkMhpAlFIqhVMD0frH1DSAKKVUCmfllW4inJoGEKWUSuH1CBVBn2YgGdAAopRSY2gAyYwGEKWUGqOyxKdTWBnQR0gppcb4u8tWUqV7QKakj5BSSo3xljUL3B7CcUGnsJRSSuVEA4hSSqmcaABRSimVEw0gSimlcqIBRCmlVE40gCillMqJBhCllFI50QCilFIqJ2KMcXsMBSMi7cDBHL+8AeiYweGciPQxyow+TlPTx2hqhXyMTjLGNI69c1YFkOkQkc3GmPVuj6OY6WOUGX2cpqaP0dSK4THSKSyllFI50QCilFIqJxpAMner2wM4DuhjlBl9nKamj9HUXH+MtAailFIqJ5qBKKWUyokGEKWUUjnRADIFEblSRHaJyF4Rudnt8RQLEVksIg+LyIsislNEPm7fXyciD4jIHvvvWrfH6jYR8YrINhH5P/v2UhHZaD+nfiEiAbfH6CYRqRGRe0TkZRF5SUTO1+fReCLy9/bv2gsicqeIlLj9XNIAMgkR8QK3AK8HVgPvFJHV7o6qaMSAfzDGrAbOA/7WfmxuBh40xqwEHrRvz3YfB15Kuf0V4BvGmBVAN/ABV0ZVPP4b+JMx5hRgDdZjpc+jFCKyEPgYsN4YczrgBa7D5eeSBpDJnQvsNcbsN8ZEgLuAq1weU1Ewxhwxxmy1P+7H+qVfiPX43G5fdjtwtTsjLA4isgh4I/BD+7YAlwL32JfM6sdIRKqBVwE/AjDGRIwxPejzKB0fUCoiPqAMOILLzyUNIJNbCLSk3G6171MpRGQJsA7YCMw1xhyxP3UUmOvSsIrFN4HPAAn7dj3QY4yJ2bdn+3NqKdAO/Nie5vuhiJSjz6NRjDGHga8Bh7ACRy+wBZefSxpA1LSISAXwK+ATxpi+1M8Za434rF0nLiJvAtqMMVvcHksR8wFnAd8zxqwDBhkzXTXbn0cAdg3oKqyAuwAoB650dVBoAJnKYWBxyu1F9n0KEBE/VvD4mTHm1/bdx0Rkvv35+UCbW+MrAhcCbxGRZqzpz0ux5vtr7GkI0OdUK9BqjNlo374HK6Do82i0y4EDxph2Y0wU+DXW88vV55IGkMltAlbaKx0CWEWr+1weU1Gw5/J/BLxkjPl6yqfuA663P74e+G2hx1YsjDGfNcYsMsYswXruPGSMeTfwMHCNfdlsf4yOAi0icrJ912XAi+jzaKxDwHkiUmb/7jmPk6vPJd2JPgUReQPWPLYXuM0Y8yWXh1QUROQi4HHgeUbm9/8Jqw5yN9CE1Tr/HcaYLlcGWURE5BLgU8aYN4nIMqyMpA7YBvy1MSbs5vjcJCJrsRYZBID9wPuw3tzq8yiFiPwbcC3WCshtwAexah6uPZc0gCillMqJTmEppZTKiQYQpZRSOdEAopRSKicaQJRSSuVEA4hSSqmcaABRagaJSFxEtqf8mbEmgCKyRERemKnvp9R0+aa+RCmVhWFjzFq3B6FUIWgGolQBiEiziHxVRJ4XkWdFZIV9/xIReUhEnhORB0Wkyb5/rojcKyI77D8X2N/KKyL/Y58L8WcRKXXtH6VmPQ0gSs2s0jFTWNemfK7XGHMG8B2s7gYA3wZuN8acCfwM+JZ9/7eAR40xa7B6Q+20718J3GKMOQ3oAd6W53+PUhPSnehKzSARGTDGVKS5vxm41Biz325CedQYUy8iHcB8Y0zUvv+IMaZBRNqBRaltKey2+Q/YhywhIv8I+I0xX8z/v0yp8TQDUapwzAQfZyO1z1EcrWMqF2kAUapwrk35+2n746ewOvUCvBurQSVYx7jeCMkzdG0MqQAAAIZJREFU1asLNUilMqXvXpSaWaUisj3l9p+MMc5S3loReQ4ri3infd/fYZ3G92msk/neZ9//ceBWEfkAVqZxI9ZJdEoVDa2BKFUAdg1kvTGmw+2xKDVTdApLKaVUTjQDUUoplRPNQJRSSuVEA4hSSqmcaABRSimVEw0gSimlcqIBRCmlVE7+H04k8kUJQdelAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYTMTW0P8eBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "7608366f-d1ee-41aa-ae53-e638fcf3bd52"
      },
      "source": [
        "plt.plot(range(len(value_loss)),value_loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYZs3x_jwKVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}