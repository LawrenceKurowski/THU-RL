{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCWQ9yUT3W61"
   },
   "source": [
    "# Setup (should take < 100 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kB9McZ4THuor",
    "outputId": "6d8e898e-f103-4cfb-c18c-ac087bc12287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]    \n",
      "Get:8 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease                        \n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]     \n",
      "Get:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
      "Get:13 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [88.1 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [37.4 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [889 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [12.6 kB]\n",
      "Get:18 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,811 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,372 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [839 kB]\n",
      "Get:21 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [8,213 B]\n",
      "Get:22 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [44.6 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [59.0 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,183 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [7,674 B]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [8,286 B]\n",
      "Get:27 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [874 kB]\n",
      "Fetched 7,526 kB in 4s (1,850 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  gir1.2-ibus-1.0 libcapnp-0.6.1 libdbus-1-dev libibus-1.0-5 libibus-1.0-dev\n",
      "  libmirclient-dev libmirclient9 libmircommon-dev libmircommon7\n",
      "  libmircookie-dev libmircookie2 libmircore-dev libmircore1 libmirprotobuf3\n",
      "  libprotobuf-dev libprotobuf-lite10 libpulse-dev libpulse-mainloop-glib0\n",
      "  libsdl2-dev libsdl2-gfx-1.0-0 libsdl2-ttf-2.0-0 libsndio-dev libudev-dev\n",
      "  libxcursor-dev libxinerama-dev libxkbcommon-dev libxrandr-dev libxv-dev\n",
      "  x11proto-randr-dev x11proto-xinerama-dev\n",
      "Suggested packages:\n",
      "  libsdl2-gfx-doc\n",
      "The following NEW packages will be installed:\n",
      "  gir1.2-ibus-1.0 libcapnp-0.6.1 libdbus-1-dev libibus-1.0-5 libibus-1.0-dev\n",
      "  libmirclient-dev libmirclient9 libmircommon-dev libmircommon7\n",
      "  libmircookie-dev libmircookie2 libmircore-dev libmircore1 libmirprotobuf3\n",
      "  libprotobuf-dev libprotobuf-lite10 libpulse-dev libpulse-mainloop-glib0\n",
      "  libsdl2-dev libsdl2-gfx-1.0-0 libsdl2-gfx-dev libsdl2-ttf-2.0-0\n",
      "  libsdl2-ttf-dev libsndio-dev libudev-dev libxcursor-dev libxinerama-dev\n",
      "  libxkbcommon-dev libxrandr-dev libxv-dev x11proto-randr-dev\n",
      "  x11proto-xinerama-dev\n",
      "0 upgraded, 32 newly installed, 0 to remove and 65 not upgraded.\n",
      "Need to get 3,919 kB of archives.\n",
      "After this operation, 24.9 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libibus-1.0-5 amd64 1.5.17-3ubuntu5.3 [133 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gir1.2-ibus-1.0 amd64 1.5.17-3ubuntu5.3 [66.5 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcapnp-0.6.1 amd64 0.6.1-1ubuntu1 [658 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdbus-1-dev amd64 1.12.2-1ubuntu1.1 [165 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libibus-1.0-dev amd64 1.5.17-3ubuntu5.3 [145 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore1 amd64 0.31.1-0ubuntu1 [26.5 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon7 amd64 0.31.1-0ubuntu1 [73.9 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-lite10 amd64 3.0.0-9.1ubuntu1 [97.7 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirprotobuf3 amd64 0.31.1-0ubuntu1 [127 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient9 amd64 0.31.1-0ubuntu1 [199 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore-dev amd64 0.31.1-0ubuntu1 [21.7 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-dev amd64 3.0.0-9.1ubuntu1 [959 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxkbcommon-dev amd64 0.8.2-1~ubuntu18.04.1 [150 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon-dev amd64 0.31.1-0ubuntu1 [13.9 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie2 amd64 0.31.1-0ubuntu1 [19.7 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie-dev amd64 0.31.1-0ubuntu1 [4,392 B]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient-dev amd64 0.31.1-0ubuntu1 [47.8 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-mainloop-glib0 amd64 1:11.1-1ubuntu7.4 [22.1 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-dev amd64 1:11.1-1ubuntu7.4 [81.5 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsndio-dev amd64 1.1.0-3 [13.3 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libudev-dev amd64 237-3ubuntu10.39 [19.1 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor-dev amd64 1:1.1.15-1 [26.5 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xinerama-dev all 2018.4-4 [2,628 B]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama-dev amd64 2:1.1.3-1 [8,404 B]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-randr-dev all 2018.4-4 [2,620 B]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr-dev amd64 2:1.5.1-1 [24.0 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxv-dev amd64 2:1.0.11-1 [32.5 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsdl2-dev amd64 2.0.8+dfsg1-1ubuntu1.18.04.4 [683 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-gfx-1.0-0 amd64 1.0.4+dfsg-1 [29.9 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-gfx-dev amd64 1.0.4+dfsg-1 [29.8 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-ttf-2.0-0 amd64 2.0.14+dfsg1-2 [14.8 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-ttf-dev amd64 2.0.14+dfsg1-2 [19.7 kB]\n",
      "Fetched 3,919 kB in 2s (2,012 kB/s)\n",
      "Extracting templates from packages: 100%\n",
      "Selecting previously unselected package libibus-1.0-5:amd64.\n",
      "(Reading database ... 144568 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libibus-1.0-5_1.5.17-3ubuntu5.3_amd64.deb ...\n",
      "Unpacking libibus-1.0-5:amd64 (1.5.17-3ubuntu5.3) ...\n",
      "Selecting previously unselected package gir1.2-ibus-1.0:amd64.\n",
      "Preparing to unpack .../01-gir1.2-ibus-1.0_1.5.17-3ubuntu5.3_amd64.deb ...\n",
      "Unpacking gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu5.3) ...\n",
      "Selecting previously unselected package libcapnp-0.6.1:amd64.\n",
      "Preparing to unpack .../02-libcapnp-0.6.1_0.6.1-1ubuntu1_amd64.deb ...\n",
      "Unpacking libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n",
      "Selecting previously unselected package libdbus-1-dev:amd64.\n",
      "Preparing to unpack .../03-libdbus-1-dev_1.12.2-1ubuntu1.1_amd64.deb ...\n",
      "Unpacking libdbus-1-dev:amd64 (1.12.2-1ubuntu1.1) ...\n",
      "Selecting previously unselected package libibus-1.0-dev:amd64.\n",
      "Preparing to unpack .../04-libibus-1.0-dev_1.5.17-3ubuntu5.3_amd64.deb ...\n",
      "Unpacking libibus-1.0-dev:amd64 (1.5.17-3ubuntu5.3) ...\n",
      "Selecting previously unselected package libmircore1:amd64.\n",
      "Preparing to unpack .../05-libmircore1_0.31.1-0ubuntu1_amd64.deb ...\n",
      "Unpacking libmircore1:amd64 (0.31.1-0ubuntu1) ...\n",
      "Selecting previously unselected package libmircommon7:amd64.\n",
      "Preparing to unpack .../06-libmircommon7_0.31.1-0ubuntu1_amd64.deb ...\n",
      "Unpacking libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n",
      "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
      "Preparing to unpack .../07-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
      "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
      "Selecting previously unselected package libmirprotobuf3:amd64.\n",
      "Preparing to unpack .../08-libmirprotobuf3_0.31.1-0ubuntu1_amd64.deb ...\n",
      "Unpacking libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n",
      "Selecting previously unselected package libmirclient9:amd64.\n",
      "Preparing to unpack .../09-libmirclient9_0.31.1-0ubuntu1_amd64.deb ...\n",
      "Unpacking libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n",
      "Selecting previously unselected package libmircore-dev:amd64.\n",
      "Preparing to unpack .../10-libmircore-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
      "Unpacking libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n",
      "Selecting previously unselected package libprotobuf-dev:amd64.\n",
      "Preparing to unpack .../11-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
      "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
      "Selecting previously unselected package libxkbcommon-dev:amd64.\n",
      "Preparing to unpack .../12-libxkbcommon-dev_0.8.2-1~ubuntu18.04.1_amd64.deb ...\n",
      "Unpacking libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\n",
      "Selecting previously unselected package libmircommon-dev:amd64.\n",
      "Preparing to unpack .../13-libmircommon-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
      "Unpacking libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n",
      "Selecting previously unselected package libmircookie2:amd64.\n",
      "Preparing to unpack .../14-libmircookie2_0.31.1-0ubuntu1_amd64.deb ...\n",
      "Unpacking libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n",
      "Selecting previously unselected package libmircookie-dev:amd64.\n",
      "Preparing to unpack .../15-libmircookie-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
      "Unpacking libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n",
      "Selecting previously unselected package libmirclient-dev:amd64.\n",
      "Preparing to unpack .../16-libmirclient-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
      "Unpacking libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n",
      "Selecting previously unselected package libpulse-mainloop-glib0:amd64.\n",
      "Preparing to unpack .../17-libpulse-mainloop-glib0_1%3a11.1-1ubuntu7.4_amd64.deb ...\n",
      "Unpacking libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.4) ...\n",
      "Selecting previously unselected package libpulse-dev:amd64.\n",
      "Preparing to unpack .../18-libpulse-dev_1%3a11.1-1ubuntu7.4_amd64.deb ...\n",
      "Unpacking libpulse-dev:amd64 (1:11.1-1ubuntu7.4) ...\n",
      "Selecting previously unselected package libsndio-dev:amd64.\n",
      "Preparing to unpack .../19-libsndio-dev_1.1.0-3_amd64.deb ...\n",
      "Unpacking libsndio-dev:amd64 (1.1.0-3) ...\n",
      "Selecting previously unselected package libudev-dev:amd64.\n",
      "Preparing to unpack .../20-libudev-dev_237-3ubuntu10.39_amd64.deb ...\n",
      "Unpacking libudev-dev:amd64 (237-3ubuntu10.39) ...\n",
      "Selecting previously unselected package libxcursor-dev:amd64.\n",
      "Preparing to unpack .../21-libxcursor-dev_1%3a1.1.15-1_amd64.deb ...\n",
      "Unpacking libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
      "Selecting previously unselected package x11proto-xinerama-dev.\n",
      "Preparing to unpack .../22-x11proto-xinerama-dev_2018.4-4_all.deb ...\n",
      "Unpacking x11proto-xinerama-dev (2018.4-4) ...\n",
      "Selecting previously unselected package libxinerama-dev:amd64.\n",
      "Preparing to unpack .../23-libxinerama-dev_2%3a1.1.3-1_amd64.deb ...\n",
      "Unpacking libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
      "Selecting previously unselected package x11proto-randr-dev.\n",
      "Preparing to unpack .../24-x11proto-randr-dev_2018.4-4_all.deb ...\n",
      "Unpacking x11proto-randr-dev (2018.4-4) ...\n",
      "Selecting previously unselected package libxrandr-dev:amd64.\n",
      "Preparing to unpack .../25-libxrandr-dev_2%3a1.5.1-1_amd64.deb ...\n",
      "Unpacking libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
      "Selecting previously unselected package libxv-dev:amd64.\n",
      "Preparing to unpack .../26-libxv-dev_2%3a1.0.11-1_amd64.deb ...\n",
      "Unpacking libxv-dev:amd64 (2:1.0.11-1) ...\n",
      "Selecting previously unselected package libsdl2-dev:amd64.\n",
      "Preparing to unpack .../27-libsdl2-dev_2.0.8+dfsg1-1ubuntu1.18.04.4_amd64.deb ...\n",
      "Unpacking libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\n",
      "Selecting previously unselected package libsdl2-gfx-1.0-0:amd64.\n",
      "Preparing to unpack .../28-libsdl2-gfx-1.0-0_1.0.4+dfsg-1_amd64.deb ...\n",
      "Unpacking libsdl2-gfx-1.0-0:amd64 (1.0.4+dfsg-1) ...\n",
      "Selecting previously unselected package libsdl2-gfx-dev:amd64.\n",
      "Preparing to unpack .../29-libsdl2-gfx-dev_1.0.4+dfsg-1_amd64.deb ...\n",
      "Unpacking libsdl2-gfx-dev:amd64 (1.0.4+dfsg-1) ...\n",
      "Selecting previously unselected package libsdl2-ttf-2.0-0:amd64.\n",
      "Preparing to unpack .../30-libsdl2-ttf-2.0-0_2.0.14+dfsg1-2_amd64.deb ...\n",
      "Unpacking libsdl2-ttf-2.0-0:amd64 (2.0.14+dfsg1-2) ...\n",
      "Selecting previously unselected package libsdl2-ttf-dev:amd64.\n",
      "Preparing to unpack .../31-libsdl2-ttf-dev_2.0.14+dfsg1-2_amd64.deb ...\n",
      "Unpacking libsdl2-ttf-dev:amd64 (2.0.14+dfsg1-2) ...\n",
      "Setting up libdbus-1-dev:amd64 (1.12.2-1ubuntu1.1) ...\n",
      "Setting up libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
      "Setting up libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\n",
      "Setting up libsdl2-gfx-1.0-0:amd64 (1.0.4+dfsg-1) ...\n",
      "Setting up libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.4) ...\n",
      "Setting up libpulse-dev:amd64 (1:11.1-1ubuntu7.4) ...\n",
      "Setting up libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n",
      "Setting up libsndio-dev:amd64 (1.1.0-3) ...\n",
      "Setting up libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n",
      "Setting up x11proto-xinerama-dev (2018.4-4) ...\n",
      "Setting up x11proto-randr-dev (2018.4-4) ...\n",
      "Setting up libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
      "Setting up libxv-dev:amd64 (2:1.0.11-1) ...\n",
      "Setting up libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n",
      "Setting up libibus-1.0-5:amd64 (1.5.17-3ubuntu5.3) ...\n",
      "Setting up libsdl2-ttf-2.0-0:amd64 (2.0.14+dfsg1-2) ...\n",
      "Setting up libmircore1:amd64 (0.31.1-0ubuntu1) ...\n",
      "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
      "Setting up libudev-dev:amd64 (237-3ubuntu10.39) ...\n",
      "Setting up gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu5.3) ...\n",
      "Setting up libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
      "Setting up libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n",
      "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
      "Setting up libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n",
      "Setting up libibus-1.0-dev:amd64 (1.5.17-3ubuntu5.3) ...\n",
      "Setting up libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n",
      "Setting up libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n",
      "Setting up libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n",
      "Setting up libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n",
      "Setting up libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\n",
      "Setting up libsdl2-ttf-dev:amd64 (2.0.14+dfsg1-2) ...\n",
      "Setting up libsdl2-gfx-dev:amd64 (1.0.4+dfsg-1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "Cloning into 'football'...\n",
      "remote: Enumerating objects: 2225, done.\u001b[K\n",
      "remote: Total 2225 (delta 0), reused 0 (delta 0), pack-reused 2225\u001b[K\n",
      "Receiving objects: 100% (2225/2225), 26.80 MiB | 18.12 MiB/s, done.\n",
      "Resolving deltas: 100% (1183/1183), done.\n",
      "--2020-04-21 01:58:10--  https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.0.6.so\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 2607:f8b0:400e:c00::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 45228864 (43M) [application/octet-stream]\n",
      "Saving to: ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’\n",
      "\n",
      "football/third_part 100%[===================>]  43.13M  99.2MB/s    in 0.4s    \n",
      "\n",
      "2020-04-21 01:58:11 (99.2 MB/s) - ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’ saved [45228864/45228864]\n",
      "\n",
      "Processing /content/football\n",
      "Collecting pygame==1.9.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
      "\u001b[K     |████████████████████████████████| 11.4MB 4.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from gfootball==2.0.6) (4.1.2.30)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gfootball==2.0.6) (1.4.1)\n",
      "Requirement already satisfied: gym>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from gfootball==2.0.6) (0.17.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from gfootball==2.0.6) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python->gfootball==2.0.6) (1.18.2)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.11.0->gfootball==2.0.6) (1.5.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym>=0.11.0->gfootball==2.0.6) (1.12.0)\n",
      "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.11.0->gfootball==2.0.6) (1.3.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.11.0->gfootball==2.0.6) (0.16.0)\n",
      "Building wheels for collected packages: gfootball\n",
      "  Building wheel for gfootball (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gfootball: filename=gfootball-2.0.6-cp36-cp36m-linux_x86_64.whl size=38595160 sha256=6e3c87a259f3b9e791b37dba3293f21a40ad9befa6595e2782482c0cb69bf538\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-fzutq5cx/wheels/41/ad/ae/8cf1d92b8694b10187e5daf33e8d5c248ffa5437e234ccbbee\n",
      "Successfully built gfootball\n",
      "Installing collected packages: pygame, gfootball\n",
      "Successfully installed gfootball-2.0.6 pygame-1.9.6\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install libsdl2-gfx-dev libsdl2-ttf-dev\n",
    "\n",
    "# Make sure that the Branch in git clone and in wget call matches !!\n",
    "!git clone -b v2.0.6 https://github.com/google-research/football.git\n",
    "!mkdir -p football/third_party/gfootball_engine/lib\n",
    "\n",
    "!wget https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.0.6.so -O football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so\n",
    "!cd football && GFOOTBALL_USE_PREBUILT_SO=1 pip3 install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGCu8kbl21Rx"
   },
   "source": [
    "# Now, you can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XnFhIFOOTEtA",
    "outputId": "16959fe8-ede2-4c80-ebcb-43d768f9dde1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqgC1st5fsxZ"
   },
   "outputs": [],
   "source": [
    "import gfootball.env as football_env\n",
    "#import gym # for cartpole (original source)\n",
    "\n",
    "EPISODES = 1000\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    # build the MLP model\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(48, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    # agent memorises the different policies\n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    # exploration / exploitation\n",
    "    def act(self, state):\n",
    "        \n",
    "        # exploration\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        # exploitation\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        loss = []\n",
    "        x_batch, y_batch = [], []\n",
    "        minibatch = random.sample(self.memory, min(len(self.memory), batch_size))\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            \n",
    "            y_target = self.model.predict(state)\n",
    "            old_q_val = y_target[0][action]\n",
    "            y_target[0][action] = reward if done else reward + self.gamma * np.max(self.model.predict(next_state)[0])\n",
    "            loss.append((y_target[0][action] - old_q_val)**2)\n",
    "            x_batch.append(state[0])\n",
    "            y_batch.append(y_target[0])\n",
    "\n",
    "        \n",
    "\n",
    "        self.model.fit(np.array(x_batch), np.array(y_batch), batch_size=len(x_batch), verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        return np.mean(loss)\n",
    "\n",
    "\n",
    "    \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TlegNSyBfuMY",
    "outputId": "4a8c32c9-98c3-4f96-c965-6f4472e0217d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0, at time 48, episode: 0, loss: 0.9042378252381371\n",
      "reward: 0.0, at time 38, episode: 1, loss: 1.7424197354803237\n",
      "reward: 0.0, at time 47, episode: 2, loss: 0.15203538445595655\n",
      "reward: 0.0, at time 120, episode: 3, loss: 0.009463633576210384\n",
      "reward: 0.0, at time 54, episode: 4, loss: 0.007495058671114663\n",
      "reward: 0.0, at time 66, episode: 5, loss: 0.0037423915714946965\n",
      "reward: 0.0, at time 123, episode: 7, loss: 0.0010396012825844014\n",
      "reward: 0.0, at time 138, episode: 8, loss: 0.0004343248050380222\n",
      "reward: 0.0, at time 191, episode: 9, loss: 0.003163110944922831\n",
      "reward: 0.0, at time 142, episode: 10, loss: 0.0010457673761319342\n",
      "reward: 0.0, at time 105, episode: 11, loss: 0.0010563086248309705\n",
      "reward: 0.0, at time 82, episode: 12, loss: 0.001326380215168621\n",
      "reward: 0.0, at time 235, episode: 13, loss: 0.0007129985024283969\n",
      "reward: 0.0, at time 92, episode: 14, loss: 0.0009904894302098788\n",
      "reward: 0.0, at time 123, episode: 15, loss: 0.0008534833017367349\n",
      "reward: 0.0, at time 154, episode: 16, loss: 0.0005265203761238291\n",
      "reward: 0.0, at time 55, episode: 17, loss: 0.00039462134284237727\n",
      "reward: 0.0, at time 143, episode: 19, loss: 0.00026979937878424815\n",
      "reward: 0.0, at time 113, episode: 20, loss: 0.0003282821541849834\n",
      "reward: 0.0, at time 114, episode: 21, loss: 0.00021715509621905021\n",
      "reward: 0.0, at time 76, episode: 22, loss: 0.00020894927120757023\n",
      "reward: 0.0, at time 145, episode: 23, loss: 0.00037405931385338376\n",
      "reward: 0.0, at time 149, episode: 24, loss: 0.00016931692650870578\n",
      "reward: 0.0, at time 145, episode: 25, loss: 0.0002127583771355246\n",
      "reward: 1.0, at time 138, episode: 26, loss: 0.005406593867720133\n",
      "reward: 0.0, at time 144, episode: 27, loss: 0.0005290403566493573\n",
      "reward: 0.0, at time 89, episode: 28, loss: 0.0006317297651008413\n",
      "reward: 0.0, at time 242, episode: 29, loss: 0.0003641796741803982\n",
      "reward: 0.0, at time 92, episode: 30, loss: 0.00010202018298791082\n",
      "reward: 0.0, at time 66, episode: 31, loss: 0.000306735380779348\n",
      "reward: -1.0, at time 124, episode: 33, loss: 0.0008346720589683734\n",
      "reward: 0.0, at time 150, episode: 34, loss: 0.00036569826816008205\n",
      "reward: 0.0, at time 222, episode: 35, loss: 0.0001717612594169804\n",
      "reward: 0.0, at time 50, episode: 36, loss: 0.00024488498858731\n",
      "reward: 0.0, at time 265, episode: 37, loss: 8.191720740439307e-05\n",
      "reward: 0.0, at time 117, episode: 38, loss: 0.000175709644767659\n",
      "reward: 0.0, at time 87, episode: 39, loss: 0.00010694112301972737\n",
      "reward: 0.0, at time 99, episode: 40, loss: 5.6240226324444365e-05\n",
      "reward: 0.0, at time 283, episode: 41, loss: 0.00013819654990859277\n",
      "reward: 0.0, at time 118, episode: 42, loss: 3.15349466085673e-05\n",
      "reward: 0.0, at time 79, episode: 43, loss: 4.3001951660801355e-05\n",
      "reward: 0.0, at time 51, episode: 44, loss: 4.1060417076917155e-05\n",
      "reward: 0.0, at time 97, episode: 45, loss: 9.925032729838149e-05\n",
      "reward: 0.0, at time 116, episode: 46, loss: 1.8940302888134988e-05\n",
      "reward: 0.0, at time 117, episode: 47, loss: 2.971993167685122e-05\n",
      "reward: 0.0, at time 71, episode: 48, loss: 5.8809480732349706e-05\n",
      "reward: 0.0, at time 257, episode: 49, loss: 3.09901020233358e-05\n",
      "reward: 0.0, at time 104, episode: 50, loss: 4.608268902492503e-05\n",
      "reward: 0.0, at time 123, episode: 51, loss: 0.00043828320708383384\n",
      "reward: 0.0, at time 50, episode: 52, loss: 6.424387653695268e-05\n",
      "reward: 0.0, at time 48, episode: 53, loss: 8.274537736892296e-05\n",
      "reward: 1.0, at time 79, episode: 54, loss: 7.021023101684565e-05\n",
      "reward: 0.0, at time 122, episode: 55, loss: 8.202502829082053e-05\n",
      "reward: -1.0, at time 52, episode: 56, loss: 3.584820428075702e-05\n",
      "reward: -1.0, at time 52, episode: 57, loss: 3.794784752001422e-05\n",
      "reward: 0.0, at time 158, episode: 58, loss: 1.8143704782824094e-05\n",
      "reward: 1.0, at time 82, episode: 59, loss: 0.00014626472140708002\n",
      "reward: 0.0, at time 49, episode: 60, loss: 0.00022970222072643542\n",
      "reward: 0.0, at time 177, episode: 61, loss: 1.9277135759106917e-05\n",
      "reward: 0.0, at time 71, episode: 62, loss: 1.189035542673543e-05\n",
      "reward: 0.0, at time 57, episode: 64, loss: 9.516659991239823e-06\n",
      "reward: 0.0, at time 71, episode: 65, loss: 2.224504418492368e-05\n",
      "reward: 0.0, at time 139, episode: 66, loss: 1.8423127260509473e-05\n",
      "reward: 0.0, at time 63, episode: 67, loss: 2.0479560625158606e-05\n",
      "reward: 0.0, at time 68, episode: 68, loss: 0.13932656506945307\n",
      "reward: 0.0, at time 61, episode: 69, loss: 0.049474777803062864\n",
      "reward: 0.0, at time 137, episode: 70, loss: 0.0005573638955691518\n",
      "reward: 0.0, at time 121, episode: 71, loss: 0.0004502615462407267\n",
      "reward: 0.0, at time 133, episode: 72, loss: 0.0001496046151644448\n",
      "reward: 0.0, at time 123, episode: 73, loss: 8.387317357873986e-05\n",
      "reward: 0.0, at time 137, episode: 74, loss: 0.00012374727316445677\n",
      "reward: 0.0, at time 86, episode: 75, loss: 8.771989812695474e-05\n",
      "reward: 0.0, at time 135, episode: 76, loss: 0.00020330204241749555\n",
      "reward: 0.0, at time 126, episode: 77, loss: 0.00040330362972634294\n",
      "reward: 0.0, at time 76, episode: 79, loss: 3.402928267026706e-05\n",
      "reward: 0.0, at time 58, episode: 80, loss: 4.779966145402291e-05\n",
      "reward: 0.0, at time 62, episode: 82, loss: 2.596262852462214e-05\n",
      "reward: 0.0, at time 75, episode: 83, loss: 4.415191522013501e-05\n",
      "reward: 0.0, at time 94, episode: 84, loss: 1.4273955563727514e-05\n",
      "reward: 0.0, at time 115, episode: 86, loss: 2.303664361445832e-05\n",
      "reward: 0.0, at time 109, episode: 87, loss: 4.349651352130498e-05\n",
      "reward: 0.0, at time 127, episode: 88, loss: 2.5453140952829204e-05\n",
      "reward: 0.0, at time 90, episode: 89, loss: 5.40344566708241e-05\n",
      "reward: 0.0, at time 69, episode: 90, loss: 5.167895551810332e-05\n",
      "reward: 0.0, at time 59, episode: 91, loss: 2.652790253589339e-05\n",
      "reward: 0.0, at time 294, episode: 92, loss: 2.2084633483339042e-05\n",
      "reward: 1.0, at time 89, episode: 93, loss: 1.956608411174572e-05\n",
      "reward: 0.0, at time 75, episode: 94, loss: 1.4577085308809488e-05\n",
      "reward: 0.0, at time 135, episode: 95, loss: 4.952996882565987e-05\n",
      "reward: 0.0, at time 127, episode: 96, loss: 5.543794436263516e-06\n",
      "reward: 0.0, at time 126, episode: 97, loss: 5.636834608540968e-06\n",
      "reward: 0.0, at time 55, episode: 98, loss: 1.1005043915112995e-05\n",
      "reward: 0.0, at time 141, episode: 99, loss: 8.134462844036671e-05\n",
      "reward: 1.0, at time 147, episode: 101, loss: 9.039056054538635e-05\n",
      "reward: 0.0, at time 121, episode: 102, loss: 4.615804602100138e-06\n",
      "reward: 0.0, at time 75, episode: 103, loss: 2.056931491263743e-06\n",
      "reward: 0.0, at time 67, episode: 104, loss: 7.398351234603616e-06\n",
      "reward: 0.0, at time 145, episode: 105, loss: 9.739824262060444e-06\n",
      "reward: 0.0, at time 102, episode: 107, loss: 1.787510862982615e-06\n",
      "reward: 1.0, at time 72, episode: 108, loss: 4.321861328328703e-06\n",
      "reward: 0.0, at time 62, episode: 109, loss: 5.138552793111976e-06\n",
      "reward: 0.0, at time 180, episode: 110, loss: 7.088607473619514e-06\n",
      "reward: 0.0, at time 148, episode: 111, loss: 2.9069600768911455e-06\n",
      "reward: 0.0, at time 109, episode: 112, loss: 2.382484166498335e-06\n",
      "reward: 0.0, at time 146, episode: 113, loss: 2.0578522621864668e-06\n",
      "reward: 0.0, at time 51, episode: 114, loss: 5.9713335314424965e-06\n",
      "reward: 0.0, at time 114, episode: 115, loss: 1.4356303601158193e-06\n",
      "reward: 0.0, at time 293, episode: 116, loss: 2.3283211017298498e-06\n",
      "reward: 0.0, at time 299, episode: 117, loss: 7.583870941457738e-05\n",
      "reward: 0.0, at time 93, episode: 118, loss: 2.4210264372145907e-05\n",
      "reward: 0.0, at time 57, episode: 119, loss: 5.4685969323474415e-05\n",
      "reward: 0.0, at time 54, episode: 120, loss: 3.1717266461839255e-05\n",
      "reward: 0.0, at time 37, episode: 121, loss: 2.5304227835316884e-05\n",
      "reward: 0.0, at time 122, episode: 123, loss: 1.608567958011342e-05\n",
      "reward: 0.0, at time 117, episode: 124, loss: 1.3873894961932004e-05\n",
      "reward: 0.0, at time 82, episode: 125, loss: 7.704941374437908e-06\n",
      "reward: 0.0, at time 78, episode: 126, loss: 7.995808536131934e-06\n",
      "reward: 0.0, at time 160, episode: 127, loss: 7.218142082377789e-06\n",
      "reward: 0.0, at time 122, episode: 128, loss: 7.02236639893352e-06\n",
      "reward: 0.0, at time 152, episode: 130, loss: 1.2636751524845724e-05\n",
      "reward: 0.0, at time 95, episode: 131, loss: 1.0571643311431053e-05\n",
      "reward: 0.0, at time 119, episode: 132, loss: 1.9113156696597827e-05\n",
      "reward: 0.0, at time 119, episode: 133, loss: 6.1509589510035795e-06\n",
      "reward: 0.0, at time 207, episode: 134, loss: 4.446067775785382e-06\n",
      "reward: 0.0, at time 147, episode: 135, loss: 1.0286662372775961e-05\n",
      "reward: 0.0, at time 141, episode: 136, loss: 4.277093431327792e-06\n",
      "reward: 0.0, at time 225, episode: 137, loss: 2.929117669549057e-06\n",
      "reward: 0.0, at time 252, episode: 138, loss: 3.312420625040547e-07\n",
      "reward: 0.0, at time 115, episode: 139, loss: 3.2004368029318474e-07\n",
      "reward: 0.0, at time 94, episode: 140, loss: 2.1697081353043543e-07\n",
      "reward: 0.0, at time 248, episode: 141, loss: 1.772507404820833e-07\n",
      "reward: 0.0, at time 201, episode: 142, loss: 1.3784762285885238e-08\n",
      "reward: 0.0, at time 131, episode: 143, loss: 7.840893637009599e-10\n",
      "reward: 0.0, at time 208, episode: 144, loss: 8.923061758852307e-10\n",
      "reward: 0.0, at time 97, episode: 146, loss: 1.6304284842609777e-10\n",
      "reward: 0.0, at time 113, episode: 147, loss: 4.775809567820247e-10\n",
      "reward: 0.0, at time 54, episode: 148, loss: 5.501677967174021e-11\n",
      "reward: 0.0, at time 149, episode: 149, loss: 3.158599526990955e-10\n",
      "reward: 0.0, at time 201, episode: 151, loss: 2.144667608588293e-08\n",
      "reward: 0.0, at time 108, episode: 152, loss: 0.01030847097592158\n",
      "reward: 0.0, at time 58, episode: 153, loss: 0.00037727116420338547\n",
      "reward: 0.0, at time 165, episode: 154, loss: 7.376383664997599e-05\n",
      "reward: 0.0, at time 292, episode: 155, loss: 2.9129117277560193e-05\n",
      "reward: 0.0, at time 96, episode: 158, loss: 4.145225285852577e-06\n",
      "reward: 0.0, at time 75, episode: 159, loss: 2.9780097227012116e-06\n",
      "reward: 0.0, at time 140, episode: 160, loss: 1.4408718244811108e-06\n",
      "reward: 0.0, at time 152, episode: 161, loss: 8.775024488841873e-07\n",
      "reward: 0.0, at time 197, episode: 162, loss: 3.306671321384887e-06\n",
      "reward: 0.0, at time 74, episode: 163, loss: 5.812291215450197e-07\n",
      "reward: 0.0, at time 158, episode: 164, loss: 2.826247959275823e-07\n",
      "reward: -1.0, at time 198, episode: 165, loss: 9.172488430020495e-08\n",
      "reward: 0.0, at time 226, episode: 166, loss: 1.0792096758168102e-07\n",
      "reward: 0.0, at time 70, episode: 167, loss: 6.581101842919267e-08\n",
      "reward: 0.0, at time 155, episode: 168, loss: 2.8670000333683393e-08\n",
      "reward: 0.0, at time 61, episode: 169, loss: 1.6424658925172757e-07\n",
      "reward: 0.0, at time 70, episode: 170, loss: 4.102628772878913e-08\n",
      "reward: 0.0, at time 90, episode: 171, loss: 1.020903510752848e-08\n",
      "reward: 0.0, at time 95, episode: 172, loss: 2.0943545732666528e-08\n",
      "reward: 0.0, at time 95, episode: 173, loss: 5.3740837229706675e-09\n",
      "reward: 0.0, at time 63, episode: 174, loss: 2.0628474048885253e-08\n",
      "reward: 0.0, at time 103, episode: 175, loss: 2.5910138751032532e-08\n",
      "reward: 0.0, at time 124, episode: 176, loss: 1.6295340655128095e-09\n",
      "reward: 0.0, at time 146, episode: 177, loss: 1.584204693070728e-09\n",
      "reward: 0.0, at time 108, episode: 178, loss: 4.791399138147657e-09\n",
      "reward: 0.0, at time 149, episode: 179, loss: 7.093481530555465e-09\n",
      "reward: 0.0, at time 98, episode: 180, loss: 2.0480241847415657e-09\n",
      "reward: 0.0, at time 80, episode: 181, loss: 2.3795559601451175e-09\n",
      "reward: 0.0, at time 54, episode: 182, loss: 2.090359990880972e-09\n",
      "reward: 1.0, at time 76, episode: 183, loss: 2.3166859019351106e-09\n",
      "reward: 0.0, at time 91, episode: 184, loss: 9.354614963086277e-09\n",
      "reward: 0.0, at time 123, episode: 185, loss: 7.621631619107973e-10\n",
      "reward: 1.0, at time 72, episode: 186, loss: 9.163816834803998e-10\n",
      "reward: 1.0, at time 65, episode: 187, loss: 6.155266458178733e-10\n",
      "reward: 0.0, at time 48, episode: 188, loss: 1.00385922060877e-09\n",
      "reward: 1.0, at time 68, episode: 189, loss: 5.862314833533893e-10\n",
      "reward: 0.0, at time 130, episode: 190, loss: 7.730143035183756e-10\n",
      "reward: 0.0, at time 172, episode: 191, loss: 2.3339948382920745e-10\n",
      "reward: 0.0, at time 101, episode: 192, loss: 4.522565392440956e-10\n",
      "reward: 0.0, at time 64, episode: 193, loss: 3.0256139549468398e-09\n",
      "reward: 0.0, at time 143, episode: 194, loss: 5.309658135122788e-09\n",
      "reward: 0.0, at time 135, episode: 195, loss: 1.8621797262935436e-09\n",
      "reward: 0.0, at time 145, episode: 196, loss: 9.994803874742576e-10\n",
      "reward: 0.0, at time 76, episode: 197, loss: 4.911226685465022e-10\n",
      "reward: 0.0, at time 77, episode: 199, loss: 6.585597340983301e-10\n",
      "reward: 0.0, at time 56, episode: 200, loss: 8.467983758261788e-10\n",
      "reward: -1.0, at time 75, episode: 201, loss: 4.428211024561907e-10\n",
      "reward: 0.0, at time 144, episode: 202, loss: 2.367374265476263e-09\n",
      "reward: 0.0, at time 89, episode: 203, loss: 2.145437693400567e-09\n",
      "reward: 0.0, at time 155, episode: 204, loss: 6.340719272368794e-10\n",
      "reward: 0.0, at time 124, episode: 205, loss: 1.1791385215429724e-10\n",
      "reward: 0.0, at time 51, episode: 206, loss: 7.536664915113163e-09\n",
      "reward: 0.0, at time 140, episode: 207, loss: 4.786485175565935e-10\n",
      "reward: 0.0, at time 62, episode: 209, loss: 1.447785569930157e-09\n",
      "reward: -1.0, at time 93, episode: 210, loss: 5.4739261295941975e-11\n",
      "reward: 0.0, at time 99, episode: 211, loss: 1.0768689154467673e-10\n",
      "reward: 0.0, at time 79, episode: 212, loss: 3.7181132360944134e-10\n",
      "reward: 0.0, at time 55, episode: 213, loss: 5.881493443949568e-10\n",
      "reward: 0.0, at time 139, episode: 214, loss: 4.676511614978222e-10\n",
      "reward: 0.0, at time 62, episode: 215, loss: 1.3614790065751183e-09\n",
      "reward: 0.0, at time 73, episode: 216, loss: 3.552596769957868e-10\n",
      "reward: 0.0, at time 139, episode: 217, loss: 9.991789890284438e-10\n",
      "reward: 0.0, at time 76, episode: 219, loss: 2.28764166407417e-10\n",
      "reward: 0.0, at time 84, episode: 220, loss: 4.3257900569369867e-10\n",
      "reward: 0.0, at time 130, episode: 221, loss: 3.8062016085561305e-10\n",
      "reward: 0.0, at time 60, episode: 222, loss: 6.312377462197664e-09\n",
      "reward: 0.0, at time 84, episode: 223, loss: 3.7962204865873506e-08\n",
      "reward: 0.0, at time 125, episode: 224, loss: 4.4126345079209745e-09\n",
      "reward: 0.0, at time 133, episode: 225, loss: 7.810143308727293e-08\n",
      "reward: 0.0, at time 160, episode: 226, loss: 4.1764292822489985e-09\n",
      "reward: 0.0, at time 112, episode: 227, loss: 7.054869998161393e-10\n",
      "reward: 0.0, at time 87, episode: 228, loss: 3.5679478090144447e-09\n",
      "reward: 0.0, at time 149, episode: 229, loss: 2.1833847466644013e-08\n",
      "reward: 0.0, at time 50, episode: 230, loss: 7.949286839184825e-08\n",
      "reward: 0.0, at time 128, episode: 231, loss: 3.040122677973084e-08\n",
      "reward: 0.0, at time 111, episode: 232, loss: 1.704191170595463e-08\n",
      "reward: 0.0, at time 99, episode: 233, loss: 1.2452085694645819e-08\n",
      "reward: 0.0, at time 101, episode: 234, loss: 1.9940690707852325e-08\n",
      "reward: 0.0, at time 120, episode: 235, loss: 3.1248870875236017e-08\n",
      "reward: -1.0, at time 149, episode: 237, loss: 9.344659994775192e-08\n",
      "reward: 1.0, at time 148, episode: 238, loss: 4.9375176676332575e-09\n",
      "reward: -1.0, at time 71, episode: 239, loss: 1.4099358269857075e-08\n",
      "reward: 0.0, at time 54, episode: 240, loss: 6.986198054878979e-08\n",
      "reward: 0.0, at time 83, episode: 241, loss: 2.165960664178622e-08\n",
      "reward: 0.0, at time 140, episode: 243, loss: 8.517769767607918e-09\n",
      "reward: 0.0, at time 64, episode: 244, loss: 1.1573915754483114e-08\n",
      "reward: 0.0, at time 61, episode: 245, loss: 5.325466794838549e-08\n",
      "reward: 0.0, at time 70, episode: 246, loss: 3.36020201249722e-09\n",
      "reward: 0.0, at time 88, episode: 247, loss: 3.376662254936033e-07\n",
      "reward: 0.0, at time 67, episode: 249, loss: 1.2652117418110106e-07\n",
      "reward: 0.0, at time 78, episode: 250, loss: 3.792094038401788e-08\n",
      "reward: 0.0, at time 95, episode: 251, loss: 3.274947901742446e-08\n",
      "reward: 0.0, at time 129, episode: 252, loss: 3.112359266979007e-08\n",
      "reward: 0.0, at time 48, episode: 253, loss: 3.015373770503247e-08\n",
      "reward: 0.0, at time 111, episode: 254, loss: 7.170658485576993e-08\n",
      "reward: 0.0, at time 61, episode: 255, loss: 4.429983294001257e-08\n",
      "reward: 0.0, at time 53, episode: 256, loss: 1.4028995787748722e-08\n",
      "reward: 0.0, at time 57, episode: 257, loss: 4.998008497284753e-08\n",
      "reward: 0.0, at time 55, episode: 258, loss: 1.5863370230327265e-07\n",
      "reward: 0.0, at time 161, episode: 259, loss: 1.52290278924278e-08\n",
      "reward: 0.0, at time 50, episode: 260, loss: 7.340197332822386e-08\n",
      "reward: 0.0, at time 47, episode: 261, loss: 1.7405989124009492e-08\n",
      "reward: 0.0, at time 142, episode: 262, loss: 1.3749225817184904e-08\n",
      "reward: 0.0, at time 186, episode: 264, loss: 1.3911250295226517e-06\n",
      "reward: 0.0, at time 72, episode: 265, loss: 7.093106562652482e-08\n",
      "reward: 0.0, at time 106, episode: 266, loss: 5.255248289185998e-09\n",
      "reward: 0.0, at time 96, episode: 267, loss: 1.070231967033362e-09\n",
      "reward: 0.0, at time 48, episode: 268, loss: 6.277819078807473e-10\n",
      "reward: 0.0, at time 169, episode: 269, loss: 3.069792969378095e-10\n",
      "reward: 0.0, at time 109, episode: 270, loss: 4.665329326963239e-11\n",
      "reward: 0.0, at time 117, episode: 271, loss: 2.989585994884698e-10\n",
      "reward: 0.0, at time 224, episode: 272, loss: 4.1292544011430695e-09\n",
      "reward: 0.0, at time 63, episode: 273, loss: 6.1158819692946805e-09\n",
      "reward: 0.0, at time 57, episode: 274, loss: 5.808802513745354e-09\n",
      "reward: 0.0, at time 93, episode: 275, loss: 2.7856088368517072e-09\n",
      "reward: 0.0, at time 107, episode: 276, loss: 2.819294535621222e-08\n",
      "reward: 0.0, at time 78, episode: 277, loss: 1.9781835943776297e-07\n",
      "reward: 0.0, at time 133, episode: 278, loss: 1.6803901402393396e-07\n",
      "reward: 0.0, at time 51, episode: 279, loss: 1.5430547470251187e-07\n",
      "reward: 0.0, at time 49, episode: 280, loss: 3.995966357531666e-07\n",
      "reward: -1.0, at time 103, episode: 281, loss: 1.9409583824252577e-07\n",
      "reward: 0.0, at time 177, episode: 282, loss: 1.2902153012565513e-09\n",
      "reward: 0.0, at time 229, episode: 283, loss: 2.17352850400775e-09\n",
      "reward: 0.0, at time 57, episode: 284, loss: 2.985950871489199e-09\n",
      "reward: 0.0, at time 83, episode: 285, loss: 6.776975935000386e-10\n",
      "reward: 0.0, at time 118, episode: 286, loss: 5.44088019755574e-08\n",
      "reward: 0.0, at time 95, episode: 287, loss: 2.1652890681953148e-08\n",
      "reward: 0.0, at time 188, episode: 288, loss: 7.539833721784844e-07\n",
      "reward: 0.0, at time 104, episode: 289, loss: 6.237907493818239e-07\n",
      "reward: 0.0, at time 115, episode: 290, loss: 2.3681620863684038e-07\n",
      "reward: 0.0, at time 100, episode: 291, loss: 2.4987529101709247e-07\n",
      "reward: -1.0, at time 227, episode: 292, loss: 3.294497972567762e-09\n",
      "reward: 0.0, at time 100, episode: 293, loss: 3.43785116716621e-10\n",
      "reward: 0.0, at time 146, episode: 295, loss: 1.67049584280216e-09\n",
      "reward: 0.0, at time 118, episode: 296, loss: 1.3250672986980729e-08\n",
      "reward: 0.0, at time 67, episode: 297, loss: 2.8086853637421358e-08\n",
      "reward: 0.0, at time 133, episode: 298, loss: 6.686828693084907e-08\n",
      "reward: 0.0, at time 76, episode: 299, loss: 2.9255491028074704e-07\n"
     ]
    }
   ],
   "source": [
    "env = football_env.create_environment(env_name='academy_empty_goal', representation='simple115', render=False)\n",
    "    \n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "    \n",
    "done = False\n",
    "batch_size = 32\n",
    "\n",
    "# idea is: put the ball in in least number of steps.\n",
    "\n",
    "EPISODES = 300\n",
    "STEPS = 300\n",
    "\n",
    "loss_rec = []\n",
    "reward_rec = []\n",
    "# iterate (\"play\") the game!\n",
    "for e in range(EPISODES):\n",
    "    # reset the environment at the beginning of each STEPS-step game\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    loss = 0\n",
    "    target_f = []\n",
    "    target = []\n",
    "    for t in range(STEPS):\n",
    "      # decide action\n",
    "        action = agent.act(state)\n",
    "\n",
    "      # advance the game to next frame based on the action\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "\n",
    "        if done:\n",
    "          print(\"reward: {}, at time {}, episode: {}, loss: {}\".format(reward,t,e,loss))\n",
    "          \n",
    "          break\n",
    "        \n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        \n",
    "      # memorize the previous state,action,reward and done\n",
    "        agent.memorize(state, action, reward, next_state, done)\n",
    "\n",
    "      # make next state the new current state\n",
    "        state = next_state\n",
    "\n",
    "        if len(agent.memory) > batch_size:\n",
    "                    loss = agent.replay(batch_size)\n",
    "                    \n",
    "    reward_rec.append(reward)\n",
    "    loss_rec.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ja-2b-Z3Ml0H"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "HuEW1uuaazSf",
    "outputId": "565a6e37-4956-4f5c-c191-b5bc83e558b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe8548b2b38>]"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(30),loss_rec[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yfpvanMASn_X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "“gfootball_example_from_prebuild.ipynb”的副本",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
